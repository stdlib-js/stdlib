/* eslint-disable quotes, max-lines */

/*
* This file is generated by scripts/build.js.
*/
'use strict';

module.exports = {
	"AFINN_111": "list = AFINN_111()\n",
	"AFINN_96": "list = AFINN_96()\n",
	"allocUnsafe": "buf = allocUnsafe( 100 )\n",
	"ANSCOMBES_QUARTET": "d = ANSCOMBES_QUARTET()\n",
	"any": "arr = [ 0, 0, 0, 0, 1 ];\nbool = any( arr )\n",
	"anyBy": "function negative( v ) { return ( v < 0 ); };\narr = [ 1, 2, 3, 4, -1 ];\nbool = anyBy( arr, negative )\n",
	"anyByAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 3000, 2500, 1000 ];\nanyByAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nanyByAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\nanyByAsync( arr, opts, predicate, done )\n",
	"anyByRight": "function negative( v ) { return ( v < 0 ); };\narr = [ -1, 1, 2, 3, 4 ];\nbool = anyByRight( arr, negative )\n",
	"anyByRightAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 1000, 2500, 3000 ];\nanyByRightAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\nanyByRightAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\nanyByRightAsync( arr, opts, predicate, done )\n",
	"APERY": "APERY\n",
	"append": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\narr = append( arr, [ 6.0, 7.0 ] )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\narr = append( arr, [ 3.0, 4.0 ] )\n\n// Array-like object:\narr = { 'length': 0 };\narr = append( arr, [ 1.0, 2.0 ] )\n",
	"argumentFunction": "argn = argumentFunction( 1 );\nv = argn( 3.14, -3.14, 0.0 )\nv = argn( -1.0, -0.0, 1.0 )\nv = argn( 'beep', 'boop', 'bop' )\nv = argn( 'beep' )\n",
	"ARGV": "execPath = ARGV[ 0 ]\n",
	"ArrayBuffer": "buf = new ArrayBuffer( 5 )\n",
	"arraybuffer2buffer": "ab = new ArrayBuffer( 10 )\nbuf = arraybuffer2buffer( ab )\nlen = buf.length\nbuf = arraybuffer2buffer( ab, 2, 6 )\nlen = buf.length\n",
	"arrayCtors": "ctor = arrayCtors( 'float64' )\nctor = arrayCtors( 'float' )\n",
	"arrayDataType": "arr = new Float64Array( 10 );\ndt = arrayDataType( arr )\ndt = arrayDataType( 'beep' )\n",
	"arrayDataTypes": "out = arrayDataTypes()\n",
	"array2buffer": "buf = array2buffer( [ 1, 2, 3, 4 ] )\n",
	"base.abs": "y = base.abs( -1.0 )\ny = base.abs( 2.0 )\ny = base.abs( 0.0 )\ny = base.abs( -0.0 )\ny = base.abs( NaN )\n",
	"base.abs2": "y = base.abs2( -1.0 )\ny = base.abs2( 2.0 )\ny = base.abs2( 0.0 )\ny = base.abs2( -0.0 )\ny = base.abs2( NaN )\n",
	"base.absdiff": "d = base.absdiff( 2.0, 5.0 )\nd = base.absdiff( -1.0, 3.14 )\nd = base.absdiff( 10.1, -2.05 )\nd = base.absdiff( -0.0, 0.0 )\nd = base.absdiff( NaN, 5.0 )\nd = base.absdiff( PINF, NINF )\nd = base.absdiff( PINF, PINF )\n",
	"base.absInt32": "v = base.absInt32( -1|0 )\nv = base.absInt32( 2|0 )\nv = base.absInt32( 0|0 )\n",
	"base.acos": "y = base.acos( 1.0 )\ny = base.acos( 0.707 )\ny = base.acos( NaN )\n",
	"base.acosh": "y = base.acosh( 1.0 )\ny = base.acosh( 2.0 )\ny = base.acosh( NaN )\n",
	"base.acovercos": "y = base.acovercos( -1.5 )\ny = base.acovercos( -0.0 )\n",
	"base.acoversin": "y = base.acoversin( 1.5 )\ny = base.acoversin( 0.0 )\n",
	"base.ahavercos": "y = base.ahavercos( 0.5 )\ny = base.ahavercos( 0.0 )\n",
	"base.ahaversin": "y = base.ahaversin( 0.5 )\ny = base.ahaversin( 0.0 )\n",
	"base.asin": "y = base.asin( 0.0 )\ny = base.asin( PI/2.0 )\ny = base.asin( -PI/6.0 )\ny = base.asin( NaN )\n",
	"base.asinh": "y = base.asinh( 0.0 )\ny = base.asinh( 2.0 )\ny = base.asinh( -2.0 )\ny = base.asinh( NaN )\ny = base.asinh( NINF )\ny = base.asinh( PINF )\n",
	"base.atan": "y = base.atan( 0.0 )\ny = base.atan( -PI/4.0 )\ny = base.atan( PI/4.0 )\ny = base.atan( NaN )\n",
	"base.atan2": "v = base.atan2( 2.0, 2.0 )\nv = base.atan2( 6.0, 2.0 )\nv = base.atan2( -1.0, -1.0 )\nv = base.atan2( 3.0, 0.0 )\nv = base.atan2( -2.0, 0.0 )\nv = base.atan2( 0.0, 0.0 )\nv = base.atan2( 3.0, NaN )\nv = base.atan2( NaN, 2.0 )\n",
	"base.atanh": "y = base.atanh( 0.0 )\ny = base.atanh( 0.9 )\ny = base.atanh( 1.0 )\ny = base.atanh( -1.0 )\ny = base.atanh( NaN )\n",
	"base.avercos": "y = base.avercos( -1.5 )\ny = base.avercos( -0.0 )\n",
	"base.aversin": "y = base.aversin( 1.5 )\ny = base.aversin( 0.0 )\n",
	"base.bernoulli": "y = base.bernoulli( 0 )\ny = base.bernoulli( 1 )\ny = base.bernoulli( 2 )\ny = base.bernoulli( 3 )\ny = base.bernoulli( 4 )\ny = base.bernoulli( 5 )\ny = base.bernoulli( 20 )\ny = base.bernoulli( 260 )\ny = base.bernoulli( 262 )\ny = base.bernoulli( NaN )\n",
	"base.besselj0": "y = base.besselj0( 0.0 )\ny = base.besselj0( 1.0 )\ny = base.besselj0( PINF )\ny = base.besselj0( NINF )\ny = base.besselj0( NaN )\n",
	"base.besselj1": "y = base.besselj1( 0.0 )\ny = base.besselj1( 1.0 )\ny = base.besselj1( PINF )\ny = base.besselj1( NINF )\ny = base.besselj1( NaN )\n",
	"base.bessely0": "y = base.bessely0( 0.0 )\ny = base.bessely0( 1.0 )\ny = base.bessely0( -1.0 )\ny = base.bessely0( PINF )\ny = base.bessely0( NINF )\ny = base.bessely0( NaN )\n",
	"base.bessely1": "y = base.bessely1( 0.0 )\ny = base.bessely1( 1.0 )\ny = base.bessely1( -1.0 )\ny = base.bessely1( PINF )\ny = base.bessely1( NINF )\ny = base.bessely1( NaN )\n",
	"base.beta": "v = base.beta( 0.0, 0.0 )\nv = base.beta( 1.0, 1.0 )\nv = base.beta( -1.0, 2.0 )\nv = base.beta( 5.0, 0.2 )\nv = base.beta( 4.0, 1.0 )\nv = base.beta( NaN, 2.0 )\n",
	"base.betainc": "y = base.betainc( 0.5, 2.0, 2.0 )\ny = base.betainc( 0.5, 2.0, 2.0, false )\ny = base.betainc( 0.2, 1.0, 2.0 )\ny = base.betainc( 0.2, 1.0, 2.0, true, true )\ny = base.betainc( NaN, 1.0, 1.0 )\ny = base.betainc( 0.8, NaN, 1.0 )\ny = base.betainc( 0.8, 1.0, NaN )\ny = base.betainc( 1.5, 1.0, 1.0 )\ny = base.betainc( -0.5, 1.0, 1.0 )\ny = base.betainc( 0.5, -2.0, 2.0 )\ny = base.betainc( 0.5, 2.0, -2.0 )\n",
	"base.betaincinv": "y = base.betaincinv( 0.2, 3.0, 3.0 )\ny = base.betaincinv( 0.4, 3.0, 3.0 )\ny = base.betaincinv( 0.4, 3.0, 3.0, true )\ny = base.betaincinv( 0.4, 1.0, 6.0 )\ny = base.betaincinv( 0.8, 1.0, 6.0 )\ny = base.betaincinv( NaN, 1.0, 1.0 )\ny = base.betaincinv( 0.5, NaN, 1.0 )\ny = base.betaincinv( 0.5, 1.0, NaN )\ny = base.betaincinv( 1.2, 1.0, 1.0 )\ny = base.betaincinv( -0.5, 1.0, 1.0 )\ny = base.betaincinv( 0.5, -2.0, 2.0 )\ny = base.betaincinv( 0.5, 0.0, 2.0 )\ny = base.betaincinv( 0.5, 2.0, -2.0 )\ny = base.betaincinv( 0.5, 2.0, 0.0 )\n",
	"base.betaln": "v = base.betaln( 0.0, 0.0 )\nv = base.betaln( 1.0, 1.0 )\nv = base.betaln( -1.0, 2.0 )\nv = base.betaln( 5.0, 0.2 )\nv = base.betaln( 4.0, 1.0 )\nv = base.betaln( NaN, 2.0 )\n",
	"base.binet": "y = base.binet( 0.0 )\ny = base.binet( 1.0 )\ny = base.binet( 2.0 )\ny = base.binet( 3.0 )\ny = base.binet( 4.0 )\ny = base.binet( 5.0 )\ny = base.binet( NaN )\n",
	"base.binomcoef": "v = base.binomcoef( 8, 2 )\nv = base.binomcoef( 0, 0 )\nv = base.binomcoef( -4, 2 )\nv = base.binomcoef( 5, 3 )\nv = base.binomcoef( NaN, 3 )\nv = base.binomcoef( 5, NaN )\nv = base.binomcoef( NaN, NaN )\n",
	"base.binomcoefln": "v = base.binomcoefln( 8, 2 )\nv = base.binomcoefln( 0, 0 )\nv = base.binomcoefln( -4, 2 )\nv = base.binomcoefln( 88, 3 )\nv = base.binomcoefln( NaN, 3 )\nv = base.binomcoefln( 5, NaN )\nv = base.binomcoefln( NaN, NaN )\n",
	"base.cabs": "y = base.cabs( 5.0, 3.0 )\n",
	"base.cabs2": "y = base.cabs2( 5.0, 3.0 )\n",
	"base.cadd": "y = base.cadd( 5.0, 3.0, -2.0, 1.0 )\n\n// Provide an output array:\nout = new Float32Array( 2 );\ny = base.cadd( out, 5.0, 3.0, -2.0, 1.0 )\nbool = ( y === out )\n",
	"base.cbrt": "y = base.cbrt( 64.0 )\ny = base.cbrt( 27.0 )\ny = base.cbrt( 0.0 )\ny = base.cbrt( -0.0 )\ny = base.cbrt( -9.0 )\ny = base.cbrt( NaN )\n",
	"base.cceil": "out = base.cceil( 5.5, 3.3 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.cceil( out, 5.5, 3.3 )\nbool = ( v === out )\n",
	"base.ccis": "y = base.ccis( 0.0, 0.0 )\ny = base.ccis( 1.0, 0.0 )\nout = new Float64Array( 2 );\nv = base.ccis( out, 1.0, 0.0 )\nbool = ( v === out )\n",
	"base.cdiv": "y = base.cdiv( -13.0, -1.0, -2.0, 1.0 )\nout = new Float64Array( 2 );\nv = base.cdiv( out, -13.0, -1.0, -2.0, 1.0 )\nbool = ( v === out )\n",
	"base.ceil": "y = base.ceil( 3.14 )\ny = base.ceil( -4.2 )\ny = base.ceil( -4.6 )\ny = base.ceil( 9.5 )\ny = base.ceil( -0.0 )\n",
	"base.ceil10": "y = base.ceil10( 3.14 )\ny = base.ceil10( -4.2 )\ny = base.ceil10( -4.6 )\ny = base.ceil10( 9.5 )\ny = base.ceil10( 13.0 )\ny = base.ceil10( -13.0 )\ny = base.ceil10( -0.0 )\n",
	"base.ceil2": "y = base.ceil2( 3.14 )\ny = base.ceil2( -4.2 )\ny = base.ceil2( -4.6 )\ny = base.ceil2( 9.5 )\ny = base.ceil2( 13.0 )\ny = base.ceil2( -13.0 )\ny = base.ceil2( -0.0 )\n",
	"base.ceilb": "\n// Round to 4 decimal places:\ny = base.ceilb( 3.14159, -4, 10 )\n\n// If `n = 0` or `b = 1`, standard round behavior:\ny = base.ceilb( 3.14159, 0, 2 )\n\n// Round to nearest multiple of two toward positive infinity:\ny = base.ceilb( 5.0, 1, 2 )\n",
	"base.ceiln": "\n// Round to 2 decimal places:\ny = base.ceiln( 3.14159, -2 )\n\n// If `n = 0`, standard round toward positive infinity behavior:\ny = base.ceiln( 3.14159, 0 )\n\n// Round to nearest thousand:\ny = base.ceiln( 12368.0, 3 )\n",
	"base.ceilsd": "y = base.ceilsd( 3.14159, 5 )\ny = base.ceilsd( 3.14159, 1 )\ny = base.ceilsd( 12368.0, 2 )\ny = base.ceilsd( 0.0313, 2, 2 )\n",
	"base.cfloor": "out = base.cfloor( 5.5, 3.3 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.cfloor( out, 5.5, 3.3 )\nbool = ( v === out )\n",
	"base.clamp": "y = base.clamp( 3.14, 0.0, 5.0 )\ny = base.clamp( -3.14, 0.0, 5.0 )\ny = base.clamp( 3.14, 0.0, 3.0 )\ny = base.clamp( -0.0, 0.0, 5.0 )\ny = base.clamp( 0.0, -3.14, -0.0 )\ny = base.clamp( NaN, 0.0, 5.0 )\n",
	"base.cinv": "y = base.cinv( 2.0, 4.0 )\nout = new Float64Array( 2 );\nv = base.cinv( out, 2.0, 4.0 )\nbool = ( v === out )\n",
	"base.cmul": "out = base.cmul( 5.0, 3.0, -2.0, 1.0 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.cmul( out, 5.0, 3.0, -2.0, 1.0 )\nbool = ( v === out )\n",
	"base.continuedFraction": "\n// Continued fraction for (e-1)^(-1):\nfunction closure() {\ni = 0;\nreturn function() {\ni++;\nreturn [ i, i ];\n};\n}\ngen = closure()\nout = base.continuedFraction( gen )\n\n// Using an ES6 generator:\nfunction* generator() {\ni = 0;\nwhile ( true ) {\ni++;\nyield [ i, i ];\n}\n}\ngen = generator();\nout = base.continuedFraction( gen )\n\n// Set options:\nout = base.continuedFraction( generator(), { 'keep': true } )\nout = base.continuedFraction( generator(), { 'maxIter': 10 } )\nout = base.continuedFraction( generator(), { 'tolerance': 1e-1 } )\n",
	"base.copysign": "z = base.copysign( -3.14, 10.0 )\nz = base.copysign( 3.14, -1.0 )\nz = base.copysign( 1.0, -0.0 )\nz = base.copysign( -3.14, -0.0 )\nz = base.copysign( -0.0, 1.0 )\n",
	"base.cos": "y = base.cos( 0.0 )\ny = base.cos( PI/4.0 )\ny = base.cos( -PI/6.0 )\ny = base.cos( NaN )\n",
	"base.cosh": "y = base.cosh( 0.0 )\ny = base.cosh( 2.0 )\ny = base.cosh( -2.0 )\ny = base.cosh( NaN )\n",
	"base.cosm1": "y = base.cosm1( 0.0 )\ny = base.cosm1( PI/4.0 )\ny = base.cosm1( -PI/6.0 )\ny = base.cosm1( NaN )\n",
	"base.cospi": "y = base.cospi( 0.0 )\ny = base.cospi( 0.5 )\ny = base.cospi( 0.1 )\ny = base.cospi( NaN )\n",
	"base.covercos": "y = base.covercos( 3.14 )\ny = base.covercos( -4.2 )\ny = base.covercos( -4.6 )\ny = base.covercos( 9.5 )\ny = base.covercos( -0.0 )\n",
	"base.coversin": "y = base.coversin( 3.14 )\ny = base.coversin( -4.2 )\ny = base.coversin( -4.6 )\ny = base.coversin( 9.5 )\ny = base.coversin( -0.0 )\n",
	"base.cphase": "phi = base.cphase( 5.0, 3.0 )\n",
	"base.cpolar": "out = base.cpolar( 5.0, 3.0 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.cpolar( out, 5.0, 3.0 )\nbool = ( v === out )\n",
	"base.cround": "out = base.cround( 5.5, 3.3 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.cround( out, 5.5, 3.3 )\nbool = ( v === out )\n",
	"base.csub": "out = base.csub( 5.0, 3.0, -2.0, 1.0 )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.csub( out, 5.0, 3.0, -2.0, 1.0 )\nbool = ( v === out )\n",
	"base.dasum": "\n// Standard usage:\nx = new Float64Array( [ -2.0, 1.0, 3.0, -5.0, 4.0, 0.0, -1.0, -3.0 ] );\nsum = base.dasum( x.length, x, 1 )\n\n// Sum every other value:\nN = base.floor( x.length / 2 );\nstride = 2;\nsum = base.dasum( N, x, stride )\n\n// Use view offset; e.g., starting at 2nd element:\nx0 = new Float64Array( [ 1.0, -2.0, 3.0, -4.0, 5.0, -6.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\nN = base.floor( x0.length / 2 );\nsum = base.dasum( N, x1, stride )\n",
	"base.daxpy": "\n// Standard usage:\nx = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0 ] );\ny = new Float64Array( [ 1.0, 1.0, 1.0, 1.0, 1.0 ] );\nalpha = 5.0;\nbase.daxpy( x.length, alpha, x, 1, y, 1 )\n\n// Using `N` and `stride` parameters:\nN = base.floor( x.length / 2 );\nbase.daxpy( N, alpha, x, 2, y, -1 )\n\n// Using view offsets:\nx0 = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float64Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float64Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.daxpy( N, 5.0, x1, -2, y1, 1 )\ny0\n",
	"base.dcopy": "\n// Standard usage:\nx = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0 ] );\ny = new Float64Array( [ 6.0, 7.0, 8.0, 9.0, 10.0 ] );\nbase.dcopy( x.length, x, 1, y, 1 )\n\n// Advanced indexing:\nx = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny = new Float64Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nN = base.floor( x.length / 2 );\nbase.dcopy( N, x, -2, y, 1 )\n\n// Using typed array views:\nx0 = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float64Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float64Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.dcopy( N, x1, -2, y1, 1 )\ny0\n",
	"base.deg2rad": "r = base.deg2rad( 90.0 )\nr = base.deg2rad( -45.0 )\nr = base.deg2rad( NaN )\n",
	"base.digamma": "y = base.digamma( -2.5 )\ny = base.digamma( 1.0 )\ny = base.digamma( 10.0 )\ny = base.digamma( NaN )\ny = base.digamma( -1.0 )\n",
	"base.diracDelta": "y = base.diracDelta( 3.14 )\ny = base.diracDelta( 0.0 )\n",
	"base.dists.arcsine.Arcsine": "arcsine = base.dists.arcsine.Arcsine( 0.0, 1.0 );\narcsine.a\narcsine.b\narcsine.entropy\narcsine.kurtosis\narcsine.mean\narcsine.median\narcsine.mode\narcsine.skewness\narcsine.stdev\narcsine.variance\narcsine.cdf( 0.8 )\narcsine.logcdf( 0.8 )\narcsine.logpdf( 1.0 )\narcsine.pdf( 0.8 )\narcsine.quantile( 0.8 )\n",
	"base.dists.arcsine.cdf": "y = base.dists.arcsine.cdf( 9.0, 0.0, 10.0 )\ny = base.dists.arcsine.cdf( 0.5, 0.0, 2.0 )\ny = base.dists.arcsine.cdf( PINF, 2.0, 4.0 )\ny = base.dists.arcsine.cdf( NINF, 2.0, 4.0 )\ny = base.dists.arcsine.cdf( NaN, 0.0, 1.0 )\ny = base.dists.arcsine.cdf( 0.0, NaN, 1.0 )\ny = base.dists.arcsine.cdf( 0.0, 0.0, NaN )\ny = base.dists.arcsine.cdf( 2.0, 1.0, 0.0 )\n",
	"base.dists.arcsine.entropy": "v = base.dists.arcsine.entropy( 0.0, 1.0 )\nv = base.dists.arcsine.entropy( 4.0, 12.0 )\nv = base.dists.arcsine.entropy( 2.0, 8.0 )\n",
	"base.dists.arcsine.kurtosis": "v = base.dists.arcsine.kurtosis( 0.0, 1.0 )\nv = base.dists.arcsine.kurtosis( 4.0, 12.0 )\nv = base.dists.arcsine.kurtosis( 2.0, 8.0 )\n",
	"base.dists.arcsine.logcdf": "y = base.dists.arcsine.logcdf( 9.0, 0.0, 10.0 )\ny = base.dists.arcsine.logcdf( 0.5, 0.0, 2.0 )\ny = base.dists.arcsine.logcdf( PINF, 2.0, 4.0 )\ny = base.dists.arcsine.logcdf( NINF, 2.0, 4.0 )\ny = base.dists.arcsine.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.arcsine.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.arcsine.logcdf( 0.0, 0.0, NaN )\ny = base.dists.arcsine.logcdf( 2.0, 1.0, 0.0 )\n",
	"base.dists.arcsine.logpdf": "y = base.dists.arcsine.logpdf( 2.0, 0.0, 4.0 )\ny = base.dists.arcsine.logpdf( 5.0, 0.0, 4.0 )\ny = base.dists.arcsine.logpdf( 0.25, 0.0, 1.0 )\ny = base.dists.arcsine.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.arcsine.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.arcsine.logpdf( 0.0, 0.0, NaN )\ny = base.dists.arcsine.logpdf( 2.0, 3.0, 1.0 )\n",
	"base.dists.arcsine.mean": "v = base.dists.arcsine.mean( 0.0, 1.0 )\nv = base.dists.arcsine.mean( 4.0, 12.0 )\nv = base.dists.arcsine.mean( 2.0, 8.0 )\n",
	"base.dists.arcsine.median": "v = base.dists.arcsine.median( 0.0, 1.0 )\nv = base.dists.arcsine.median( 4.0, 12.0 )\nv = base.dists.arcsine.median( 2.0, 8.0 )\n",
	"base.dists.arcsine.mode": "v = base.dists.arcsine.mode( 0.0, 1.0 )\nv = base.dists.arcsine.mode( 4.0, 12.0 )\nv = base.dists.arcsine.mode( 2.0, 8.0 )\n",
	"base.dists.arcsine.pdf": "y = base.dists.arcsine.pdf( 2.0, 0.0, 4.0 )\ny = base.dists.arcsine.pdf( 5.0, 0.0, 4.0 )\ny = base.dists.arcsine.pdf( 0.25, 0.0, 1.0 )\ny = base.dists.arcsine.pdf( NaN, 0.0, 1.0 )\ny = base.dists.arcsine.pdf( 0.0, NaN, 1.0 )\ny = base.dists.arcsine.pdf( 0.0, 0.0, NaN )\ny = base.dists.arcsine.pdf( 2.0, 3.0, 1.0 )\n",
	"base.dists.arcsine.quantile": "y = base.dists.arcsine.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.arcsine.quantile( 0.5, 0.0, 10.0 )\ny = base.dists.arcsine.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.arcsine.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.arcsine.quantile( NaN, 0.0, 1.0 )\ny = base.dists.arcsine.quantile( 0.0, NaN, 1.0 )\ny = base.dists.arcsine.quantile( 0.0, 0.0, NaN )\ny = base.dists.arcsine.quantile( 0.5, 2.0, 1.0 )\n",
	"base.dists.arcsine.skewness": "v = base.dists.arcsine.skewness( 0.0, 1.0 )\nv = base.dists.arcsine.skewness( 4.0, 12.0 )\nv = base.dists.arcsine.skewness( 2.0, 8.0 )\n",
	"base.dists.arcsine.stdev": "v = base.dists.arcsine.stdev( 0.0, 1.0 )\nv = base.dists.arcsine.stdev( 4.0, 12.0 )\nv = base.dists.arcsine.stdev( 2.0, 8.0 )\n",
	"base.dists.arcsine.variance": "v = base.dists.arcsine.variance( 0.0, 1.0 )\nv = base.dists.arcsine.variance( 4.0, 12.0 )\nv = base.dists.arcsine.variance( 2.0, 8.0 )\n",
	"base.dists.beta.Beta": "beta = base.dists.beta.Beta( 1.0, 1.0 );\nbeta.alpha\nbeta.beta\nbeta.entropy\nbeta.kurtosis\nbeta.mean\nbeta.median\nbeta.mode\nbeta.skewness\nbeta.stdev\nbeta.variance\nbeta.cdf( 0.8 )\nbeta.logcdf( 0.8 )\nbeta.logpdf( 1.0 )\nbeta.mgf( 3.14 )\nbeta.pdf( 1.0 )\nbeta.quantile( 0.8 )\n",
	"base.dists.beta.cdf": "y = base.dists.beta.cdf( 0.5, 1.0, 1.0 )\ny = base.dists.beta.cdf( 0.5, 2.0, 4.0 )\ny = base.dists.beta.cdf( 0.2, 2.0, 2.0 )\ny = base.dists.beta.cdf( 0.8, 4.0, 4.0 )\ny = base.dists.beta.cdf( -0.5, 4.0, 2.0 )\ny = base.dists.beta.cdf( 1.5, 4.0, 2.0 )\ny = base.dists.beta.cdf( 2.0, -1.0, 0.5 )\ny = base.dists.beta.cdf( 2.0, 0.5, -1.0 )\ny = base.dists.beta.cdf( NaN, 1.0, 1.0 )\ny = base.dists.beta.cdf( 0.0, NaN, 1.0 )\ny = base.dists.beta.cdf( 0.0, 1.0, NaN )\n",
	"base.dists.beta.entropy": "v = base.dists.beta.entropy( 1.0, 1.0 )\nv = base.dists.beta.entropy( 4.0, 12.0 )\nv = base.dists.beta.entropy( 8.0, 2.0 )\nv = base.dists.beta.entropy( 1.0, -0.1 )\nv = base.dists.beta.entropy( -0.1, 1.0 )\nv = base.dists.beta.entropy( 2.0, NaN )\nv = base.dists.beta.entropy( NaN, 2.0 )\n",
	"base.dists.beta.kurtosis": "v = base.dists.beta.kurtosis( 1.0, 1.0 )\nv = base.dists.beta.kurtosis( 4.0, 12.0 )\nv = base.dists.beta.kurtosis( 8.0, 2.0 )\nv = base.dists.beta.kurtosis( 1.0, -0.1 )\nv = base.dists.beta.kurtosis( -0.1, 1.0 )\nv = base.dists.beta.kurtosis( 2.0, NaN )\nv = base.dists.beta.kurtosis( NaN, 2.0 )\n",
	"base.dists.beta.logcdf": "y = base.dists.beta.logcdf( 0.5, 1.0, 1.0 )\ny = base.dists.beta.logcdf( 0.5, 2.0, 4.0 )\ny = base.dists.beta.logcdf( 0.2, 2.0, 2.0 )\ny = base.dists.beta.logcdf( 0.8, 4.0, 4.0 )\ny = base.dists.beta.logcdf( -0.5, 4.0, 2.0 )\ny = base.dists.beta.logcdf( 1.5, 4.0, 2.0 )\ny = base.dists.beta.logcdf( 2.0, -1.0, 0.5 )\ny = base.dists.beta.logcdf( 2.0, 0.5, -1.0 )\ny = base.dists.beta.logcdf( NaN, 1.0, 1.0 )\ny = base.dists.beta.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.beta.logcdf( 0.0, 1.0, NaN )\n",
	"base.dists.beta.logpdf": "y = base.dists.beta.logpdf( 0.5, 1.0, 1.0 )\ny = base.dists.beta.logpdf( 0.5, 2.0, 4.0 )\ny = base.dists.beta.logpdf( 0.2, 2.0, 2.0 )\ny = base.dists.beta.logpdf( 0.8, 4.0, 4.0 )\ny = base.dists.beta.logpdf( -0.5, 4.0, 2.0 )\ny = base.dists.beta.logpdf( 1.5, 4.0, 2.0 )\ny = base.dists.beta.logpdf( 0.5, -1.0, 0.5 )\ny = base.dists.beta.logpdf( 0.5, 0.5, -1.0 )\ny = base.dists.beta.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.beta.logpdf( 0.5, NaN, 1.0 )\ny = base.dists.beta.logpdf( 0.5, 1.0, NaN )\n",
	"base.dists.beta.mean": "v = base.dists.beta.mean( 1.0, 1.0 )\nv = base.dists.beta.mean( 4.0, 12.0 )\nv = base.dists.beta.mean( 8.0, 2.0 )\n",
	"base.dists.beta.median": "v = base.dists.beta.median( 1.0, 1.0 )\nv = base.dists.beta.median( 4.0, 12.0 )\nv = base.dists.beta.median( 8.0, 2.0 )\nv = base.dists.beta.median( 1.0, -0.1 )\nv = base.dists.beta.median( -0.1, 1.0 )\nv = base.dists.beta.median( 2.0, NaN )\nv = base.dists.beta.median( NaN, 2.0 )\n",
	"base.dists.beta.mgf": "y = base.dists.beta.mgf( 0.5, 1.0, 1.0 )\ny = base.dists.beta.mgf( 0.5, 2.0, 4.0 )\ny = base.dists.beta.mgf( 3.0, 2.0, 2.0 )\ny = base.dists.beta.mgf( -0.8, 4.0, 4.0 )\ny = base.dists.beta.mgf( NaN, 1.0, 1.0 )\ny = base.dists.beta.mgf( 0.0, NaN, 1.0 )\ny = base.dists.beta.mgf( 0.0, 1.0, NaN )\ny = base.dists.beta.mgf( 2.0, -1.0, 0.5 )\ny = base.dists.beta.mgf( 2.0, 0.0, 0.5 )\ny = base.dists.beta.mgf( 2.0, 0.5, -1.0 )\ny = base.dists.beta.mgf( 2.0, 0.5, 0.0 )\n",
	"base.dists.beta.mode": "v = base.dists.beta.mode( 4.0, 12.0 )\nv = base.dists.beta.mode( 8.0, 2.0 )\nv = base.dists.beta.mode( 1.0, 1.0 )\n",
	"base.dists.beta.pdf": "y = base.dists.beta.pdf( 0.5, 1.0, 1.0 )\ny = base.dists.beta.pdf( 0.5, 2.0, 4.0 )\ny = base.dists.beta.pdf( 0.2, 2.0, 2.0 )\ny = base.dists.beta.pdf( 0.8, 4.0, 4.0 )\ny = base.dists.beta.pdf( -0.5, 4.0, 2.0 )\ny = base.dists.beta.pdf( 1.5, 4.0, 2.0 )\ny = base.dists.beta.pdf( 0.5, -1.0, 0.5 )\ny = base.dists.beta.pdf( 0.5, 0.5, -1.0 )\ny = base.dists.beta.pdf( NaN, 1.0, 1.0 )\ny = base.dists.beta.pdf( 0.5, NaN, 1.0 )\ny = base.dists.beta.pdf( 0.5, 1.0, NaN )\n",
	"base.dists.beta.quantile": "y = base.dists.beta.quantile( 0.8, 2.0, 1.0 )\ny = base.dists.beta.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.beta.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.beta.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.beta.quantile( NaN, 1.0, 1.0 )\ny = base.dists.beta.quantile( 0.5, NaN, 1.0 )\ny = base.dists.beta.quantile( 0.5, 1.0, NaN )\ny = base.dists.beta.quantile( 0.5, -1.0, 1.0 )\ny = base.dists.beta.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.beta.skewness": "v = base.dists.beta.skewness( 1.0, 1.0 )\nv = base.dists.beta.skewness( 4.0, 12.0 )\nv = base.dists.beta.skewness( 8.0, 2.0 )\nv = base.dists.beta.skewness( 1.0, -0.1 )\nv = base.dists.beta.skewness( -0.1, 1.0 )\nv = base.dists.beta.skewness( 2.0, NaN )\nv = base.dists.beta.skewness( NaN, 2.0 )\n",
	"base.dists.beta.stdev": "v = base.dists.beta.stdev( 1.0, 1.0 )\nv = base.dists.beta.stdev( 4.0, 12.0 )\nv = base.dists.beta.stdev( 8.0, 2.0 )\nv = base.dists.beta.stdev( 1.0, -0.1 )\nv = base.dists.beta.stdev( -0.1, 1.0 )\nv = base.dists.beta.stdev( 2.0, NaN )\nv = base.dists.beta.stdev( NaN, 2.0 )\n",
	"base.dists.beta.variance": "v = base.dists.beta.variance( 1.0, 1.0 )\nv = base.dists.beta.variance( 4.0, 12.0 )\nv = base.dists.beta.variance( 8.0, 2.0 )\nv = base.dists.beta.variance( 1.0, -0.1 )\nv = base.dists.beta.variance( -0.1, 1.0 )\nv = base.dists.beta.variance( 2.0, NaN )\nv = base.dists.beta.variance( NaN, 2.0 )\n",
	"base.dists.betaprime.BetaPrime": "betaprime = base.dists.betaprime.BetaPrime( 6.0, 5.0 );\nbetaprime.alpha\nbetaprime.beta\nbetaprime.kurtosis\nbetaprime.mean\nbetaprime.mode\nbetaprime.skewness\nbetaprime.stdev\nbetaprime.variance\nbetaprime.cdf( 0.8 )\nbetaprime.logcdf( 0.8 )\nbetaprime.logpdf( 1.0 )\nbetaprime.pdf( 1.0 )\nbetaprime.quantile( 0.8 )\n",
	"base.dists.betaprime.cdf": "y = base.dists.betaprime.cdf( 0.5, 1.0, 1.0 )\ny = base.dists.betaprime.cdf( 0.5, 2.0, 4.0 )\ny = base.dists.betaprime.cdf( 0.2, 2.0, 2.0 )\ny = base.dists.betaprime.cdf( 0.8, 4.0, 4.0 )\ny = base.dists.betaprime.cdf( -0.5, 4.0, 2.0 )\ny = base.dists.betaprime.cdf( 2.0, -1.0, 0.5 )\ny = base.dists.betaprime.cdf( 2.0, 0.5, -1.0 )\ny = base.dists.betaprime.cdf( NaN, 1.0, 1.0 )\ny = base.dists.betaprime.cdf( 0.0, NaN, 1.0 )\ny = base.dists.betaprime.cdf( 0.0, 1.0, NaN )\n",
	"base.dists.betaprime.kurtosis": "v = base.dists.betaprime.kurtosis( 2.0, 6.0 )\nv = base.dists.betaprime.kurtosis( 4.0, 12.0 )\nv = base.dists.betaprime.kurtosis( 8.0, 6.0 )\nv = base.dists.betaprime.kurtosis( 1.0, 2.8 )\nv = base.dists.betaprime.kurtosis( 1.0, -0.1 )\nv = base.dists.betaprime.kurtosis( -0.1, 5.0 )\nv = base.dists.betaprime.kurtosis( 2.0, NaN )\nv = base.dists.betaprime.kurtosis( NaN, 6.0 )\n",
	"base.dists.betaprime.logcdf": "y = base.dists.betaprime.logcdf( 0.5, 1.0, 1.0 )\ny = base.dists.betaprime.logcdf( 0.5, 2.0, 4.0 )\ny = base.dists.betaprime.logcdf( 0.2, 2.0, 2.0 )\ny = base.dists.betaprime.logcdf( 0.8, 4.0, 4.0 )\ny = base.dists.betaprime.logcdf( -0.5, 4.0, 2.0 )\ny = base.dists.betaprime.logcdf( 2.0, -1.0, 0.5 )\ny = base.dists.betaprime.logcdf( 2.0, 0.5, -1.0 )\ny = base.dists.betaprime.logcdf( NaN, 1.0, 1.0 )\ny = base.dists.betaprime.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.betaprime.logcdf( 0.0, 1.0, NaN )\n",
	"base.dists.betaprime.logpdf": "y = base.dists.betaprime.logpdf( 0.5, 1.0, 1.0 )\ny = base.dists.betaprime.logpdf( 0.5, 2.0, 4.0 )\ny = base.dists.betaprime.logpdf( 0.2, 2.0, 2.0 )\ny = base.dists.betaprime.logpdf( 0.8, 4.0, 4.0 )\ny = base.dists.betaprime.logpdf( -0.5, 4.0, 2.0 )\ny = base.dists.betaprime.logpdf( 0.5, -1.0, 0.5 )\ny = base.dists.betaprime.logpdf( 0.5, 0.5, -1.0 )\ny = base.dists.betaprime.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.betaprime.logpdf( 0.5, NaN, 1.0 )\ny = base.dists.betaprime.logpdf( 0.5, 1.0, NaN )\n",
	"base.dists.betaprime.mean": "v = base.dists.betaprime.mean( 1.0, 2.0 )\nv = base.dists.betaprime.mean( 4.0, 12.0 )\nv = base.dists.betaprime.mean( 8.0, 2.0 )\n",
	"base.dists.betaprime.mode": "v = base.dists.betaprime.mode( 1.0, 2.0 )\nv = base.dists.betaprime.mode( 4.0, 12.0 )\nv = base.dists.betaprime.mode( 8.0, 2.0 )\n",
	"base.dists.betaprime.pdf": "y = base.dists.betaprime.pdf( 0.5, 1.0, 1.0 )\ny = base.dists.betaprime.pdf( 0.5, 2.0, 4.0 )\ny = base.dists.betaprime.pdf( 0.2, 2.0, 2.0 )\ny = base.dists.betaprime.pdf( 0.8, 4.0, 4.0 )\ny = base.dists.betaprime.pdf( -0.5, 4.0, 2.0 )\ny = base.dists.betaprime.pdf( 0.5, -1.0, 0.5 )\ny = base.dists.betaprime.pdf( 0.5, 0.5, -1.0 )\ny = base.dists.betaprime.pdf( NaN, 1.0, 1.0 )\ny = base.dists.betaprime.pdf( 0.5, NaN, 1.0 )\ny = base.dists.betaprime.pdf( 0.5, 1.0, NaN )\n",
	"base.dists.betaprime.quantile": "y = base.dists.betaprime.quantile( 0.8, 2.0, 1.0 )\ny = base.dists.betaprime.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.betaprime.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.betaprime.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.betaprime.quantile( NaN, 1.0, 1.0 )\ny = base.dists.betaprime.quantile( 0.5, NaN, 1.0 )\ny = base.dists.betaprime.quantile( 0.5, 1.0, NaN )\ny = base.dists.betaprime.quantile( 0.5, -1.0, 1.0 )\ny = base.dists.betaprime.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.betaprime.skewness": "v = base.dists.betaprime.skewness( 2.0, 4.0 )\nv = base.dists.betaprime.skewness( 4.0, 12.0 )\nv = base.dists.betaprime.skewness( 8.0, 4.0 )\nv = base.dists.betaprime.skewness( 1.0, 2.8 )\nv = base.dists.betaprime.skewness( 1.0, -0.1 )\nv = base.dists.betaprime.skewness( -0.1, 4.0 )\nv = base.dists.betaprime.skewness( 2.0, NaN )\nv = base.dists.betaprime.skewness( NaN, 4.0 )\n",
	"base.dists.betaprime.stdev": "v = base.dists.betaprime.stdev( 1.0, 2.5 )\nv = base.dists.betaprime.stdev( 4.0, 12.0 )\nv = base.dists.betaprime.stdev( 8.0, 2.5 )\nv = base.dists.betaprime.stdev( 8.0, 1.0 )\nv = base.dists.betaprime.stdev( 1.0, -0.1 )\nv = base.dists.betaprime.stdev( -0.1, 3.0 )\nv = base.dists.betaprime.stdev( 2.0, NaN )\nv = base.dists.betaprime.stdev( NaN, 3.0 )\n",
	"base.dists.betaprime.variance": "v = base.dists.betaprime.variance( 1.0, 2.5 )\nv = base.dists.betaprime.variance( 4.0, 12.0 )\nv = base.dists.betaprime.variance( 8.0, 2.5 )\nv = base.dists.betaprime.variance( 8.0, 1.0 )\nv = base.dists.betaprime.variance( 1.0, -0.1 )\nv = base.dists.betaprime.variance( -0.1, 3.0 )\nv = base.dists.betaprime.variance( 2.0, NaN )\nv = base.dists.betaprime.variance( NaN, 3.0 )\n",
	"base.dists.binomial.Binomial": "binomial = base.dists.binomial.Binomial( 8, 0.5 );\nbinomial.n\nbinomial.p\nbinomial.kurtosis\nbinomial.mean\nbinomial.median\nbinomial.mode\nbinomial.skewness\nbinomial.stdev\nbinomial.variance\nbinomial.cdf( 2.9 )\nbinomial.logpmf( 3.0 )\nbinomial.mgf( 0.2 )\nbinomial.pmf( 3.0 )\nbinomial.quantile( 0.8 )\n",
	"base.dists.binomial.cdf": "y = base.dists.binomial.cdf( 3.0, 20, 0.2 )\ny = base.dists.binomial.cdf( 21.0, 20, 0.2 )\ny = base.dists.binomial.cdf( 5.0, 10, 0.4 )\ny = base.dists.binomial.cdf( 0.0, 10, 0.4 )\ny = base.dists.binomial.cdf( NaN, 20, 0.5 )\ny = base.dists.binomial.cdf( 0.0, NaN, 0.5 )\ny = base.dists.binomial.cdf( 0.0, 20, NaN )\ny = base.dists.binomial.cdf( 2.0, 1.5, 0.5 )\ny = base.dists.binomial.cdf( 2.0, -2.0, 0.5 )\ny = base.dists.binomial.cdf( 2.0, 20, -1.0 )\ny = base.dists.binomial.cdf( 2.0, 20, 1.5 )\n",
	"base.dists.binomial.entropy": "v = base.dists.binomial.entropy( 100, 0.1 )\nv = base.dists.binomial.entropy( 20, 0.5 )\nv = base.dists.binomial.entropy( 10.3, 0.5 )\nv = base.dists.binomial.entropy( 20, 1.1 )\nv = base.dists.binomial.entropy( 20, NaN )\n",
	"base.dists.binomial.kurtosis": "v = base.dists.binomial.kurtosis( 100, 0.1 )\nv = base.dists.binomial.kurtosis( 20, 0.5 )\nv = base.dists.binomial.kurtosis( 10.3, 0.5 )\nv = base.dists.binomial.kurtosis( 20, 1.1 )\nv = base.dists.binomial.kurtosis( 20, NaN )\n",
	"base.dists.binomial.logpmf": "y = base.dists.binomial.logpmf( 3.0, 20, 0.2 )\ny = base.dists.binomial.logpmf( 21.0, 20, 0.2 )\ny = base.dists.binomial.logpmf( 5.0, 10, 0.4 )\ny = base.dists.binomial.logpmf( 0.0, 10, 0.4 )\ny = base.dists.binomial.logpmf( NaN, 20, 0.5 )\ny = base.dists.binomial.logpmf( 0.0, NaN, 0.5 )\ny = base.dists.binomial.logpmf( 0.0, 20, NaN )\ny = base.dists.binomial.logpmf( 2.0, 1.5, 0.5 )\ny = base.dists.binomial.logpmf( 2.0, -2.0, 0.5 )\ny = base.dists.binomial.logpmf( 2.0, 20, -1.0 )\ny = base.dists.binomial.logpmf( 2.0, 20, 1.5 )\n",
	"base.dists.binomial.mean": "v = base.dists.binomial.mean( 100, 0.1 )\nv = base.dists.binomial.mean( 20, 0.5 )\nv = base.dists.binomial.mean( 10.3, 0.5 )\nv = base.dists.binomial.mean( 20, 1.1 )\nv = base.dists.binomial.mean( 20, NaN )\n",
	"base.dists.binomial.median": "v = base.dists.binomial.median( 100, 0.1 )\nv = base.dists.binomial.median( 20, 0.5 )\nv = base.dists.binomial.median( 10.3, 0.5 )\nv = base.dists.binomial.median( 20, 1.1 )\nv = base.dists.binomial.median( 20, NaN )\n",
	"base.dists.binomial.mgf": "y = base.dists.binomial.mgf( 0.5, 20, 0.2 )\ny = base.dists.binomial.mgf( 5.0, 20, 0.2 )\ny = base.dists.binomial.mgf( 0.9, 10, 0.4 )\ny = base.dists.binomial.mgf( 0.0, 10, 0.4 )\ny = base.dists.binomial.mgf( NaN, 20, 0.5 )\ny = base.dists.binomial.mgf( 0.0, NaN, 0.5 )\ny = base.dists.binomial.mgf( 0.0, 20, NaN )\ny = base.dists.binomial.mgf( 2.0, 1.5, 0.5 )\ny = base.dists.binomial.mgf( 2.0, -2.0, 0.5 )\ny = base.dists.binomial.mgf( 2.0, 20, -1.0 )\ny = base.dists.binomial.mgf( 2.0, 20, 1.5 )\n",
	"base.dists.binomial.mode": "v = base.dists.binomial.mode( 100, 0.1 )\nv = base.dists.binomial.mode( 20, 0.5 )\nv = base.dists.binomial.mode( 10.3, 0.5 )\nv = base.dists.binomial.mode( 20, 1.1 )\nv = base.dists.binomial.mode( 20, NaN )\n",
	"base.dists.binomial.pmf": "y = base.dists.binomial.pmf( 3.0, 20, 0.2 )\ny = base.dists.binomial.pmf( 21.0, 20, 0.2 )\ny = base.dists.binomial.pmf( 5.0, 10, 0.4 )\ny = base.dists.binomial.pmf( 0.0, 10, 0.4 )\ny = base.dists.binomial.pmf( NaN, 20, 0.5 )\ny = base.dists.binomial.pmf( 0.0, NaN, 0.5 )\ny = base.dists.binomial.pmf( 0.0, 20, NaN )\ny = base.dists.binomial.pmf( 2.0, 1.5, 0.5 )\ny = base.dists.binomial.pmf( 2.0, -2.0, 0.5 )\ny = base.dists.binomial.pmf( 2.0, 20, -1.0 )\ny = base.dists.binomial.pmf( 2.0, 20, 1.5 )\n",
	"base.dists.binomial.quantile": "y = base.dists.binomial.quantile( 0.4, 20, 0.2 )\ny = base.dists.binomial.quantile( 0.8, 20, 0.2 )\ny = base.dists.binomial.quantile( 0.5, 10, 0.4 )\ny = base.dists.binomial.quantile( 0.0, 10, 0.4 )\ny = base.dists.binomial.quantile( 1.0, 10, 0.4 )\ny = base.dists.binomial.quantile( NaN, 20, 0.5 )\ny = base.dists.binomial.quantile( 0.2, NaN, 0.5 )\ny = base.dists.binomial.quantile( 0.2, 20, NaN )\ny = base.dists.binomial.quantile( 0.5, 1.5, 0.5 )\ny = base.dists.binomial.quantile( 0.5, -2.0, 0.5 )\ny = base.dists.binomial.quantile( 0.5, 20, -1.0 )\ny = base.dists.binomial.quantile( 0.5, 20, 1.5 )\n",
	"base.dists.binomial.skewness": "v = base.dists.binomial.skewness( 100, 0.1 )\nv = base.dists.binomial.skewness( 20, 0.5 )\nv = base.dists.binomial.skewness( 10.3, 0.5 )\nv = base.dists.binomial.skewness( 20, 1.1 )\nv = base.dists.binomial.skewness( 20, NaN )\n",
	"base.dists.binomial.stdev": "v = base.dists.binomial.stdev( 100, 0.1 )\nv = base.dists.binomial.stdev( 20, 0.5 )\nv = base.dists.binomial.stdev( 10.3, 0.5 )\nv = base.dists.binomial.stdev( 20, 1.1 )\nv = base.dists.binomial.stdev( 20, NaN )\n",
	"base.dists.binomial.variance": "v = base.dists.binomial.variance( 100, 0.1 )\nv = base.dists.binomial.variance( 20, 0.5 )\nv = base.dists.binomial.variance( 10.3, 0.5 )\nv = base.dists.binomial.variance( 20, 1.1 )\nv = base.dists.binomial.variance( 20, NaN )\n",
	"base.dists.cauchy.Cauchy": "cauchy = base.dists.cauchy.Cauchy( 0.0, 1.0 );\ncauchy.x0\ncauchy.gamma\ncauchy.entropy\ncauchy.median\ncauchy.mode\ncauchy.cdf( 0.8 )\ncauchy.logcdf( 1.0 )\ncauchy.logpdf( 1.0 )\ncauchy.pdf( 1.0 )\ncauchy.quantile( 0.8 )\n",
	"base.dists.cauchy.cdf": "y = base.dists.cauchy.cdf( 4.0, 0.0, 2.0 )\ny = base.dists.cauchy.cdf( 1.0, 0.0, 2.0 )\ny = base.dists.cauchy.cdf( 1.0, 3.0, 2.0 )\ny = base.dists.cauchy.cdf( NaN, 0.0, 2.0 )\ny = base.dists.cauchy.cdf( 1.0, 2.0, NaN )\ny = base.dists.cauchy.cdf( 1.0, NaN, 3.0 )\n",
	"base.dists.cauchy.entropy": "v = base.dists.cauchy.entropy( 10.0, 7.0 )\nv = base.dists.cauchy.entropy( 22.0, 0.5 )\nv = base.dists.cauchy.entropy( 10.3, -0.5 )\n",
	"base.dists.cauchy.logcdf": "y = base.dists.cauchy.logcdf( 4.0, 0.0, 2.0 )\ny = base.dists.cauchy.logcdf( 1.0, 0.0, 2.0 )\ny = base.dists.cauchy.logcdf( 1.0, 3.0, 2.0 )\ny = base.dists.cauchy.logcdf( NaN, 0.0, 2.0 )\ny = base.dists.cauchy.logcdf( 1.0, 2.0, NaN )\ny = base.dists.cauchy.logcdf( 1.0, NaN, 3.0 )\n",
	"base.dists.cauchy.logpdf": "y = base.dists.cauchy.logpdf( 2.0, 1.0, 1.0 )\ny = base.dists.cauchy.logpdf( 4.0, 3.0, 0.1 )\ny = base.dists.cauchy.logpdf( 4.0, 3.0, 3.0 )\ny = base.dists.cauchy.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.cauchy.logpdf( 2.0, NaN, 1.0 )\ny = base.dists.cauchy.logpdf( 2.0, 1.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cauchy.logpdf( 2.0, 1.0, -2.0 )\n",
	"base.dists.cauchy.median": "v = base.dists.cauchy.median( 10.0, 5.0 )\nv = base.dists.cauchy.median( 7.0, 0.5 )\nv = base.dists.cauchy.median( 10.3, -0.5 )\n",
	"base.dists.cauchy.mode": "v = base.dists.cauchy.mode( 10.0, 5.0 )\nv = base.dists.cauchy.mode( 7.0, 0.5 )\nv = base.dists.cauchy.mode( 10.3, -0.5 )\n",
	"base.dists.cauchy.pdf": "y = base.dists.cauchy.pdf( 2.0, 1.0, 1.0 )\ny = base.dists.cauchy.pdf( 4.0, 3.0, 0.1 )\ny = base.dists.cauchy.pdf( 4.0, 3.0, 3.0 )\ny = base.dists.cauchy.pdf( NaN, 1.0, 1.0 )\ny = base.dists.cauchy.pdf( 2.0, NaN, 1.0 )\ny = base.dists.cauchy.pdf( 2.0, 1.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cauchy.pdf( 2.0, 1.0, -2.0 )\n",
	"base.dists.cauchy.quantile": "y = base.dists.cauchy.quantile( 0.3, 2.0, 2.0 )\ny = base.dists.cauchy.quantile( 0.8, 10, 2.0 )\ny = base.dists.cauchy.quantile( 0.1, 10.0, 2.0 )\ny = base.dists.cauchy.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.cauchy.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.cauchy.quantile( NaN, 0.0, 1.0 )\ny = base.dists.cauchy.quantile( 0.0, NaN, 1.0 )\ny = base.dists.cauchy.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cauchy.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.chi.cdf": "y = base.dists.chi.cdf( 2.0, 3.0 )\ny = base.dists.chi.cdf( 1.0, 0.5 )\ny = base.dists.chi.cdf( -1.0, 4.0 )\ny = base.dists.chi.cdf( NaN, 1.0 )\ny = base.dists.chi.cdf( 0.0, NaN )\n\n// Negative degrees of freedom:\ny = base.dists.chi.cdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chi.cdf( 2.0, 0.0 )\ny = base.dists.chi.cdf( -2.0, 0.0 )\ny = base.dists.chi.cdf( 0.0, 0.0 )\n",
	"base.dists.chi.Chi": "chi = base.dists.chi.Chi( 6.0 );\nchi.k\nchi.entropy\nchi.kurtosis\nchi.mean\nchi.mode\nchi.skewness\nchi.stdev\nchi.variance\nchi.cdf( 1.0 )\nchi.logpdf( 1.5 )\nchi.pdf( 1.5 )\nchi.quantile( 0.5 )\n",
	"base.dists.chi.entropy": "v = base.dists.chi.entropy( 11.0 )\nv = base.dists.chi.entropy( 1.5 )\n",
	"base.dists.chi.kurtosis": "v = base.dists.chi.kurtosis( 9.0 )\nv = base.dists.chi.kurtosis( 1.5 )\n",
	"base.dists.chi.logpdf": "y = base.dists.chi.logpdf( 0.3, 4.0 )\ny = base.dists.chi.logpdf( 0.7, 0.7 )\ny = base.dists.chi.logpdf( -1.0, 0.5 )\ny = base.dists.chi.logpdf( 0.0, NaN )\ny = base.dists.chi.logpdf( NaN, 2.0 )\n\n// Negative degrees of freedom:\ny = base.dists.chi.logpdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chi.logpdf( 2.0, 0.0, 2.0 )\ny = base.dists.chi.logpdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.chi.mean": "v = base.dists.chi.mean( 11.0 )\nv = base.dists.chi.mean( 4.5 )\n",
	"base.dists.chi.mode": "v = base.dists.chi.mode( 11.0 )\nv = base.dists.chi.mode( 1.5 )\n",
	"base.dists.chi.pdf": "y = base.dists.chi.pdf( 0.3, 4.0 )\ny = base.dists.chi.pdf( 0.7, 0.7 )\ny = base.dists.chi.pdf( -1.0, 0.5 )\ny = base.dists.chi.pdf( 0.0, NaN )\ny = base.dists.chi.pdf( NaN, 2.0 )\n\n// Negative degrees of freedom:\ny = base.dists.chi.pdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chi.pdf( 2.0, 0.0, 2.0 )\ny = base.dists.chi.pdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.chi.quantile": "y = base.dists.chi.quantile( 0.8, 1.0 )\ny = base.dists.chi.quantile( 0.5, 4.0 )\ny = base.dists.chi.quantile( 0.8, 0.1 )\ny = base.dists.chi.quantile( -0.2, 0.5 )\ny = base.dists.chi.quantile( 1.1, 0.5 )\ny = base.dists.chi.quantile( NaN, 1.0 )\ny = base.dists.chi.quantile( 0.0, NaN )\n\n// Negative degrees of freedom:\ny = base.dists.chi.quantile( 0.5, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chi.quantile( 0.3, 0.0 )\ny = base.dists.chi.quantile( 0.9, 0.0 )\n",
	"base.dists.chi.skewness": "v = base.dists.chi.skewness( 11.0 )\nv = base.dists.chi.skewness( 1.5 )\n",
	"base.dists.chi.stdev": "v = base.dists.chi.stdev( 11.0 )\nv = base.dists.chi.stdev( 1.5 )\n",
	"base.dists.chi.variance": "v = base.dists.chi.variance( 11.0 )\nv = base.dists.chi.variance( 1.5 )\n",
	"base.dists.chisquare.cdf": "y = base.dists.chisquare.cdf( 2.0, 3.0 )\ny = base.dists.chisquare.cdf( 1.0, 0.5 )\ny = base.dists.chisquare.cdf( -1.0, 4.0 )\ny = base.dists.chisquare.cdf( NaN, 1.0 )\ny = base.dists.chisquare.cdf( 0.0, NaN )\n\n// Negative degrees of freedom:\ny = base.dists.chisquare.cdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chisquare.cdf( 2.0, 0.0 )\ny = base.dists.chisquare.cdf( -2.0, 0.0 )\ny = base.dists.chisquare.cdf( 0.0, 0.0 )\n",
	"base.dists.chisquare.ChiSquare": "chisquare = base.dists.chisquare.ChiSquare( 6.0 );\nchisquare.k\nchisquare.entropy\nchisquare.kurtosis\nchisquare.mean\nchisquare.mode\nchisquare.skewness\nchisquare.stdev\nchisquare.variance\nchisquare.cdf( 3.0 )\nchisquare.mgf( 0.2 )\nchisquare.pdf( 1.5 )\nchisquare.quantile( 0.5 )\n",
	"base.dists.chisquare.entropy": "v = base.dists.chisquare.entropy( 11.0 )\nv = base.dists.chisquare.entropy( 1.5 )\n",
	"base.dists.chisquare.kurtosis": "v = base.dists.chisquare.kurtosis( 9.0 )\nv = base.dists.chisquare.kurtosis( 1.5 )\n",
	"base.dists.chisquare.logpdf": "y = base.dists.chisquare.logpdf( 0.3, 4.0 )\ny = base.dists.chisquare.logpdf( 0.7, 0.7 )\ny = base.dists.chisquare.logpdf( -1.0, 0.5 )\ny = base.dists.chisquare.logpdf( 0.0, NaN )\ny = base.dists.chisquare.logpdf( NaN, 2.0 )\n\n// Negative degrees of freedom:\ny = base.dists.chisquare.logpdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chisquare.logpdf( 2.0, 0.0, 2.0 )\ny = base.dists.chisquare.logpdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.chisquare.mean": "v = base.dists.chisquare.mean( 11.0 )\nv = base.dists.chisquare.mean( 4.5 )\n",
	"base.dists.chisquare.mode": "v = base.dists.chisquare.mode( 11.0 )\nv = base.dists.chisquare.mode( 1.5 )\n",
	"base.dists.chisquare.pdf": "y = base.dists.chisquare.pdf( 0.3, 4.0 )\ny = base.dists.chisquare.pdf( 0.7, 0.7 )\ny = base.dists.chisquare.pdf( -1.0, 0.5 )\ny = base.dists.chisquare.pdf( 0.0, NaN )\ny = base.dists.chisquare.pdf( NaN, 2.0 )\n\n// Negative degrees of freedom:\ny = base.dists.chisquare.pdf( 2.0, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chisquare.pdf( 2.0, 0.0, 2.0 )\ny = base.dists.chisquare.pdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.chisquare.quantile": "y = base.dists.chisquare.quantile( 0.8, 1.0 )\ny = base.dists.chisquare.quantile( 0.5, 4.0 )\ny = base.dists.chisquare.quantile( 0.8, 0.1 )\ny = base.dists.chisquare.quantile( -0.2, 0.5 )\ny = base.dists.chisquare.quantile( 1.1, 0.5 )\ny = base.dists.chisquare.quantile( NaN, 1.0 )\ny = base.dists.chisquare.quantile( 0.0, NaN )\n\n// Negative degrees of freedom:\ny = base.dists.chisquare.quantile( 0.5, -1.0 )\n\n// Degenerate distribution when `k = 0`:\ny = base.dists.chisquare.quantile( 0.3, 0.0 )\ny = base.dists.chisquare.quantile( 0.9, 0.0 )\n",
	"base.dists.chisquare.skewness": "v = base.dists.chisquare.skewness( 11.0 )\nv = base.dists.chisquare.skewness( 1.5 )\n",
	"base.dists.chisquare.stdev": "v = base.dists.chisquare.stdev( 11.0 )\nv = base.dists.chisquare.stdev( 1.5 )\n",
	"base.dists.chisquare.variance": "v = base.dists.chisquare.variance( 11.0 )\nv = base.dists.chisquare.variance( 1.5 )\n",
	"base.dists.cosine.cdf": "y = base.dists.cosine.cdf( 2.0, 0.0, 3.0 )\ny = base.dists.cosine.cdf( 9.0, 10.0, 3.0 )\ny = base.dists.cosine.cdf( 2.0, 0.0, NaN )\ny = base.dists.cosine.cdf( 2.0, NaN, 1.0 )\ny = base.dists.cosine.cdf( NaN, 0.0, 1.0 )\n\n// Degenerate distribution centered at `μ` when `s = 0.0`:\ny = base.dists.cosine.cdf( 2.0, 8.0, 0.0 )\ny = base.dists.cosine.cdf( 8.0, 8.0, 0.0 )\ny = base.dists.cosine.cdf( 10.0, 8.0, 0.0 )\n",
	"base.dists.cosine.Cosine": "cosine = base.dists.cosine.Cosine( -2.0, 3.0 );\ncosine.mu\ncosine.s\ncosine.kurtosis\ncosine.mean\ncosine.median\ncosine.mode\ncosine.skewness\ncosine.stdev\ncosine.variance\ncosine.cdf( 0.5 )\ncosine.logcdf( 0.5 )\ncosine.logpdf( -1.0 )\ncosine.mgf( 0.2 )\ncosine.pdf( -2.0 )\ncosine.quantile( 0.9 )\n",
	"base.dists.cosine.kurtosis": "y = base.dists.cosine.kurtosis( 0.0, 1.0 )\ny = base.dists.cosine.kurtosis( 4.0, 2.0 )\ny = base.dists.cosine.kurtosis( NaN, 1.0 )\ny = base.dists.cosine.kurtosis( 0.0, NaN )\ny = base.dists.cosine.kurtosis( 0.0, 0.0 )\n",
	"base.dists.cosine.logcdf": "y = base.dists.cosine.logcdf( 2.0, 0.0, 3.0 )\ny = base.dists.cosine.logcdf( 9.0, 10.0, 3.0 )\ny = base.dists.cosine.logcdf( 2.0, 0.0, NaN )\ny = base.dists.cosine.logcdf( 2.0, NaN, 1.0 )\ny = base.dists.cosine.logcdf( NaN, 0.0, 1.0 )\n\n// Degenerate distribution centered at `μ` when `s = 0.0`:\ny = base.dists.cosine.logcdf( 2.0, 8.0, 0.0 )\ny = base.dists.cosine.logcdf( 8.0, 8.0, 0.0 )\ny = base.dists.cosine.logcdf( 10.0, 8.0, 0.0 )\n",
	"base.dists.cosine.logpdf": "y = base.dists.cosine.logpdf( 2.0, 0.0, 3.0 )\ny = base.dists.cosine.logpdf( -1.0, 2.0, 4.0 )\ny = base.dists.cosine.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.cosine.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.cosine.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cosine.logpdf( 2.0, 0.0, -1.0 )\n\n// Degenerate distribution at `s = 0.0`:\ny = base.dists.cosine.logpdf( 2.0, 8.0, 0.0 )\ny = base.dists.cosine.logpdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.cosine.mean": "y = base.dists.cosine.mean( 0.0, 1.0 )\ny = base.dists.cosine.mean( 4.0, 2.0 )\ny = base.dists.cosine.mean( NaN, 1.0 )\ny = base.dists.cosine.mean( 0.0, NaN )\ny = base.dists.cosine.mean( 0.0, 0.0 )\n",
	"base.dists.cosine.median": "y = base.dists.cosine.median( 0.0, 1.0 )\ny = base.dists.cosine.median( 4.0, 2.0 )\ny = base.dists.cosine.median( NaN, 1.0 )\ny = base.dists.cosine.median( 0.0, NaN )\ny = base.dists.cosine.median( 0.0, 0.0 )\n",
	"base.dists.cosine.mgf": "y = base.dists.cosine.mgf( 2.0, 0.0, 3.0 )\ny = base.dists.cosine.mgf( 9.0, 10.0, 3.0 )\ny = base.dists.cosine.mgf( 0.5, 0.0, NaN )\ny = base.dists.cosine.mgf( 0.5, NaN, 1.0 )\ny = base.dists.cosine.mgf( NaN, 0.0, 1.0 )\n",
	"base.dists.cosine.mode": "y = base.dists.cosine.mode( 0.0, 1.0 )\ny = base.dists.cosine.mode( 4.0, 2.0 )\ny = base.dists.cosine.mode( NaN, 1.0 )\ny = base.dists.cosine.mode( 0.0, NaN )\ny = base.dists.cosine.mode( 0.0, 0.0 )\n",
	"base.dists.cosine.pdf": "y = base.dists.cosine.pdf( 2.0, 0.0, 3.0 )\ny = base.dists.cosine.pdf( 2.4, 4.0, 2.0 )\ny = base.dists.cosine.pdf( NaN, 0.0, 1.0 )\ny = base.dists.cosine.pdf( 0.0, NaN, 1.0 )\ny = base.dists.cosine.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cosine.pdf( 2.0, 0.0, -1.0 )\ny = base.dists.cosine.pdf( 2.0, 8.0, 0.0 )\ny = base.dists.cosine.pdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.cosine.quantile": "y = base.dists.cosine.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.cosine.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.cosine.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.cosine.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.cosine.quantile( NaN, 0.0, 1.0 )\ny = base.dists.cosine.quantile( 0.0, NaN, 1.0 )\ny = base.dists.cosine.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.cosine.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.cosine.skewness": "y = base.dists.cosine.skewness( 0.0, 1.0 )\ny = base.dists.cosine.skewness( 4.0, 2.0 )\ny = base.dists.cosine.skewness( NaN, 1.0 )\ny = base.dists.cosine.skewness( 0.0, NaN )\ny = base.dists.cosine.skewness( 0.0, 0.0 )\n",
	"base.dists.cosine.stdev": "y = base.dists.cosine.stdev( 0.0, 1.0 )\ny = base.dists.cosine.stdev( 4.0, 2.0 )\ny = base.dists.cosine.stdev( NaN, 1.0 )\ny = base.dists.cosine.stdev( 0.0, NaN )\ny = base.dists.cosine.stdev( 0.0, 0.0 )\n",
	"base.dists.cosine.variance": "y = base.dists.cosine.variance( 0.0, 1.0 )\ny = base.dists.cosine.variance( 4.0, 2.0 )\ny = base.dists.cosine.variance( NaN, 1.0 )\ny = base.dists.cosine.variance( 0.0, NaN )\ny = base.dists.cosine.variance( 0.0, 0.0 )\n",
	"base.dists.degenerate.cdf": "y = base.dists.degenerate.cdf( 2.0, 3.0 )\ny = base.dists.degenerate.cdf( 4.0, 3.0 )\ny = base.dists.degenerate.cdf( 3.0, 3.0 )\ny = base.dists.degenerate.cdf( NaN, 0.0 )\ny = base.dists.degenerate.cdf( 0.0, NaN )\n",
	"base.dists.degenerate.logcdf": "y = base.dists.degenerate.logcdf( 2.0, 3.0 )\ny = base.dists.degenerate.logcdf( 4.0, 3.0 )\ny = base.dists.degenerate.logcdf( 3.0, 3.0 )\ny = base.dists.degenerate.logcdf( NaN, 0.0 )\ny = base.dists.degenerate.logcdf( 0.0, NaN )\n",
	"base.dists.degenerate.logpdf": "y = base.dists.degenerate.logpdf( 2.0, 3.0 )\ny = base.dists.degenerate.logpdf( 3.0, 3.0 )\ny = base.dists.degenerate.logpdf( NaN, 0.0 )\ny = base.dists.degenerate.logpdf( 0.0, NaN )\n",
	"base.dists.degenerate.logpmf": "y = base.dists.degenerate.logpmf( 2.0, 3.0 )\ny = base.dists.degenerate.logpmf( 3.0, 3.0 )\ny = base.dists.degenerate.logpmf( NaN, 0.0 )\ny = base.dists.degenerate.logpmf( 0.0, NaN )\n",
	"base.dists.degenerate.mgf": "y = base.dists.degenerate.mgf( 1.0, 1.0 )\ny = base.dists.degenerate.mgf( 2.0, 3.0 )\ny = base.dists.degenerate.mgf( NaN, 0.0 )\ny = base.dists.degenerate.mgf( 0.0, NaN )\n",
	"base.dists.degenerate.pdf": "y = base.dists.degenerate.pdf( 2.0, 3.0 )\ny = base.dists.degenerate.pdf( 3.0, 3.0 )\ny = base.dists.degenerate.pdf( NaN, 0.0 )\ny = base.dists.degenerate.pdf( 0.0, NaN )\n",
	"base.dists.degenerate.pmf": "y = base.dists.degenerate.pmf( 2.0, 3.0 )\ny = base.dists.degenerate.pmf( 3.0, 3.0 )\ny = base.dists.degenerate.pmf( NaN, 0.0 )\ny = base.dists.degenerate.pmf( 0.0, NaN )\n",
	"base.dists.degenerate.quantile": "y = base.dists.degenerate.quantile( 0.5, 2.0 )\ny = base.dists.degenerate.quantile( 0.9, 4.0 )\ny = base.dists.degenerate.quantile( 1.1, 0.0 )\ny = base.dists.degenerate.quantile( -0.2, 0.0 )\ny = base.dists.degenerate.quantile( NaN, 0.0 )\ny = base.dists.degenerate.quantile( 0.0, NaN )\n",
	"base.dists.discreteUniform.cdf": "y = base.dists.discreteUniform.cdf( 9.0, 0, 10 )\ny = base.dists.discreteUniform.cdf( 0.5, 0, 2 )\ny = base.dists.discreteUniform.cdf( PINF, 2, 4 )\ny = base.dists.discreteUniform.cdf( NINF, 2, 4 )\ny = base.dists.discreteUniform.cdf( NaN, 0, 1 )\ny = base.dists.discreteUniform.cdf( 0.0, NaN, 1 )\ny = base.dists.discreteUniform.cdf( 0.0, 0, NaN )\ny = base.dists.discreteUniform.cdf( 2.0, 1, 0 )\n",
	"base.dists.discreteUniform.DiscreteUniform": "discreteUniform = base.dists.discreteUniform.DiscreteUniform( -2, 2 );\ndiscreteUniform.a\ndiscreteUniform.b\ndiscreteUniform.entropy\ndiscreteUniform.kurtosis\ndiscreteUniform.mean\ndiscreteUniform.median\ndiscreteUniform.skewness\ndiscreteUniform.stdev\ndiscreteUniform.variance\ndiscreteUniform.cdf( 0.8 )\ndiscreteUniform.logcdf( 0.5 )\ndiscreteUniform.logpmf( 1.0 )\ndiscreteUniform.mgf( 0.8 )\ndiscreteUniform.pmf( 0.0 )\ndiscreteUniform.quantile( 0.8 )\n",
	"base.dists.discreteUniform.kurtosis": "v = base.dists.discreteUniform.kurtosis( 0, 1 )\nv = base.dists.discreteUniform.kurtosis( 4, 12 )\nv = base.dists.discreteUniform.kurtosis( -4, 8 )\n",
	"base.dists.discreteUniform.logcdf": "y = base.dists.discreteUniform.logcdf( 9.0, 0, 10 )\ny = base.dists.discreteUniform.logcdf( 0.5, 0, 2 )\ny = base.dists.discreteUniform.logcdf( PINF, 2, 4 )\ny = base.dists.discreteUniform.logcdf( NINF, 2, 4 )\ny = base.dists.discreteUniform.logcdf( NaN, 0, 1 )\ny = base.dists.discreteUniform.logcdf( 0.0, NaN, 1 )\ny = base.dists.discreteUniform.logcdf( 0.0, 0, NaN )\ny = base.dists.discreteUniform.logcdf( 2.0, 1, 0 )\n",
	"base.dists.discreteUniform.logpmf": "y = base.dists.discreteUniform.logpmf( 2.0, 0, 4 )\ny = base.dists.discreteUniform.logpmf( 5.0, 0, 4 )\ny = base.dists.discreteUniform.logpmf( 3.0, -4, 4 )\ny = base.dists.discreteUniform.logpmf( NaN, 0, 1 )\ny = base.dists.discreteUniform.logpmf( 0.0, NaN, 1 )\ny = base.dists.discreteUniform.logpmf( 0.0, 0, NaN )\ny = base.dists.discreteUniform.logpmf( 2.0, 3, 1 )\ny = base.dists.discreteUniform.logpmf( 2.0, 1, 2.4 )\n",
	"base.dists.discreteUniform.mean": "v = base.dists.discreteUniform.mean( -2, 2 )\nv = base.dists.discreteUniform.mean( 4, 12 )\nv = base.dists.discreteUniform.mean( 2, 8 )\n",
	"base.dists.discreteUniform.median": "v = base.dists.discreteUniform.median( -2, 2 )\nv = base.dists.discreteUniform.median( 4, 12 )\nv = base.dists.discreteUniform.median( 2, 8 )\n",
	"base.dists.discreteUniform.mgf": "y = base.dists.discreteUniform.mgf( 2.0, 0, 4 )\ny = base.dists.discreteUniform.mgf( -0.2, 0, 4 )\ny = base.dists.discreteUniform.mgf( 2.0, 0, 1 )\ny = base.dists.discreteUniform.mgf( 0.5, 3, 2 )\ny = base.dists.discreteUniform.mgf( NaN, 0, 1  )\ny = base.dists.discreteUniform.mgf( 0.0, NaN, 1 )\ny = base.dists.discreteUniform.mgf( 0.0, 0, NaN )\n",
	"base.dists.discreteUniform.pmf": "y = base.dists.discreteUniform.pmf( 2.0, 0, 4 )\ny = base.dists.discreteUniform.pmf( 5.0, 0, 4 )\ny = base.dists.discreteUniform.pmf( 3.0, -4, 4 )\ny = base.dists.discreteUniform.pmf( NaN, 0, 1 )\ny = base.dists.discreteUniform.pmf( 0.0, NaN, 1 )\ny = base.dists.discreteUniform.pmf( 0.0, 0, NaN )\ny = base.dists.discreteUniform.pmf( 2.0, 3, 1 )\ny = base.dists.discreteUniform.pmf( 2.0, 1, 2.4 )\n",
	"base.dists.discreteUniform.quantile": "y = base.dists.discreteUniform.quantile( 0.8, 0, 1 )\ny = base.dists.discreteUniform.quantile( 0.5, 0.0, 10.0 )\ny = base.dists.discreteUniform.quantile( 1.1, 0, 4 )\ny = base.dists.discreteUniform.quantile( -0.2, 0, 4 )\ny = base.dists.discreteUniform.quantile( NaN, -2, 2 )\ny = base.dists.discreteUniform.quantile( 0.1, NaN, 2 )\ny = base.dists.discreteUniform.quantile( 0.1, -2, NaN )\ny = base.dists.discreteUniform.quantile( 0.5, 2, 1 )\n",
	"base.dists.discreteUniform.skewness": "v = base.dists.discreteUniform.skewness( -2, 2 )\nv = base.dists.discreteUniform.skewness( 4, 12 )\nv = base.dists.discreteUniform.skewness( 2, 8 )\n",
	"base.dists.discreteUniform.stdev": "v = base.dists.discreteUniform.stdev( 0, 1 )\nv = base.dists.discreteUniform.stdev( 4, 12 )\nv = base.dists.discreteUniform.stdev( 2, 8 )\n",
	"base.dists.discreteUniform.variance": "v = base.dists.discreteUniform.variance( 0, 1 )\nv = base.dists.discreteUniform.variance( 4, 12 )\nv = base.dists.discreteUniform.variance( 2, 8 )\n",
	"base.dists.erlang.cdf": "y = base.dists.erlang.cdf( 2.0, 1, 1.0 );\ny = base.dists.erlang.cdf( 2.0, 3, 1.0 )\ny = base.dists.erlang.cdf( 2.0, 2.5, 1.0 )\ny = base.dists.erlang.cdf( -1.0, 2, 2.0 )\ny = base.dists.erlang.cdf( PINF, 4, 2.0 )\ny = base.dists.erlang.cdf( NINF, 4, 2.0 )\ny = base.dists.erlang.cdf( NaN, 0, 1.0 )\ny = base.dists.erlang.cdf( 0.0, NaN, 1.0 )\ny = base.dists.erlang.cdf( 0.0, 0, NaN )\ny = base.dists.erlang.cdf( 2.0, -1, 1.0 )\ny = base.dists.erlang.cdf( 2.0, 1, -1.0 )\n",
	"base.dists.erlang.entropy": "v = base.dists.erlang.entropy( 1, 1.0 )\nv = base.dists.erlang.entropy( 4, 12.0 )\nv = base.dists.erlang.entropy( 8, 2.0 )\n",
	"base.dists.erlang.Erlang": "erlang = base.dists.erlang.Erlang( 6, 5.0 );\nerlang.k\nerlang.lambda\nerlang.entropy\nerlang.kurtosis\nerlang.mean\nerlang.mode\nerlang.skewness\nerlang.stdev\nerlang.variance\nerlang.cdf( 3.0 )\nerlang.logpdf( 3.0 )\nerlang.mgf( -0.5 )\nerlang.pdf( 3.0 )\nerlang.quantile( 0.8 )\n",
	"base.dists.erlang.kurtosis": "v = base.dists.erlang.kurtosis( 1, 1.0 )\nv = base.dists.erlang.kurtosis( 4, 12.0 )\nv = base.dists.erlang.kurtosis( 8, 2.0 )\n",
	"base.dists.erlang.logpdf": "y = base.dists.erlang.logpdf( 0.1, 1, 1.0 )\ny = base.dists.erlang.logpdf( 0.5, 2, 2.5 )\ny = base.dists.erlang.logpdf( -1.0, 4, 2.0 )\ny = base.dists.erlang.logpdf( NaN, 1, 1.0 )\ny = base.dists.erlang.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.erlang.logpdf( 0.0, 1, NaN )\ny = base.dists.erlang.logpdf( 2.0, -2, 0.5 )\ny = base.dists.erlang.logpdf( 2.0, 0.5, 0.5 )\ny = base.dists.erlang.logpdf( 2.0, 0.0, 2.0 )\ny = base.dists.erlang.logpdf( 0.0, 0.0, 2.0 )\ny = base.dists.erlang.logpdf( 2.0, 1, 0.0 )\ny = base.dists.erlang.logpdf( 2.0, 1, -1.0 )\n",
	"base.dists.erlang.mean": "v = base.dists.erlang.mean( 1, 1.0 )\nv = base.dists.erlang.mean( 4, 12.0 )\nv = base.dists.erlang.mean( 8, 2.0 )\n",
	"base.dists.erlang.mgf": "y = base.dists.erlang.mgf( 0.3, 1, 1.0 )\ny = base.dists.erlang.mgf( 2.0, 2, 3.0 )\ny = base.dists.erlang.mgf( -1.0, 2, 2.0 )\ny = base.dists.erlang.mgf( NaN, 1, 1.0 )\ny = base.dists.erlang.mgf( 0.0, NaN, 1.0 )\ny = base.dists.erlang.mgf( 0.0, 1, NaN )\ny = base.dists.erlang.mgf( 0.2, -2, 0.5 )\ny = base.dists.erlang.mgf( 0.2, 0.5, 0.5 )\ny = base.dists.erlang.mgf( 0.2, 1, 0.0 )\ny = base.dists.erlang.mgf( 0.2, 1, -5.0 )\n",
	"base.dists.erlang.mode": "v = base.dists.erlang.mode( 1, 1.0 )\nv = base.dists.erlang.mode( 4, 12.0 )\nv = base.dists.erlang.mode( 8, 2.0 )\n",
	"base.dists.erlang.pdf": "y = base.dists.erlang.pdf( 0.1, 1, 1.0 )\ny = base.dists.erlang.pdf( 0.5, 2, 2.5 )\ny = base.dists.erlang.pdf( -1.0, 4, 2.0 )\ny = base.dists.erlang.pdf( NaN, 1, 1.0 )\ny = base.dists.erlang.pdf( 0.0, NaN, 1.0 )\ny = base.dists.erlang.pdf( 0.0, 1, NaN )\ny = base.dists.erlang.pdf( 2.0, -2, 0.5 )\ny = base.dists.erlang.pdf( 2.0, 0.5, 0.5 )\ny = base.dists.erlang.pdf( 2.0, 0.0, 2.0 )\ny = base.dists.erlang.pdf( 0.0, 0.0, 2.0 )\ny = base.dists.erlang.pdf( 2.0, 1, 0.0 )\ny = base.dists.erlang.pdf( 2.0, 1, -1.0 )\n",
	"base.dists.erlang.quantile": "y = base.dists.erlang.quantile( 0.8, 2, 1.0 )\ny = base.dists.erlang.quantile( 0.5, 4, 2.0 )\ny = base.dists.erlang.quantile( 1.1, 1, 1.0 )\ny = base.dists.erlang.quantile( -0.2, 1, 1.0 )\ny = base.dists.erlang.quantile( NaN, 1, 1.0 )\ny = base.dists.erlang.quantile( 0.0, NaN, 1.0 )\ny = base.dists.erlang.quantile( 0.0, 1, NaN )\n\n// Non-integer shape parameter:\ny = base.dists.erlang.quantile( 0.5, 0.5, 1.0 )\n\n// Non-positive shape parameter:\ny = base.dists.erlang.quantile( 0.5, -1, 1.0 )\n\n// Non-positive rate parameter:\ny = base.dists.erlang.quantile( 0.5, 1, -1.0 )\n",
	"base.dists.erlang.skewness": "v = base.dists.erlang.skewness( 1, 1.0 )\nv = base.dists.erlang.skewness( 4, 12.0 )\nv = base.dists.erlang.skewness( 8, 2.0 )\n",
	"base.dists.erlang.stdev": "v = base.dists.erlang.stdev( 1, 1.0 )\nv = base.dists.erlang.stdev( 4, 12.0 )\nv = base.dists.erlang.stdev( 8, 2.0 )\n",
	"base.dists.erlang.variance": "v = base.dists.erlang.variance( 1, 1.0 )\nv = base.dists.erlang.variance( 4, 12.0 )\nv = base.dists.erlang.variance( 8, 2.0 )\n",
	"base.dists.exponential.cdf": "y = base.dists.exponential.cdf( 2.0, 0.1 )\ny = base.dists.exponential.cdf( 1.0, 2.0 )\ny = base.dists.exponential.cdf( -1.0, 4.0 )\ny = base.dists.exponential.cdf( NaN, 1.0 )\ny = base.dists.exponential.cdf( 0.0, NaN )\n\n// Negative rate parameter:\ny = base.dists.exponential.cdf( 2.0, -1.0 )\n",
	"base.dists.exponential.entropy": "v = base.dists.exponential.entropy( 11.0 )\nv = base.dists.exponential.entropy( 4.5 )\n",
	"base.dists.exponential.Exponential": "exponential = base.dists.exponential.Exponential( 6.0 );\nexponential.lambda\nexponential.entropy\nexponential.kurtosis\nexponential.mean\nexponential.median\nexponential.mode\nexponential.skewness\nexponential.stdev\nexponential.variance\nexponential.cdf( 1.0 )\nexponential.logcdf( 1.0 )\nexponential.logpdf( 1.5 )\nexponential.mgf( -0.5 )\nexponential.pdf( 1.5 )\nexponential.quantile( 0.5 )\n",
	"base.dists.exponential.kurtosis": "v = base.dists.exponential.kurtosis( 11.0 )\nv = base.dists.exponential.kurtosis( 4.5 )\n",
	"base.dists.exponential.logcdf": "y = base.dists.exponential.logcdf( 2.0, 0.1 )\ny = base.dists.exponential.logcdf( 1.0, 2.0 )\ny = base.dists.exponential.logcdf( -1.0, 4.0 )\ny = base.dists.exponential.logcdf( NaN, 1.0 )\ny = base.dists.exponential.logcdf( 0.0, NaN )\n\n// Negative rate parameter:\ny = base.dists.exponential.logcdf( 2.0, -1.0 )\n",
	"base.dists.exponential.logpdf": "y = base.dists.exponential.logpdf( 0.3, 4.0 )\ny = base.dists.exponential.logpdf( 2.0, 0.7 )\ny = base.dists.exponential.logpdf( -1.0, 0.5 )\ny = base.dists.exponential.logpdf( 0, NaN )\ny = base.dists.exponential.logpdf( NaN, 2.0 )\n\n// Negative rate:\ny = base.dists.exponential.logpdf( 2.0, -1.0 )\n",
	"base.dists.exponential.mean": "v = base.dists.exponential.mean( 11.0 )\nv = base.dists.exponential.mean( 4.5 )\n",
	"base.dists.exponential.median": "v = base.dists.exponential.median( 11.0 )\nv = base.dists.exponential.median( 4.5 )\n",
	"base.dists.exponential.mode": "v = base.dists.exponential.mode( 11.0 )\nv = base.dists.exponential.mode( 4.5 )\n",
	"base.dists.exponential.pdf": "y = base.dists.exponential.pdf( 0.3, 4.0 )\ny = base.dists.exponential.pdf( 2.0, 0.7 )\ny = base.dists.exponential.pdf( -1.0, 0.5 )\ny = base.dists.exponential.pdf( 0, NaN )\ny = base.dists.exponential.pdf( NaN, 2.0 )\n\n// Negative rate:\ny = base.dists.exponential.pdf( 2.0, -1.0 )\n",
	"base.dists.exponential.quantile": "y = base.dists.exponential.quantile( 0.8, 1.0 )\ny = base.dists.exponential.quantile( 0.5, 4.0 )\ny = base.dists.exponential.quantile( 0.5, 0.1 )\ny = base.dists.exponential.quantile( -0.2, 0.1 )\ny = base.dists.exponential.quantile( NaN, 1.0 )\ny = base.dists.exponential.quantile( 0.0, NaN )\n\n// Negative rate parameter:\ny = base.dists.exponential.quantile( 0.5, -1.0 )\n",
	"base.dists.exponential.skewness": "v = base.dists.exponential.skewness( 11.0 )\nv = base.dists.exponential.skewness( 4.5 )\n",
	"base.dists.exponential.stdev": "v = base.dists.exponential.stdev( 9.0 )\nv = base.dists.exponential.stdev( 1.0 )\n",
	"base.dists.exponential.variance": "v = base.dists.exponential.variance( 9.0 )\nv = base.dists.exponential.variance( 1.0 )\n",
	"base.dists.f.cdf": "y = base.dists.f.cdf( 2.0, 1.0, 1.0 )\ny = base.dists.f.cdf( 2.0, 8.0, 4.0 )\ny = base.dists.f.cdf( -1.0, 2.0, 2.0 )\ny = base.dists.f.cdf( PINF, 4.0, 2.0 )\ny = base.dists.f.cdf( NINF, 4.0, 2.0 )\ny = base.dists.f.cdf( NaN, 1.0, 1.0 )\ny = base.dists.f.cdf( 0.0, NaN, 1.0 )\ny = base.dists.f.cdf( 0.0, 1.0, NaN )\ny = base.dists.f.cdf( 2.0, 1.0, -1.0 )\ny = base.dists.f.cdf( 2.0, -1.0, 1.0 )\n",
	"base.dists.f.entropy": "v = base.dists.f.entropy( 3.0, 7.0 )\nv = base.dists.f.entropy( 4.0, 12.0 )\nv = base.dists.f.entropy( 8.0, 2.0 )\n",
	"base.dists.f.F": "f = base.dists.f.F( 6.0, 9.0 );\nf.d1\nf.d2\nf.entropy\nf.kurtosis\nf.mean\nf.mode\nf.skewness\nf.stdev\nf.variance\nf.cdf( 3.0 )\nf.pdf( 2.5 )\nf.quantile( 0.8 )\n",
	"base.dists.f.kurtosis": "v = base.dists.f.kurtosis( 3.0, 9.0 )\nv = base.dists.f.kurtosis( 4.0, 12.0 )\nv = base.dists.f.kurtosis( 8.0, 9.0 )\n",
	"base.dists.f.mean": "v = base.dists.f.mean( 3.0, 5.0 )\nv = base.dists.f.mean( 4.0, 12.0 )\nv = base.dists.f.mean( 8.0, 4.0 )\n",
	"base.dists.f.mode": "v = base.dists.f.mode( 3.0, 5.0 )\nv = base.dists.f.mode( 4.0, 12.0 )\nv = base.dists.f.mode( 8.0, 4.0 )\n",
	"base.dists.f.pdf": "y = base.dists.f.pdf( 2.0, 0.5, 1.0 )\ny = base.dists.f.pdf( 0.1, 1.0, 1.0 )\ny = base.dists.f.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.f.pdf( NaN, 1.0, 1.0 )\ny = base.dists.f.pdf( 0.0, NaN, 1.0 )\ny = base.dists.f.pdf( 0.0, 1.0, NaN )\ny = base.dists.f.pdf( 2.0, 1.0, -1.0 )\ny = base.dists.f.pdf( 2.0, -1.0, 1.0 )\n",
	"base.dists.f.quantile": "y = base.dists.f.quantile( 0.8, 1.0, 1.0 )\ny = base.dists.f.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.f.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.f.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.f.quantile( NaN, 1.0, 1.0 )\ny = base.dists.f.quantile( 0.5, NaN, 1.0 )\ny = base.dists.f.quantile( 0.5, 1.0, NaN )\ny = base.dists.f.quantile( 0.5, -1.0, 1.0 )\ny = base.dists.f.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.f.skewness": "v = base.dists.f.skewness( 3.0, 7.0 )\nv = base.dists.f.skewness( 4.0, 12.0 )\nv = base.dists.f.skewness( 8.0, 7.0 )\n",
	"base.dists.f.stdev": "v = base.dists.f.stdev( 3.0, 5.0 )\nv = base.dists.f.stdev( 4.0, 12.0 )\nv = base.dists.f.stdev( 8.0, 5.0 )\n",
	"base.dists.f.variance": "v = base.dists.f.variance( 3.0, 5.0 )\nv = base.dists.f.variance( 4.0, 12.0 )\nv = base.dists.f.variance( 8.0, 5.0 )\n",
	"base.dists.frechet.cdf": "y = base.dists.frechet.cdf( 10.0, 2.0, 3.0, 0.0 )\ny = base.dists.frechet.cdf( -1.0, 2.0, 3.0, -3.0 )\ny = base.dists.frechet.cdf( 2.5, 2.0, 1.0, 2.0 )\ny = base.dists.frechet.cdf( NaN, 1.0, 1.0, 0.0 )\ny = base.dists.frechet.cdf( 0.0, NaN, 1.0, 0.0 )\ny = base.dists.frechet.cdf( 0.0, 1.0, NaN, 0.0 )\ny = base.dists.frechet.cdf( 0.0, 1.0, 1.0, NaN )\ny = base.dists.frechet.cdf( 0.0, -1.0, 1.0, 0.0 )\ny = base.dists.frechet.cdf( 0.0, 1.0, -1.0, 0.0 )\n",
	"base.dists.frechet.entropy": "y = base.dists.frechet.entropy( 1.0, 1.0, 1.0 )\ny = base.dists.frechet.entropy( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.entropy( NaN, 1.0, 0.0 )\ny = base.dists.frechet.entropy( 1.0, NaN, 0.0 )\ny = base.dists.frechet.entropy( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.Frechet": "frechet = base.dists.frechet.Frechet( 1.0, 1.0, 0.0 );\nfrechet.alpha\nfrechet.s\nfrechet.m\nfrechet.entropy\nfrechet.kurtosis\nfrechet.mean\nfrechet.median\nfrechet.mode\nfrechet.skewness\nfrechet.stdev\nfrechet.variance\nfrechet.cdf( 0.8 )\nfrechet.logcdf( 0.8 )\nfrechet.logpdf( 0.8 )\nfrechet.pdf( 0.8 )\nfrechet.quantile( 0.8 )\n",
	"base.dists.frechet.kurtosis": "y = base.dists.frechet.kurtosis( 5.0, 2.0, 1.0 )\ny = base.dists.frechet.kurtosis( 5.0, 10.0, -3.0 )\ny = base.dists.frechet.kurtosis( 3.5, 2.0, 1.0 )\ny = base.dists.frechet.kurtosis( NaN, 1.0, 0.0 )\ny = base.dists.frechet.kurtosis( 1.0, NaN, 0.0 )\ny = base.dists.frechet.kurtosis( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.logcdf": "y = base.dists.frechet.logcdf( 10.0, 2.0, 3.0, 0.0 )\ny = base.dists.frechet.logcdf( -1.0, 2.0, 3.0, -3.0 )\ny = base.dists.frechet.logcdf( 2.5, 2.0, 1.0, 2.0 )\ny = base.dists.frechet.logcdf( NaN, 1.0, 1.0, 0.0 )\ny = base.dists.frechet.logcdf( 0.0, NaN, 1.0, 0.0 )\ny = base.dists.frechet.logcdf( 0.0, 1.0, NaN, 0.0 )\ny = base.dists.frechet.logcdf( 0.0, 1.0, 1.0, NaN )\ny = base.dists.frechet.logcdf( 0.0, -1.0, 1.0, 0.0 )\ny = base.dists.frechet.logcdf( 0.0, 1.0, -1.0, 0.0 )\n",
	"base.dists.frechet.logpdf": "y = base.dists.frechet.logpdf( 10.0, 1.0, 3.0, 5.0 )\ny = base.dists.frechet.logpdf( -2.0, 1.0, 3.0, -3.0 )\ny = base.dists.frechet.logpdf( 0.0, 2.0, 1.0, -1.0 )\ny = base.dists.frechet.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.frechet.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.frechet.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.frechet.logpdf( 0.0, 0.0, -1.0 )\n",
	"base.dists.frechet.mean": "y = base.dists.frechet.mean( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.mean( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.mean( NaN, 1.0, 0.0 )\ny = base.dists.frechet.mean( 1.0, NaN, 0.0 )\ny = base.dists.frechet.mean( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.median": "y = base.dists.frechet.median( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.median( 4.0, 2.0, -3.0 )\ny = base.dists.frechet.median( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.median( NaN, 1.0, 0.0 )\ny = base.dists.frechet.median( 1.0, NaN, 0.0 )\ny = base.dists.frechet.median( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.mode": "y = base.dists.frechet.mode( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.mode( 4.0, 2.0, -3.0 )\ny = base.dists.frechet.mode( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.mode( NaN, 1.0, 0.0 )\ny = base.dists.frechet.mode( 1.0, NaN, 0.0 )\ny = base.dists.frechet.mode( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.pdf": "y = base.dists.frechet.pdf( 10.0, 0.0, 3.0 )\ny = base.dists.frechet.pdf( -2.0, 0.0, 3.0 )\ny = base.dists.frechet.pdf( 0.0, 0.0, 1.0 )\ny = base.dists.frechet.pdf( NaN, 0.0, 1.0 )\ny = base.dists.frechet.pdf( 0.0, NaN, 1.0 )\ny = base.dists.frechet.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.frechet.pdf( 0.0, 0.0, -1.0 )\n",
	"base.dists.frechet.quantile": "y = base.dists.frechet.quantile( 0.3, 10.0, 2.0, 3.0 )\ny = base.dists.frechet.quantile( 0.2, 3.0, 3.0, 3.0 )\ny = base.dists.frechet.quantile( 0.9, 1.0, 1.0, -3.0 )\ny = base.dists.frechet.quantile( NaN, 1.0, 1.0, 0.0 )\ny = base.dists.frechet.quantile( 0.0, NaN, 1.0, 0.0)\ny = base.dists.frechet.quantile( 0.0, 1.0, NaN, 0.0 )\ny = base.dists.frechet.quantile( 0.0, 1.0, 1.0, NaN )\ny = base.dists.frechet.quantile( 0.0, -1.0, 1.0, 0.0 )\ny = base.dists.frechet.quantile( 0.0, 1.0, -1.0, 0.0 )\n",
	"base.dists.frechet.skewness": "y = base.dists.frechet.skewness( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.skewness( 4.0, 2.0, -3.0 )\ny = base.dists.frechet.skewness( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.skewness( NaN, 1.0, 0.0 )\ny = base.dists.frechet.skewness( 1.0, NaN, 0.0 )\ny = base.dists.frechet.skewness( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.stdev": "y = base.dists.frechet.stdev( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.stdev( 4.0, 2.0, -3.0 )\ny = base.dists.frechet.stdev( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.stdev( NaN, 1.0, 0.0 )\ny = base.dists.frechet.stdev( 1.0, NaN, 0.0 )\ny = base.dists.frechet.stdev( 1.0, 1.0, NaN )\n",
	"base.dists.frechet.variance": "y = base.dists.frechet.variance( 4.0, 2.0, 1.0 )\ny = base.dists.frechet.variance( 4.0, 2.0, -3.0 )\ny = base.dists.frechet.variance( 0.5, 2.0, 1.0 )\ny = base.dists.frechet.variance( NaN, 1.0, 0.0 )\ny = base.dists.frechet.variance( 1.0, NaN, 0.0 )\ny = base.dists.frechet.variance( 1.0, 1.0, NaN )\n",
	"base.dists.gamma.cdf": "y = base.dists.gamma.cdf( 2.0, 1.0, 1.0 )\ny = base.dists.gamma.cdf( 2.0, 3.0, 1.0 )\ny = base.dists.gamma.cdf( -1.0, 2.0, 2.0 )\ny = base.dists.gamma.cdf( PINF, 4.0, 2.0 )\ny = base.dists.gamma.cdf( NINF, 4.0, 2.0 )\ny = base.dists.gamma.cdf( NaN, 0.0, 1.0 )\ny = base.dists.gamma.cdf( 0.0, NaN, 1.0 )\ny = base.dists.gamma.cdf( 0.0, 0.0, NaN )\ny = base.dists.gamma.cdf( 2.0, -1.0, 1.0 )\ny = base.dists.gamma.cdf( 2.0, 1.0, -1.0 )\n\n// Degenerate distribution centered at `0` when `α = 0.0`:\ny = base.dists.gamma.cdf( 2.0, 0.0, 2.0 )\ny = base.dists.gamma.cdf( -2.0, 0.0, 2.0 )\ny = base.dists.gamma.cdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.gamma.entropy": "v = base.dists.gamma.entropy( 1.0, 1.0 )\nv = base.dists.gamma.entropy( 4.0, 12.0 )\nv = base.dists.gamma.entropy( 8.0, 2.0 )\n",
	"base.dists.gamma.Gamma": "gamma = base.dists.gamma.Gamma( 6.0, 5.0 );\ngamma.alpha\ngamma.beta\ngamma.entropy\ngamma.kurtosis\ngamma.mean\ngamma.mode\ngamma.skewness\ngamma.stdev\ngamma.variance\ngamma.cdf( 0.8 )\ngamma.logpdf( 1.0 )\ngamma.mgf( -0.5 )\ngamma.pdf( 1.0 )\ngamma.quantile( 0.8 )\n",
	"base.dists.gamma.kurtosis": "v = base.dists.gamma.kurtosis( 1.0, 1.0 )\nv = base.dists.gamma.kurtosis( 4.0, 12.0 )\nv = base.dists.gamma.kurtosis( 8.0, 2.0 )\n",
	"base.dists.gamma.logpdf": "y = base.dists.gamma.logpdf( 2.0, 0.5, 1.0 )\ny = base.dists.gamma.logpdf( 0.1, 1.0, 1.0 )\ny = base.dists.gamma.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.gamma.logpdf( NaN, 0.6, 1.0 )\ny = base.dists.gamma.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.gamma.logpdf( 0.0, 1.0, NaN )\n\n// Negative shape parameter:\ny = base.dists.gamma.logpdf( 2.0, -1.0, 1.0 )\n\n// Non-positive rate parameter:\ny = base.dists.gamma.logpdf( 2.0, 1.0, -1.0 )\n\n// Degenerate distribution centered at `0.0` when `α = 0.0`:\ny = base.dists.gamma.logpdf( 2.0, 0.0, 2.0 )\ny = base.dists.gamma.logpdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.gamma.mean": "v = base.dists.gamma.mean( 1.0, 1.0 )\nv = base.dists.gamma.mean( 4.0, 12.0 )\nv = base.dists.gamma.mean( 8.0, 2.0 )\n",
	"base.dists.gamma.mgf": "y = base.dists.gamma.mgf( 0.5, 0.5, 1.0 )\ny = base.dists.gamma.mgf( 0.1, 1.0, 1.0 )\ny = base.dists.gamma.mgf( -1.0, 4.0, 2.0 )\ny = base.dists.gamma.mgf( NaN, 1.0, 1.0 )\ny = base.dists.gamma.mgf( 0.0, NaN, 1.0 )\ny = base.dists.gamma.mgf( 0.0, 1.0, NaN )\ny = base.dists.gamma.mgf( 2.0, 4.0, 1.0 )\ny = base.dists.gamma.mgf( 2.0, -0.5, 1.0 )\ny = base.dists.gamma.mgf( 2.0, 1.0, 0.0 )\ny = base.dists.gamma.mgf( 2.0, 1.0, -1.0 )\n",
	"base.dists.gamma.mode": "v = base.dists.gamma.mode( 1.0, 1.0 )\nv = base.dists.gamma.mode( 4.0, 12.0 )\nv = base.dists.gamma.mode( 8.0, 2.0 )\n",
	"base.dists.gamma.pdf": "y = base.dists.gamma.pdf( 2.0, 0.5, 1.0 )\ny = base.dists.gamma.pdf( 0.1, 1.0, 1.0 )\ny = base.dists.gamma.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.gamma.pdf( NaN, 0.6, 1.0 )\ny = base.dists.gamma.pdf( 0.0, NaN, 1.0 )\ny = base.dists.gamma.pdf( 0.0, 1.0, NaN )\n\n// Negative shape parameter:\ny = base.dists.gamma.pdf( 2.0, -1.0, 1.0 )\n\n// Non-positive rate parameter:\ny = base.dists.gamma.pdf( 2.0, 1.0, -1.0 )\n\n// Degenerate distribution centered at `0.0` when `α = 0.0`:\ny = base.dists.gamma.pdf( 2.0, 0.0, 2.0 )\ny = base.dists.gamma.pdf( 0.0, 0.0, 2.0 )\n",
	"base.dists.gamma.quantile": "y = base.dists.gamma.quantile( 0.8, 2.0, 1.0 )\ny = base.dists.gamma.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.gamma.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.gamma.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.gamma.quantile( NaN, 1.0, 1.0 )\ny = base.dists.gamma.quantile( 0.0, NaN, 1.0 )\ny = base.dists.gamma.quantile( 0.0, 1.0, NaN )\n\n// Non-positive shape parameter:\ny = base.dists.gamma.quantile( 0.5, -1.0, 1.0 )\n\n// Non-positive rate parameter:\ny = base.dists.gamma.quantile( 0.5, 1.0, -1.0 )\n\n// Degenerate distribution centered at `0.0` when `α = 0.0`:\ny = base.dists.gamma.quantile( 0.3, 0.0, 2.0 );\ny = base.dists.gamma.quantile( 0.9, 0.0, 2.0 );\n",
	"base.dists.gamma.skewness": "v = base.dists.gamma.skewness( 1.0, 1.0 )\nv = base.dists.gamma.skewness( 4.0, 12.0 )\nv = base.dists.gamma.skewness( 8.0, 2.0 )\n",
	"base.dists.gamma.stdev": "v = base.dists.gamma.stdev( 1.0, 1.0 )\nv = base.dists.gamma.stdev( 4.0, 12.0 )\nv = base.dists.gamma.stdev( 8.0, 2.0 )\n",
	"base.dists.gamma.variance": "v = base.dists.gamma.variance( 1.0, 1.0 )\nv = base.dists.gamma.variance( 4.0, 12.0 )\nv = base.dists.gamma.variance( 8.0, 2.0 )\n",
	"base.dists.geometric.cdf": "y = base.dists.geometric.cdf( 2.0, 0.5 )\ny = base.dists.geometric.cdf( 2.0, 0.1 )\ny = base.dists.geometric.cdf( -1.0, 4.0 )\ny = base.dists.geometric.cdf( NaN, 0.5 )\ny = base.dists.geometric.cdf( 0.0, NaN )\n\n// Invalid probability\ny = base.dists.geometric.cdf( 2.0, 1.4 )\n",
	"base.dists.geometric.entropy": "v = base.dists.geometric.entropy( 0.1 )\nv = base.dists.geometric.entropy( 0.5 )\n",
	"base.dists.geometric.Geometric": "geometric = base.dists.geometric.Geometric( 0.6 );\ngeometric.p\ngeometric.entropy\ngeometric.kurtosis\ngeometric.mean\ngeometric.median\ngeometric.mode\ngeometric.skewness\ngeometric.stdev\ngeometric.variance\ngeometric.cdf( 3.0 )\ngeometric.logcdf( 3.0 )\ngeometric.logpmf( 4.0 )\ngeometric.mgf( 0.5 )\ngeometric.pmf( 2.0 )\ngeometric.quantile( 0.7 )\n",
	"base.dists.geometric.kurtosis": "v = base.dists.geometric.kurtosis( 0.1 )\nv = base.dists.geometric.kurtosis( 0.5 )\n",
	"base.dists.geometric.logcdf": "y = base.dists.geometric.logcdf( 2.0, 0.5 )\ny = base.dists.geometric.logcdf( 2.0, 0.1 )\ny = base.dists.geometric.logcdf( -1.0, 4.0 )\ny = base.dists.geometric.logcdf( NaN, 0.5 )\ny = base.dists.geometric.logcdf( 0.0, NaN )\n\n// Invalid probability\ny = base.dists.geometric.logcdf( 2.0, 1.4 )\n",
	"base.dists.geometric.logpmf": "y = base.dists.geometric.logpmf( 4.0, 0.3 )\ny = base.dists.geometric.logpmf( 2.0, 0.7 )\ny = base.dists.geometric.logpmf( -1.0, 0.5 )\ny = base.dists.geometric.logpmf( 0.0, NaN )\ny = base.dists.geometric.logpmf( NaN, 0.5 )\n\n// Invalid success probability:\ny = base.dists.geometric.logpmf( 2.0, 1.5 )\n",
	"base.dists.geometric.mean": "v = base.dists.geometric.mean( 0.1 )\nv = base.dists.geometric.mean( 0.5 )\n",
	"base.dists.geometric.median": "v = base.dists.geometric.median( 0.1 )\nv = base.dists.geometric.median( 0.5 )\n",
	"base.dists.geometric.mgf": "y = base.dists.geometric.mgf( 0.2, 0.5 )\ny = base.dists.geometric.mgf( 0.4, 0.5 )\n\n// Case: t >= -ln(1-p)\ny = base.dists.geometric.mgf( 0.8, 0.5 )\ny = base.dists.geometric.mgf( NaN, 0.0 )\ny = base.dists.geometric.mgf( 0.0, NaN )\ny = base.dists.geometric.mgf( -2.0, -1.0 )\ny = base.dists.geometric.mgf( 0.2, 2.0 )\n",
	"base.dists.geometric.mode": "v = base.dists.geometric.mode( 0.1 )\nv = base.dists.geometric.mode( 0.5 )\n",
	"base.dists.geometric.pmf": "y = base.dists.geometric.pmf( 4.0, 0.3 )\ny = base.dists.geometric.pmf( 2.0, 0.7 )\ny = base.dists.geometric.pmf( -1.0, 0.5 )\ny = base.dists.geometric.pmf( 0.0, NaN )\ny = base.dists.geometric.pmf( NaN, 0.5 )\n\n// Invalid success probability:\ny = base.dists.geometric.pmf( 2.0, 1.5 )\n",
	"base.dists.geometric.quantile": "y = base.dists.geometric.quantile( 0.8, 0.4 )\ny = base.dists.geometric.quantile( 0.5, 0.4 )\ny = base.dists.geometric.quantile( 0.9, 0.1 )\ny = base.dists.geometric.quantile( -0.2, 0.1 )\ny = base.dists.geometric.quantile( NaN, 0.8 )\ny = base.dists.geometric.quantile( 0.4, NaN )\ny = base.dists.geometric.quantile( 0.5, -1.0 )\ny = base.dists.geometric.quantile( 0.5, 1.5 )\n",
	"base.dists.geometric.skewness": "v = base.dists.geometric.skewness( 0.1 )\nv = base.dists.geometric.skewness( 0.5 )\n",
	"base.dists.geometric.stdev": "v = base.dists.geometric.stdev( 0.1 )\nv = base.dists.geometric.stdev( 0.5 )\n",
	"base.dists.geometric.variance": "v = base.dists.geometric.variance( 0.1 )\nv = base.dists.geometric.variance( 0.5 )\n",
	"base.dists.gumbel.cdf": "y = base.dists.gumbel.cdf( 10.0, 0.0, 3.0 )\ny = base.dists.gumbel.cdf( -2.0, 0.0, 3.0 )\ny = base.dists.gumbel.cdf( 0.0, 0.0, 1.0 )\ny = base.dists.gumbel.cdf( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.cdf( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.cdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.gumbel.cdf( 0.0, 0.0, -1.0 )\n",
	"base.dists.gumbel.entropy": "y = base.dists.gumbel.entropy( 0.0, 1.0 )\ny = base.dists.gumbel.entropy( 4.0, 2.0 )\ny = base.dists.gumbel.entropy( NaN, 1.0 )\ny = base.dists.gumbel.entropy( 0.0, NaN )\ny = base.dists.gumbel.entropy( 0.0, 0.0 )\n",
	"base.dists.gumbel.Gumbel": "gumbel = base.dists.gumbel.Gumbel( -2.0, 3.0 );\ngumbel.mu\ngumbel.beta\ngumbel.entropy\ngumbel.kurtosis\ngumbel.mean\ngumbel.median\ngumbel.mode\ngumbel.skewness\ngumbel.stdev\ngumbel.variance\ngumbel.cdf( 0.8 )\ngumbel.logcdf( 0.8 )\ngumbel.logpdf( 1.0 )\ngumbel.mgf( 0.2 )\ngumbel.pdf( 1.0 )\ngumbel.quantile( 0.8 )\n",
	"base.dists.gumbel.kurtosis": "y = base.dists.gumbel.kurtosis( 0.0, 1.0 )\ny = base.dists.gumbel.kurtosis( 4.0, 2.0 )\ny = base.dists.gumbel.kurtosis( NaN, 1.0 )\ny = base.dists.gumbel.kurtosis( 0.0, NaN )\ny = base.dists.gumbel.kurtosis( 0.0, 0.0 )\n",
	"base.dists.gumbel.logcdf": "y = base.dists.gumbel.logcdf( 10.0, 0.0, 3.0 )\ny = base.dists.gumbel.logcdf( -2.0, 0.0, 3.0 )\ny = base.dists.gumbel.logcdf( 0.0, 0.0, 1.0 )\ny = base.dists.gumbel.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.logcdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.gumbel.logcdf( 0.0, 0.0, -1.0 )\n",
	"base.dists.gumbel.logpdf": "y = base.dists.gumbel.logpdf( 0.0, 0.0, 2.0 )\ny = base.dists.gumbel.logpdf( 0.0, 0.0, 1.0 )\ny = base.dists.gumbel.logpdf( 1.0, 3.0, 2.0 )\ny = base.dists.gumbel.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.gumbel.logpdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.gumbel.mean": "y = base.dists.gumbel.mean( 0.0, 1.0 )\ny = base.dists.gumbel.mean( 4.0, 2.0 )\ny = base.dists.gumbel.mean( NaN, 1.0 )\ny = base.dists.gumbel.mean( 0.0, NaN )\ny = base.dists.gumbel.mean( 0.0, 0.0 )\n",
	"base.dists.gumbel.median": "y = base.dists.gumbel.median( 0.0, 1.0 )\ny = base.dists.gumbel.median( 4.0, 2.0 )\ny = base.dists.gumbel.median( NaN, 1.0 )\ny = base.dists.gumbel.median( 0.0, NaN )\ny = base.dists.gumbel.median( 0.0, 0.0 )\n",
	"base.dists.gumbel.mgf": "y = base.dists.gumbel.mgf( -1.0, 0.0, 3.0 )\ny = base.dists.gumbel.mgf( 0.0, 0.0, 1.0 )\ny = base.dists.gumbel.mgf( 0.1, 0.0, 3.0 )\ny = base.dists.gumbel.mgf( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.mgf( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.mgf( 0.0, 0.0, NaN )\n\n// Case: `t >= 1/beta`\ny = base.dists.gumbel.mgf( 0.8, 0.0, 2.0 )\n\n// Non-positive scale parameter:\ny = base.dists.gumbel.mgf( 0.0, 0.0, -1.0 )\n",
	"base.dists.gumbel.mode": "y = base.dists.gumbel.mode( 0.0, 1.0 )\ny = base.dists.gumbel.mode( 4.0, 2.0 )\ny = base.dists.gumbel.mode( NaN, 1.0 )\ny = base.dists.gumbel.mode( 0.0, NaN )\ny = base.dists.gumbel.mode( 0.0, 0.0 )\n",
	"base.dists.gumbel.pdf": "y = base.dists.gumbel.pdf( 0.0, 0.0, 2.0 )\ny = base.dists.gumbel.pdf( 0.0, 0.0, 1.0 )\ny = base.dists.gumbel.pdf( 1.0, 3.0, 2.0 )\ny = base.dists.gumbel.pdf( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.pdf( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.gumbel.pdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.gumbel.quantile": "y = base.dists.gumbel.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.gumbel.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.gumbel.quantile( 0.5, 4.0, 4.0 )\ny = base.dists.gumbel.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.gumbel.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.gumbel.quantile( NaN, 0.0, 1.0 )\ny = base.dists.gumbel.quantile( 0.0, NaN, 1.0 )\ny = base.dists.gumbel.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.gumbel.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.gumbel.skewness": "y = base.dists.gumbel.skewness( 0.0, 1.0 )\ny = base.dists.gumbel.skewness( 4.0, 2.0 )\ny = base.dists.gumbel.skewness( NaN, 1.0 )\ny = base.dists.gumbel.skewness( 0.0, NaN )\ny = base.dists.gumbel.skewness( 0.0, 0.0 )\n",
	"base.dists.gumbel.stdev": "y = base.dists.gumbel.stdev( 0.0, 1.0 )\ny = base.dists.gumbel.stdev( 4.0, 2.0 )\ny = base.dists.gumbel.stdev( NaN, 1.0 )\ny = base.dists.gumbel.stdev( 0.0, NaN )\ny = base.dists.gumbel.stdev( 0.0, 0.0 )\n",
	"base.dists.gumbel.variance": "y = base.dists.gumbel.variance( 0.0, 1.0 )\ny = base.dists.gumbel.variance( 4.0, 2.0 )\ny = base.dists.gumbel.variance( NaN, 1.0 )\ny = base.dists.gumbel.variance( 0.0, NaN )\ny = base.dists.gumbel.variance( 0.0, 0.0 )\n",
	"base.dists.hypergeometric.cdf": "y = base.dists.hypergeometric.cdf( 1.0, 8, 4, 2 )\ny = base.dists.hypergeometric.cdf( 1.5, 8, 4, 2 )\ny = base.dists.hypergeometric.cdf( 2.0, 8, 4, 2 )\ny = base.dists.hypergeometric.cdf( 0, 8, 4, 2)\ny = base.dists.hypergeometric.cdf( NaN, 10, 5, 2 )\ny = base.dists.hypergeometric.cdf( 0.0, NaN, 5, 2 )\ny = base.dists.hypergeometric.cdf( 0.0, 10, NaN, 2 )\ny = base.dists.hypergeometric.cdf( 0.0, 10, 5, NaN )\ny = base.dists.hypergeometric.cdf( 2.0, 10.5, 5, 2 )\ny = base.dists.hypergeometric.cdf( 2.0, 10, 1.5, 2 )\ny = base.dists.hypergeometric.cdf( 2.0, 10, 5, -2.0 )\ny = base.dists.hypergeometric.cdf( 2.0, 10, 5, 12 )\ny = base.dists.hypergeometric.cdf( 2.0, 8, 3, 9 )\n",
	"base.dists.hypergeometric.Hypergeometric": "hypergeometric = base.dists.hypergeometric.Hypergeometric( 100, 70, 20 );\nhypergeometric.N\nhypergeometric.K\nhypergeometric.n\nhypergeometric.kurtosis\nhypergeometric.mean\nhypergeometric.mode\nhypergeometric.skewness\nhypergeometric.stdev\nhypergeometric.variance\nhypergeometric.cdf( 2.9 )\nhypergeometric.logpmf( 10 )\nhypergeometric.pmf( 10 )\nhypergeometric.quantile( 0.8 )\n",
	"base.dists.hypergeometric.kurtosis": "v = base.dists.hypergeometric.kurtosis( 16, 11, 4 )\nv = base.dists.hypergeometric.kurtosis( 4, 2, 2 )\nv = base.dists.hypergeometric.kurtosis( 10, 5, 12 )\nv = base.dists.hypergeometric.kurtosis( 10.3, 10, 4 )\nv = base.dists.hypergeometric.kurtosis( 10, 5.5, 4 )\nv = base.dists.hypergeometric.kurtosis( 10, 5, 4.5 )\nv = base.dists.hypergeometric.kurtosis( NaN, 10, 4 )\nv = base.dists.hypergeometric.kurtosis( 20, NaN, 4 )\nv = base.dists.hypergeometric.kurtosis( 20, 10, NaN )\n",
	"base.dists.hypergeometric.logpmf": "y = base.dists.hypergeometric.logpmf( 1.0, 8, 4, 2 )\ny = base.dists.hypergeometric.logpmf( 2.0, 8, 4, 2 )\ny = base.dists.hypergeometric.logpmf( 0.0, 8, 4, 2 )\ny = base.dists.hypergeometric.logpmf( 1.5, 8, 4, 2 )\ny = base.dists.hypergeometric.logpmf( NaN, 10, 5, 2 )\ny = base.dists.hypergeometric.logpmf( 0.0, NaN, 5, 2 )\ny = base.dists.hypergeometric.logpmf( 0.0, 10, NaN, 2 )\ny = base.dists.hypergeometric.logpmf( 0.0, 10, 5, NaN )\ny = base.dists.hypergeometric.logpmf( 2.0, 10.5, 5, 2 )\ny = base.dists.hypergeometric.logpmf( 2.0, 5, 1.5, 2 )\ny = base.dists.hypergeometric.logpmf( 2.0, 10, 5, -2.0 )\ny = base.dists.hypergeometric.logpmf( 2.0, 10, 5, 12 )\ny = base.dists.hypergeometric.logpmf( 2.0, 8, 3, 9 )\n",
	"base.dists.hypergeometric.mean": "v = base.dists.hypergeometric.mean( 16, 11, 4 )\nv = base.dists.hypergeometric.mean( 2, 1, 1 )\nv = base.dists.hypergeometric.mean( 10, 5, 12 )\nv = base.dists.hypergeometric.mean( 10.3, 10, 4 )\nv = base.dists.hypergeometric.mean( 10, 5.5, 4 )\nv = base.dists.hypergeometric.mean( 10, 5, 4.5 )\nv = base.dists.hypergeometric.mean( NaN, 10, 4 )\nv = base.dists.hypergeometric.mean( 20, NaN, 4 )\nv = base.dists.hypergeometric.mean( 20, 10, NaN )\n",
	"base.dists.hypergeometric.mode": "v = base.dists.hypergeometric.mode( 16, 11, 4 )\nv = base.dists.hypergeometric.mode( 2, 1, 1 )\nv = base.dists.hypergeometric.mode( 10, 5, 12 )\nv = base.dists.hypergeometric.mode( 10.3, 10, 4 )\nv = base.dists.hypergeometric.mode( 10, 5.5, 4 )\nv = base.dists.hypergeometric.mode( 10, 5, 4.5 )\nv = base.dists.hypergeometric.mode( NaN, 10, 4 )\nv = base.dists.hypergeometric.mode( 20, NaN, 4 )\nv = base.dists.hypergeometric.mode( 20, 10, NaN )\n",
	"base.dists.hypergeometric.pmf": "y = base.dists.hypergeometric.pmf( 1.0, 8, 4, 2 )\ny = base.dists.hypergeometric.pmf( 2.0, 8, 4, 2 )\ny = base.dists.hypergeometric.pmf( 0.0, 8, 4, 2 )\ny = base.dists.hypergeometric.pmf( 1.5, 8, 4, 2 )\ny = base.dists.hypergeometric.pmf( NaN, 10, 5, 2 )\ny = base.dists.hypergeometric.pmf( 0.0, NaN, 5, 2 )\ny = base.dists.hypergeometric.pmf( 0.0, 10, NaN, 2 )\ny = base.dists.hypergeometric.pmf( 0.0, 10, 5, NaN )\ny = base.dists.hypergeometric.pmf( 2.0, 10.5, 5, 2 )\ny = base.dists.hypergeometric.pmf( 2.0, 5, 1.5, 2 )\ny = base.dists.hypergeometric.pmf( 2.0, 10, 5, -2.0 )\ny = base.dists.hypergeometric.pmf( 2.0, 10, 5, 12 )\ny = base.dists.hypergeometric.pmf( 2.0, 8, 3, 9 )\n",
	"base.dists.hypergeometric.quantile": "y = base.dists.hypergeometric.quantile( 0.4, 40, 20, 10 )\ny = base.dists.hypergeometric.quantile( 0.8, 60, 40, 20 )\ny = base.dists.hypergeometric.quantile( 0.5, 100, 10, 10 )\ny = base.dists.hypergeometric.quantile( 0.0, 100, 40, 20 )\ny = base.dists.hypergeometric.quantile( 1.0, 100, 40, 20 )\ny = base.dists.hypergeometric.quantile( NaN, 40, 20, 10 )\ny = base.dists.hypergeometric.quantile( 0.2, NaN, 20, 10 )\ny = base.dists.hypergeometric.quantile( 0.2, 40, NaN, 10 )\ny = base.dists.hypergeometric.quantile( 0.2, 40, 20, NaN )\n",
	"base.dists.hypergeometric.skewness": "v = base.dists.hypergeometric.skewness( 16, 11, 4 )\nv = base.dists.hypergeometric.skewness( 4, 2, 2 )\nv = base.dists.hypergeometric.skewness( 10, 5, 12 )\nv = base.dists.hypergeometric.skewness( 10.3, 10, 4 )\nv = base.dists.hypergeometric.skewness( 10, 5.5, 4 )\nv = base.dists.hypergeometric.skewness( 10, 5, 4.5 )\nv = base.dists.hypergeometric.skewness( NaN, 10, 4 )\nv = base.dists.hypergeometric.skewness( 20, NaN, 4 )\nv = base.dists.hypergeometric.skewness( 20, 10, NaN )\n",
	"base.dists.hypergeometric.stdev": "v = base.dists.hypergeometric.stdev( 16, 11, 4 )\nv = base.dists.hypergeometric.stdev( 2, 1, 1 )\nv = base.dists.hypergeometric.stdev( 10, 5, 12 )\nv = base.dists.hypergeometric.stdev( 10.3, 10, 4 )\nv = base.dists.hypergeometric.stdev( 10, 5.5, 4 )\nv = base.dists.hypergeometric.stdev( 10, 5, 4.5 )\nv = base.dists.hypergeometric.stdev( NaN, 10, 4 )\nv = base.dists.hypergeometric.stdev( 20, NaN, 4 )\nv = base.dists.hypergeometric.stdev( 20, 10, NaN )\n",
	"base.dists.hypergeometric.variance": "v = base.dists.hypergeometric.variance( 16, 11, 4 )\nv = base.dists.hypergeometric.variance( 2, 1, 1 )\nv = base.dists.hypergeometric.variance( 10, 5, 12 )\nv = base.dists.hypergeometric.variance( 10.3, 10, 4 )\nv = base.dists.hypergeometric.variance( 10, 5.5, 4 )\nv = base.dists.hypergeometric.variance( 10, 5, 4.5 )\nv = base.dists.hypergeometric.variance( NaN, 10, 4 )\nv = base.dists.hypergeometric.variance( 20, NaN, 4 )\nv = base.dists.hypergeometric.variance( 20, 10, NaN )\n",
	"base.dists.invgamma.cdf": "y = base.dists.invgamma.cdf( 2.0, 1.0, 1.0 )\ny = base.dists.invgamma.cdf( 2.0, 3.0, 1.0 )\ny = base.dists.invgamma.cdf( -1.0, 2.0, 2.0 )\ny = base.dists.invgamma.cdf( PINF, 4.0, 2.0 )\ny = base.dists.invgamma.cdf( NINF, 4.0, 2.0 )\ny = base.dists.invgamma.cdf( NaN, 0.0, 1.0 )\ny = base.dists.invgamma.cdf( 0.0, NaN, 1.0 )\ny = base.dists.invgamma.cdf( 0.0, 0.0, NaN )\ny = base.dists.invgamma.cdf( 2.0, -1.0, 1.0 )\ny = base.dists.invgamma.cdf( 2.0, 1.0, -1.0 )\n",
	"base.dists.invgamma.entropy": "v = base.dists.invgamma.entropy( 1.0, 1.0 )\nv = base.dists.invgamma.entropy( 4.0, 12.0 )\nv = base.dists.invgamma.entropy( 8.0, 2.0 )\n",
	"base.dists.invgamma.InvGamma": "invgamma = base.dists.invgamma.InvGamma( 6.0, 5.0 );\ninvgamma.alpha\ninvgamma.beta\ninvgamma.entropy\ninvgamma.kurtosis\ninvgamma.mean\ninvgamma.mode\ninvgamma.skewness\ninvgamma.stdev\ninvgamma.variance\ninvgamma.cdf( 0.8 )\ninvgamma.pdf( 1.0 )\ninvgamma.logpdf( 1.0 )\ninvgamma.quantile( 0.8 )\n",
	"base.dists.invgamma.kurtosis": "v = base.dists.invgamma.kurtosis( 7.0, 5.0 )\nv = base.dists.invgamma.kurtosis( 6.0, 12.0 )\nv = base.dists.invgamma.kurtosis( 8.0, 2.0 )\n",
	"base.dists.invgamma.logpdf": "y = base.dists.invgamma.logpdf( 2.0, 0.5, 1.0 )\ny = base.dists.invgamma.logpdf( 0.2, 1.0, 1.0 )\ny = base.dists.invgamma.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.invgamma.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.invgamma.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.invgamma.logpdf( 0.0, 1.0, NaN )\n\n// Negative shape parameter:\ny = base.dists.invgamma.logpdf( 2.0, -1.0, 1.0 )\n\n// Negative scale parameter:\ny = base.dists.invgamma.logpdf( 2.0, 1.0, -1.0 )\n",
	"base.dists.invgamma.mean": "v = base.dists.invgamma.mean( 4.0, 12.0 )\nv = base.dists.invgamma.mean( 8.0, 2.0 )\n",
	"base.dists.invgamma.mode": "v = base.dists.invgamma.mode( 1.0, 1.0 )\nv = base.dists.invgamma.mode( 4.0, 12.0 )\nv = base.dists.invgamma.mode( 8.0, 2.0 )\n",
	"base.dists.invgamma.pdf": "y = base.dists.invgamma.pdf( 2.0, 0.5, 1.0 )\ny = base.dists.invgamma.pdf( 0.2, 1.0, 1.0 )\ny = base.dists.invgamma.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.invgamma.pdf( NaN, 1.0, 1.0 )\ny = base.dists.invgamma.pdf( 0.0, NaN, 1.0 )\ny = base.dists.invgamma.pdf( 0.0, 1.0, NaN )\n\n// Negative shape parameter:\ny = base.dists.invgamma.pdf( 2.0, -1.0, 1.0 )\n\n// Negative scale parameter:\ny = base.dists.invgamma.pdf( 2.0, 1.0, -1.0 )\n",
	"base.dists.invgamma.quantile": "y = base.dists.invgamma.quantile( 0.8, 2.0, 1.0 )\ny = base.dists.invgamma.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.invgamma.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.invgamma.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.invgamma.quantile( NaN, 1.0, 1.0 )\ny = base.dists.invgamma.quantile( 0.0, NaN, 1.0 )\ny = base.dists.invgamma.quantile( 0.0, 1.0, NaN )\n\n// Non-positive shape parameter:\ny = base.dists.invgamma.quantile( 0.5, -1.0, 1.0 )\n\n// Non-positive rate parameter:\ny = base.dists.invgamma.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.invgamma.skewness": "v = base.dists.invgamma.skewness( 4.0, 12.0 )\nv = base.dists.invgamma.skewness( 8.0, 2.0 )\n",
	"base.dists.invgamma.stdev": "v = base.dists.invgamma.stdev( 5.0, 7.0 )\nv = base.dists.invgamma.stdev( 4.0, 12.0 )\nv = base.dists.invgamma.stdev( 8.0, 2.0 )\n",
	"base.dists.invgamma.variance": "v = base.dists.invgamma.variance( 5.0, 7.0 )\nv = base.dists.invgamma.variance( 4.0, 12.0 )\nv = base.dists.invgamma.variance( 8.0, 2.0 )\n",
	"base.dists.kumaraswamy.cdf": "y = base.dists.kumaraswamy.cdf( 0.5, 1.0, 1.0 )\ny = base.dists.kumaraswamy.cdf( 0.5, 2.0, 4.0 )\ny = base.dists.kumaraswamy.cdf( 0.2, 2.0, 2.0 )\ny = base.dists.kumaraswamy.cdf( 0.8, 4.0, 4.0 )\ny = base.dists.kumaraswamy.cdf( -0.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.cdf( 1.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.cdf( 2.0, -1.0, 0.5 )\ny = base.dists.kumaraswamy.cdf( 2.0, 0.5, -1.0 )\ny = base.dists.kumaraswamy.cdf( NaN, 1.0, 1.0 )\ny = base.dists.kumaraswamy.cdf( 0.0, NaN, 1.0 )\ny = base.dists.kumaraswamy.cdf( 0.0, 1.0, NaN )\n",
	"base.dists.kumaraswamy.Kumaraswamy": "kumaraswamy = base.dists.kumaraswamy.Kumaraswamy( 6.0, 5.0 );\nkumaraswamy.a\nkumaraswamy.b\nkumaraswamy.kurtosis\nkumaraswamy.mean\nkumaraswamy.mode\nkumaraswamy.skewness\nkumaraswamy.stdev\nkumaraswamy.variance\nkumaraswamy.cdf( 0.8 )\nkumaraswamy.pdf( 1.0 )\nkumaraswamy.quantile( 0.8 )\n",
	"base.dists.kumaraswamy.kurtosis": "v = base.dists.kumaraswamy.kurtosis( 1.0, 1.0 )\nv = base.dists.kumaraswamy.kurtosis( 4.0, 12.0 )\nv = base.dists.kumaraswamy.kurtosis( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.logcdf": "y = base.dists.kumaraswamy.logcdf( 0.5, 1.0, 1.0 )\ny = base.dists.kumaraswamy.logcdf( 0.5, 2.0, 4.0 )\ny = base.dists.kumaraswamy.logcdf( 0.2, 2.0, 2.0 )\ny = base.dists.kumaraswamy.logcdf( 0.8, 4.0, 4.0 )\ny = base.dists.kumaraswamy.logcdf( -0.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.logcdf( 1.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.logcdf( 2.0, -1.0, 0.5 )\ny = base.dists.kumaraswamy.logcdf( 2.0, 0.5, -1.0 )\ny = base.dists.kumaraswamy.logcdf( NaN, 1.0, 1.0 )\ny = base.dists.kumaraswamy.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.kumaraswamy.logcdf( 0.0, 1.0, NaN )\n",
	"base.dists.kumaraswamy.logpdf": "y = base.dists.kumaraswamy.logpdf( 0.5, 1.0, 1.0 )\ny = base.dists.kumaraswamy.logpdf( 0.5, 2.0, 4.0 )\ny = base.dists.kumaraswamy.logpdf( 0.2, 2.0, 2.0 )\ny = base.dists.kumaraswamy.logpdf( 0.8, 4.0, 4.0 )\ny = base.dists.kumaraswamy.logpdf( -0.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.logpdf( 1.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.logpdf( 2.0, -1.0, 0.5 )\ny = base.dists.kumaraswamy.logpdf( 2.0, 0.5, -1.0 )\ny = base.dists.kumaraswamy.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.kumaraswamy.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.kumaraswamy.logpdf( 0.0, 1.0, NaN )\n",
	"base.dists.kumaraswamy.mean": "v = base.dists.kumaraswamy.mean( 1.5, 1.5 )\nv = base.dists.kumaraswamy.mean( 4.0, 12.0 )\nv = base.dists.kumaraswamy.mean( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.median": "v = base.dists.kumaraswamy.median( 1.0, 1.0 )\nv = base.dists.kumaraswamy.median( 4.0, 12.0 )\nv = base.dists.kumaraswamy.median( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.mode": "v = base.dists.kumaraswamy.mode( 1.5, 1.5 )\nv = base.dists.kumaraswamy.mode( 4.0, 12.0 )\nv = base.dists.kumaraswamy.mode( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.pdf": "y = base.dists.kumaraswamy.pdf( 0.5, 1.0, 1.0 )\ny = base.dists.kumaraswamy.pdf( 0.5, 2.0, 4.0 )\ny = base.dists.kumaraswamy.pdf( 0.2, 2.0, 2.0 )\ny = base.dists.kumaraswamy.pdf( 0.8, 4.0, 4.0 )\ny = base.dists.kumaraswamy.pdf( -0.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.pdf( 1.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.pdf( 2.0, -1.0, 0.5 )\ny = base.dists.kumaraswamy.pdf( 2.0, 0.5, -1.0 )\ny = base.dists.kumaraswamy.pdf( NaN, 1.0, 1.0 )\ny = base.dists.kumaraswamy.pdf( 0.0, NaN, 1.0 )\ny = base.dists.kumaraswamy.pdf( 0.0, 1.0, NaN )\n",
	"base.dists.kumaraswamy.quantile": "y = base.dists.kumaraswamy.quantile( 0.5, 1.0, 1.0 )\ny = base.dists.kumaraswamy.quantile( 0.5, 2.0, 4.0 )\ny = base.dists.kumaraswamy.quantile( 0.2, 2.0, 2.0 )\ny = base.dists.kumaraswamy.quantile( 0.8, 4.0, 4.0 )\ny = base.dists.kumaraswamy.quantile( -0.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.quantile( 1.5, 4.0, 2.0 )\ny = base.dists.kumaraswamy.quantile( 2.0, -1.0, 0.5 )\ny = base.dists.kumaraswamy.quantile( 2.0, 0.5, -1.0 )\ny = base.dists.kumaraswamy.quantile( NaN, 1.0, 1.0 )\ny = base.dists.kumaraswamy.quantile( 0.0, NaN, 1.0 )\ny = base.dists.kumaraswamy.quantile( 0.0, 1.0, NaN )\n",
	"base.dists.kumaraswamy.skewness": "v = base.dists.kumaraswamy.skewness( 1.0, 1.0 )\nv = base.dists.kumaraswamy.skewness( 4.0, 12.0 )\nv = base.dists.kumaraswamy.skewness( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.stdev": "v = base.dists.kumaraswamy.stdev( 1.0, 1.0 )\nv = base.dists.kumaraswamy.stdev( 4.0, 12.0 )\nv = base.dists.kumaraswamy.stdev( 16.0, 8.0 )\n",
	"base.dists.kumaraswamy.variance": "v = base.dists.kumaraswamy.variance( 1.0, 1.0 )\nv = base.dists.kumaraswamy.variance( 4.0, 12.0 )\nv = base.dists.kumaraswamy.variance( 16.0, 8.0 )\n",
	"base.dists.laplace.cdf": "y = base.dists.laplace.cdf( 2.0, 0.0, 1.0 )\ny = base.dists.laplace.cdf( 5.0, 10.0, 3.0 )\ny = base.dists.laplace.cdf( NaN, 0.0, 1.0 )\ny = base.dists.laplace.cdf( 2, NaN, 1.0 )\ny = base.dists.laplace.cdf( 2.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.laplace.cdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.laplace.entropy": "y = base.dists.laplace.entropy( 0.0, 1.0 )\ny = base.dists.laplace.entropy( 4.0, 2.0 )\ny = base.dists.laplace.entropy( NaN, 1.0 )\ny = base.dists.laplace.entropy( 0.0, NaN )\ny = base.dists.laplace.entropy( 0.0, 0.0 )\n",
	"base.dists.laplace.kurtosis": "y = base.dists.laplace.kurtosis( 0.0, 1.0 )\ny = base.dists.laplace.kurtosis( 4.0, 2.0 )\ny = base.dists.laplace.kurtosis( NaN, 1.0 )\ny = base.dists.laplace.kurtosis( 0.0, NaN )\ny = base.dists.laplace.kurtosis( 0.0, 0.0 )\n",
	"base.dists.laplace.Laplace": "laplace = base.dists.laplace.Laplace( -2.0, 3.0 );\nlaplace.mu\nlaplace.b\nlaplace.entropy\nlaplace.kurtosis\nlaplace.mean\nlaplace.median\nlaplace.mode\nlaplace.skewness\nlaplace.stdev\nlaplace.variance\nlaplace.cdf( 0.8 )\nlaplace.logcdf( 0.8 )\nlaplace.logpdf( 1.0 )\nlaplace.mgf( 0.2 )\nlaplace.pdf( 2.0 )\nlaplace.quantile( 0.9 )\n",
	"base.dists.laplace.logcdf": "y = base.dists.laplace.logcdf( 2.0, 0.0, 1.0 )\ny = base.dists.laplace.logcdf( 5.0, 10.0, 3.0 )\ny = base.dists.laplace.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.laplace.logcdf( 2, NaN, 1.0 )\ny = base.dists.laplace.logcdf( 2.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.laplace.logcdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.laplace.logpdf": "y = base.dists.laplace.logpdf( 2.0, 0.0, 1.0 )\ny = base.dists.laplace.logpdf( -1.0, 2.0, 3.0 )\ny = base.dists.laplace.logpdf( 2.5, 2.0, 3.0 )\ny = base.dists.laplace.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.laplace.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.laplace.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.laplace.logpdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.laplace.mean": "y = base.dists.laplace.mean( 0.0, 1.0 )\ny = base.dists.laplace.mean( 4.0, 2.0 )\ny = base.dists.laplace.mean( NaN, 1.0 )\ny = base.dists.laplace.mean( 0.0, NaN )\ny = base.dists.laplace.mean( 0.0, 0.0 )\n",
	"base.dists.laplace.median": "y = base.dists.laplace.median( 0.0, 1.0 )\ny = base.dists.laplace.median( 4.0, 2.0 )\ny = base.dists.laplace.median( NaN, 1.0 )\ny = base.dists.laplace.median( 0.0, NaN )\ny = base.dists.laplace.median( 0.0, 0.0 )\n",
	"base.dists.laplace.mgf": "y = base.dists.laplace.mgf( 0.5, 0.0, 1.0 )\ny = base.dists.laplace.mgf( 0.0, 0.0, 1.0 )\ny = base.dists.laplace.mgf( -1.0, 4.0, 0.2 )\ny = base.dists.laplace.mgf( NaN, 0.0, 1.0 )\ny = base.dists.laplace.mgf( 0.0, NaN, 1.0 )\ny = base.dists.laplace.mgf( 0.0, 0.0, NaN )\ny = base.dists.laplace.mgf( 1.0, 0.0, 2.0 )\ny = base.dists.laplace.mgf( -0.5, 0.0, 4.0 )\ny = base.dists.laplace.mgf( 2.0, 0.0, 0.0 )\ny = base.dists.laplace.mgf( 2.0, 0.0, -1.0 )\n",
	"base.dists.laplace.mode": "y = base.dists.laplace.mode( 0.0, 1.0 )\ny = base.dists.laplace.mode( 4.0, 2.0 )\ny = base.dists.laplace.mode( NaN, 1.0 )\ny = base.dists.laplace.mode( 0.0, NaN )\ny = base.dists.laplace.mode( 0.0, 0.0 )\n",
	"base.dists.laplace.pdf": "y = base.dists.laplace.pdf( 2.0, 0.0, 1.0 )\ny = base.dists.laplace.pdf( -1.0, 2.0, 3.0 )\ny = base.dists.laplace.pdf( 2.5, 2.0, 3.0 )\ny = base.dists.laplace.pdf( NaN, 0.0, 1.0 )\ny = base.dists.laplace.pdf( 0.0, NaN, 1.0 )\ny = base.dists.laplace.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.laplace.pdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.laplace.quantile": "y = base.dists.laplace.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.laplace.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.laplace.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.laplace.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.laplace.quantile( NaN, 0.0, 1.0 )\ny = base.dists.laplace.quantile( 0.0, NaN, 1.0 )\ny = base.dists.laplace.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.laplace.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.laplace.skewness": "y = base.dists.laplace.skewness( 0.0, 1.0 )\ny = base.dists.laplace.skewness( 4.0, 2.0 )\ny = base.dists.laplace.skewness( NaN, 1.0 )\ny = base.dists.laplace.skewness( 0.0, NaN )\ny = base.dists.laplace.skewness( 0.0, 0.0 )\n",
	"base.dists.laplace.stdev": "y = base.dists.laplace.stdev( 0.0, 1.0 )\ny = base.dists.laplace.stdev( 4.0, 2.0 )\ny = base.dists.laplace.stdev( NaN, 1.0 )\ny = base.dists.laplace.stdev( 0.0, NaN )\ny = base.dists.laplace.stdev( 0.0, 0.0 )\n",
	"base.dists.laplace.variance": "y = base.dists.laplace.variance( 0.0, 1.0 )\ny = base.dists.laplace.variance( 4.0, 2.0 )\ny = base.dists.laplace.variance( NaN, 1.0 )\ny = base.dists.laplace.variance( 0.0, NaN )\ny = base.dists.laplace.variance( 0.0, 0.0 )\n",
	"base.dists.levy.cdf": "y = base.dists.levy.cdf( 2.0, 0.0, 1.0 )\ny = base.dists.levy.cdf( 12.0, 10.0, 3.0 )\ny = base.dists.levy.cdf( 9.0, 10.0, 3.0 )\ny = base.dists.levy.cdf( NaN, 0.0, 1.0 )\ny = base.dists.levy.cdf( 2, NaN, 1.0 )\ny = base.dists.levy.cdf( 2.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.levy.cdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.levy.entropy": "y = base.dists.levy.entropy( 0.0, 1.0 )\ny = base.dists.levy.entropy( 4.0, 2.0 )\ny = base.dists.levy.entropy( NaN, 1.0 )\ny = base.dists.levy.entropy( 0.0, NaN )\ny = base.dists.levy.entropy( 0.0, 0.0 )\n",
	"base.dists.levy.Levy": "levy = base.dists.levy.Levy( -2.0, 3.0 );\nlevy.mu\nlevy.c\nlevy.entropy\nlevy.mean\nlevy.median\nlevy.mode\nlevy.stdev\nlevy.variance\nlevy.cdf( 0.8 )\nlevy.logcdf( 0.8 )\nlevy.logpdf( 1.0 )\nlevy.pdf( 1.0 )\nlevy.quantile( 0.8 )\n",
	"base.dists.levy.logcdf": "y = base.dists.levy.logcdf( 2.0, 0.0, 1.0 )\ny = base.dists.levy.logcdf( 12.0, 10.0, 3.0 )\ny = base.dists.levy.logcdf( 9.0, 10.0, 3.0 )\ny = base.dists.levy.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.levy.logcdf( 2, NaN, 1.0 )\ny = base.dists.levy.logcdf( 2.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.levy.logcdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.levy.logpdf": "y = base.dists.levy.logpdf( 2.0, 0.0, 1.0 )\ny = base.dists.levy.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.levy.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.levy.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.levy.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.levy.logpdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.levy.mean": "y = base.dists.levy.mean( 0.0, 1.0 )\ny = base.dists.levy.mean( 4.0, 3.0 )\ny = base.dists.levy.mean( NaN, 1.0 )\ny = base.dists.levy.mean( 0.0, NaN )\ny = base.dists.levy.mean( 0.0, 0.0 )\n",
	"base.dists.levy.median": "y = base.dists.levy.median( 0.0, 1.0 )\ny = base.dists.levy.median( 4.0, 3.0 )\ny = base.dists.levy.median( NaN, 1.0 )\ny = base.dists.levy.median( 0.0, NaN )\ny = base.dists.levy.median( 0.0, 0.0 )\n",
	"base.dists.levy.mode": "y = base.dists.levy.mode( 0.0, 1.0 )\ny = base.dists.levy.mode( 4.0, 3.0 )\ny = base.dists.levy.mode( NaN, 1.0 )\ny = base.dists.levy.mode( 0.0, NaN )\ny = base.dists.levy.mode( 0.0, 0.0 )\n",
	"base.dists.levy.pdf": "y = base.dists.levy.pdf( 2.0, 0.0, 1.0 )\ny = base.dists.levy.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.levy.pdf( NaN, 0.0, 1.0 )\ny = base.dists.levy.pdf( 0.0, NaN, 1.0 )\ny = base.dists.levy.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.levy.pdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.levy.quantile": "y = base.dists.levy.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.levy.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.levy.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.levy.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.levy.quantile( NaN, 0.0, 1.0 )\ny = base.dists.levy.quantile( 0.0, NaN, 1.0 )\ny = base.dists.levy.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.levy.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.levy.stdev": "y = base.dists.levy.stdev( 0.0, 1.0 )\ny = base.dists.levy.stdev( 4.0, 3.0 )\ny = base.dists.levy.stdev( NaN, 1.0 )\ny = base.dists.levy.stdev( 0.0, NaN )\ny = base.dists.levy.stdev( 0.0, 0.0 )\n",
	"base.dists.levy.variance": "y = base.dists.levy.variance( 0.0, 1.0 )\ny = base.dists.levy.variance( 4.0, 3.0 )\ny = base.dists.levy.variance( NaN, 1.0 )\ny = base.dists.levy.variance( 0.0, NaN )\ny = base.dists.levy.variance( 0.0, 0.0 )\n",
	"base.dists.logistic.cdf": "y = base.dists.logistic.cdf( 2.0, 0.0, 1.0 )\ny = base.dists.logistic.cdf( 5.0, 10.0, 3.0 )\ny = base.dists.logistic.cdf( 2.0, 0.0, NaN )\ny = base.dists.logistic.cdf( 2.0, NaN, 1.0 )\ny = base.dists.logistic.cdf( NaN, 0.0, 1.0 )\n\n// Degenerate distribution centered at `μ` when `s = 0.0`:\ny = base.dists.logistic.cdf( 2.0, 8.0, 0.0 )\ny = base.dists.logistic.cdf( 8.0, 8.0, 0.0 )\ny = base.dists.logistic.cdf( 10.0, 8.0, 0.0 )\n",
	"base.dists.logistic.entropy": "y = base.dists.logistic.entropy( 0.0, 1.0 )\ny = base.dists.logistic.entropy( 4.0, 2.0 )\ny = base.dists.logistic.entropy( NaN, 1.0 )\ny = base.dists.logistic.entropy( 0.0, NaN )\ny = base.dists.logistic.entropy( 0.0, 0.0 )\n",
	"base.dists.logistic.kurtosis": "y = base.dists.logistic.kurtosis( 0.0, 1.0 )\ny = base.dists.logistic.kurtosis( 4.0, 2.0 )\ny = base.dists.logistic.kurtosis( NaN, 1.0 )\ny = base.dists.logistic.kurtosis( 0.0, NaN )\ny = base.dists.logistic.kurtosis( 0.0, 0.0 )\n",
	"base.dists.logistic.logcdf": "y = base.dists.logistic.logcdf( 2.0, 0.0, 1.0 )\ny = base.dists.logistic.logcdf( 5.0, 10.0, 3.0 )\ny = base.dists.logistic.logcdf( 2.0, 0.0, NaN )\ny = base.dists.logistic.logcdf( 2, NaN, 1.0 )\ny = base.dists.logistic.logcdf( NaN, 0.0, 1.0 )\n",
	"base.dists.logistic.Logistic": "logistic = base.dists.logistic.Logistic( -2.0, 3.0 );\nlogistic.mu\nlogistic.s\nlogistic.entropy\nlogistic.kurtosis\nlogistic.mean\nlogistic.median\nlogistic.mode\nlogistic.skewness\nlogistic.stdev\nlogistic.variance\nlogistic.cdf( 0.8 )\nlogistic.logcdf( 0.8 )\nlogistic.logpdf( 2.0 )\nlogistic.mgf( 0.2 )\nlogistic.pdf( 2.0 )\nlogistic.quantile( 0.9 )\n",
	"base.dists.logistic.logpdf": "y = base.dists.logistic.logpdf( 2.0, 0.0, 1.0 )\ny = base.dists.logistic.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.logistic.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.logistic.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.logistic.logpdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.logistic.logpdf( 2.0, 0.0, -1.0 )\n\n// Degenerate distribution at `s = 0.0`:\ny = base.dists.logistic.logpdf( 2.0, 8.0, 0.0 )\ny = base.dists.logistic.logpdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.logistic.mean": "y = base.dists.logistic.mean( 0.0, 1.0 )\ny = base.dists.logistic.mean( 4.0, 2.0 )\ny = base.dists.logistic.mean( NaN, 1.0 )\ny = base.dists.logistic.mean( 0.0, NaN )\ny = base.dists.logistic.mean( 0.0, 0.0 )\n",
	"base.dists.logistic.median": "y = base.dists.logistic.median( 0.0, 1.0 )\ny = base.dists.logistic.median( 4.0, 2.0 )\ny = base.dists.logistic.median( NaN, 1.0 )\ny = base.dists.logistic.median( 0.0, NaN )\ny = base.dists.logistic.median( 0.0, 0.0 )\n",
	"base.dists.logistic.mgf": "y = base.dists.logistic.mgf( 0.9, 0.0, 1.0 )\ny = base.dists.logistic.mgf( 0.1, 4.0, 4.0 )\ny = base.dists.logistic.mgf( -0.2, 4.0, 4.0 )\ny = base.dists.logistic.mgf( 0.5, 0.0, -1.0 )\ny = base.dists.logistic.mgf( 0.5, 0.0, 4.0 )\ny = base.dists.logistic.mgf( NaN, 0.0, 1.0 )\ny = base.dists.logistic.mgf( 0.0, NaN, 1.0 )\ny = base.dists.logistic.mgf( 0.0, 0.0, NaN )\n",
	"base.dists.logistic.mode": "y = base.dists.logistic.mode( 0.0, 1.0 )\ny = base.dists.logistic.mode( 4.0, 2.0 )\ny = base.dists.logistic.mode( NaN, 1.0 )\ny = base.dists.logistic.mode( 0.0, NaN )\ny = base.dists.logistic.mode( 0.0, 0.0 )\n",
	"base.dists.logistic.pdf": "y = base.dists.logistic.pdf( 2.0, 0.0, 1.0 )\ny = base.dists.logistic.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.logistic.pdf( NaN, 0.0, 1.0 )\ny = base.dists.logistic.pdf( 0.0, NaN, 1.0 )\ny = base.dists.logistic.pdf( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.logistic.pdf( 2.0, 0.0, -1.0 )\ny = base.dists.logistic.pdf( 2.0, 8.0, 0.0 )\ny = base.dists.logistic.pdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.logistic.quantile": "y = base.dists.logistic.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.logistic.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.logistic.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.logistic.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.logistic.quantile( NaN, 0.0, 1.0 )\ny = base.dists.logistic.quantile( 0.0, NaN, 1.0 )\ny = base.dists.logistic.quantile( 0.0, 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.logistic.quantile( 0.5, 0.0, -1.0 )\n",
	"base.dists.logistic.skewness": "y = base.dists.logistic.skewness( 0.0, 1.0 )\ny = base.dists.logistic.skewness( 4.0, 2.0 )\ny = base.dists.logistic.skewness( NaN, 1.0 )\ny = base.dists.logistic.skewness( 0.0, NaN )\ny = base.dists.logistic.skewness( 0.0, 0.0 )\n",
	"base.dists.logistic.stdev": "y = base.dists.logistic.stdev( 0.0, 1.0 )\ny = base.dists.logistic.stdev( 4.0, 2.0 )\ny = base.dists.logistic.stdev( NaN, 1.0 )\ny = base.dists.logistic.stdev( 0.0, NaN )\ny = base.dists.logistic.stdev( 0.0, 0.0 )\n",
	"base.dists.logistic.variance": "y = base.dists.logistic.variance( 0.0, 1.0 )\ny = base.dists.logistic.variance( 4.0, 2.0 )\ny = base.dists.logistic.variance( NaN, 1.0 )\ny = base.dists.logistic.variance( 0.0, NaN )\ny = base.dists.logistic.variance( 0.0, 0.0 )\n",
	"base.dists.lognormal.cdf": "y = base.dists.lognormal.cdf( 2.0, 0.0, 1.0 )\ny = base.dists.lognormal.cdf( 5.0, 10.0, 3.0 )\ny = base.dists.lognormal.cdf( 2.0, 0.0, NaN )\ny = base.dists.lognormal.cdf( 2.0, NaN, 1.0 )\ny = base.dists.lognormal.cdf( NaN, 0.0, 1.0 )\n\n// Non-positive scale parameter `σ`:\ny = base.dists.lognormal.cdf( 2.0, 0.0, -1.0 )\ny = base.dists.lognormal.cdf( 2.0, 0.0, 0.0 )\n",
	"base.dists.lognormal.entropy": "y = base.dists.lognormal.entropy( 0.0, 1.0 )\ny = base.dists.lognormal.entropy( 5.0, 2.0 )\ny = base.dists.lognormal.entropy( NaN, 1.0 )\ny = base.dists.lognormal.entropy( 0.0, NaN )\ny = base.dists.lognormal.entropy( 0.0, 0.0 )\n",
	"base.dists.lognormal.kurtosis": "y = base.dists.lognormal.kurtosis( 0.0, 1.0 )\ny = base.dists.lognormal.kurtosis( 5.0, 2.0 )\ny = base.dists.lognormal.kurtosis( NaN, 1.0 )\ny = base.dists.lognormal.kurtosis( 0.0, NaN )\ny = base.dists.lognormal.kurtosis( 0.0, 0.0 )\n",
	"base.dists.lognormal.LogNormal": "lognormal = base.dists.lognormal.LogNormal( -2.0, 3.0 );\nlognormal.mu\nlognormal.sigma\nlognormal.entropy\nlognormal.kurtosis\nlognormal.mean\nlognormal.median\nlognormal.mode\nlognormal.skewness\nlognormal.stdev\nlognormal.variance\nlognormal.cdf( 0.8 )\nlognormal.logpdf( 2.0 )\nlognormal.pdf( 2.0 )\nlognormal.quantile( 0.9 )\n",
	"base.dists.lognormal.logpdf": "y = base.dists.lognormal.logpdf( 2.0, 0.0, 1.0 )\ny = base.dists.lognormal.logpdf( 1.0, 0.0, 1.0 )\ny = base.dists.lognormal.logpdf( 1.0, 3.0, 1.0 )\ny = base.dists.lognormal.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.lognormal.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.lognormal.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.lognormal.logpdf( 0.0, 0.0, NaN )\n\n// Non-positive scale parameter `σ`:\ny = base.dists.lognormal.logpdf( 2.0, 0.0, -1.0 )\ny = base.dists.lognormal.logpdf( 2.0, 0.0, 0.0 )\n",
	"base.dists.lognormal.mean": "y = base.dists.lognormal.mean( 0.0, 1.0 )\ny = base.dists.lognormal.mean( 4.0, 2.0 )\ny = base.dists.lognormal.mean( NaN, 1.0 )\ny = base.dists.lognormal.mean( 0.0, NaN )\ny = base.dists.lognormal.mean( 0.0, 0.0 )\n",
	"base.dists.lognormal.median": "y = base.dists.lognormal.median( 0.0, 1.0 )\ny = base.dists.lognormal.median( 5.0, 2.0 )\ny = base.dists.lognormal.median( NaN, 1.0 )\ny = base.dists.lognormal.median( 0.0, NaN )\ny = base.dists.lognormal.median( 0.0, 0.0 )\n",
	"base.dists.lognormal.mode": "y = base.dists.lognormal.mode( 0.0, 1.0 )\ny = base.dists.lognormal.mode( 5.0, 2.0 )\ny = base.dists.lognormal.mode( NaN, 1.0 )\ny = base.dists.lognormal.mode( 0.0, NaN )\ny = base.dists.lognormal.mode( 0.0, 0.0 )\n",
	"base.dists.lognormal.pdf": "y = base.dists.lognormal.pdf( 2.0, 0.0, 1.0 )\ny = base.dists.lognormal.pdf( 1.0, 0.0, 1.0 )\ny = base.dists.lognormal.pdf( 1.0, 3.0, 1.0 )\ny = base.dists.lognormal.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.lognormal.pdf( NaN, 0.0, 1.0 )\ny = base.dists.lognormal.pdf( 0.0, NaN, 1.0 )\ny = base.dists.lognormal.pdf( 0.0, 0.0, NaN )\n\n// Non-positive scale parameter `σ`:\ny = base.dists.lognormal.pdf( 2.0, 0.0, -1.0 )\ny = base.dists.lognormal.pdf( 2.0, 0.0, 0.0 )\n",
	"base.dists.lognormal.quantile": "y = base.dists.lognormal.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.lognormal.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.lognormal.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.lognormal.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.lognormal.quantile( NaN, 0.0, 1.0 )\ny = base.dists.lognormal.quantile( 0.0, NaN, 1.0 )\ny = base.dists.lognormal.quantile( 0.0, 0.0, NaN )\n\n// Non-positive scale parameter `σ`:\ny = base.dists.lognormal.quantile( 0.5, 0.0, -1.0 )\ny = base.dists.lognormal.quantile( 0.5, 0.0, 0.0 )\n",
	"base.dists.lognormal.skewness": "y = base.dists.lognormal.skewness( 0.0, 1.0 )\ny = base.dists.lognormal.skewness( 5.0, 2.0 )\ny = base.dists.lognormal.skewness( NaN, 1.0 )\ny = base.dists.lognormal.skewness( 0.0, NaN )\ny = base.dists.lognormal.skewness( 0.0, 0.0 )\n",
	"base.dists.lognormal.stdev": "y = base.dists.lognormal.stdev( 0.0, 1.0 )\ny = base.dists.lognormal.stdev( 4.0, 2.0 )\ny = base.dists.lognormal.stdev( NaN, 1.0 )\ny = base.dists.lognormal.stdev( 0.0, NaN )\ny = base.dists.lognormal.stdev( 0.0, 0.0 )\n",
	"base.dists.lognormal.variance": "y = base.dists.lognormal.variance( 0.0, 1.0 )\ny = base.dists.lognormal.variance( 4.0, 2.0 )\ny = base.dists.lognormal.variance( NaN, 1.0 )\ny = base.dists.lognormal.variance( 0.0, NaN )\ny = base.dists.lognormal.variance( 0.0, 0.0 )\n",
	"base.dists.negativeBinomial.cdf": "y = base.dists.negativeBinomial.cdf( 5.0, 20.0, 0.8 )\ny = base.dists.negativeBinomial.cdf( 21.0, 20.0, 0.5 )\ny = base.dists.negativeBinomial.cdf( 5.0, 10.0, 0.4 )\ny = base.dists.negativeBinomial.cdf( 0.0, 10.0, 0.9 )\ny = base.dists.negativeBinomial.cdf( 21.0, 15.5, 0.5 )\ny = base.dists.negativeBinomial.cdf( 5.0, 7.4, 0.4 )\ny = base.dists.negativeBinomial.cdf( 2.0, 0.0, 0.5 )\ny = base.dists.negativeBinomial.cdf( 2.0, -2.0, 0.5 )\ny = base.dists.negativeBinomial.cdf( NaN, 20.0, 0.5 )\ny = base.dists.negativeBinomial.cdf( 0.0, NaN, 0.5 )\ny = base.dists.negativeBinomial.cdf( 0.0, 20.0, NaN )\ny = base.dists.negativeBinomial.cdf( 2.0, 20, -1.0 )\ny = base.dists.negativeBinomial.cdf( 2.0, 20, 1.5 )\n",
	"base.dists.negativeBinomial.kurtosis": "v = base.dists.negativeBinomial.kurtosis( 100, 0.2 )\nv = base.dists.negativeBinomial.kurtosis( 20, 0.5 )\n",
	"base.dists.negativeBinomial.logpmf": "y = base.dists.negativeBinomial.logpmf( 5.0, 20.0, 0.8 )\ny = base.dists.negativeBinomial.logpmf( 21.0, 20.0, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 5.0, 10.0, 0.4 )\ny = base.dists.negativeBinomial.logpmf( 0.0, 10.0, 0.9 )\ny = base.dists.negativeBinomial.logpmf( 21.0, 15.5, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 5.0, 7.4, 0.4 )\ny = base.dists.negativeBinomial.logpmf( 2.0, 0.0, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 2.0, -2.0, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 2.0, 20, -1.0 )\ny = base.dists.negativeBinomial.logpmf( 2.0, 20, 1.5 )\ny = base.dists.negativeBinomial.logpmf( NaN, 20.0, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 0.0, NaN, 0.5 )\ny = base.dists.negativeBinomial.logpmf( 0.0, 20.0, NaN )\n",
	"base.dists.negativeBinomial.mean": "v = base.dists.negativeBinomial.mean( 100, 0.2 )\nv = base.dists.negativeBinomial.mean( 20, 0.5 )\n",
	"base.dists.negativeBinomial.mgf": "y = base.dists.negativeBinomial.mgf( 0.05, 20.0, 0.8 )\ny = base.dists.negativeBinomial.mgf( 0.1, 20.0, 0.1 )\ny = base.dists.negativeBinomial.mgf( 0.5, 10.0, 0.4 )\ny = base.dists.negativeBinomial.mgf( 0.1, 0.0, 0.5 )\ny = base.dists.negativeBinomial.mgf( 0.1, -2.0, 0.5 )\ny = base.dists.negativeBinomial.mgf( NaN, 20.0, 0.5 )\ny = base.dists.negativeBinomial.mgf( 0.0, NaN, 0.5 )\ny = base.dists.negativeBinomial.mgf( 0.0, 20.0, NaN )\ny = base.dists.negativeBinomial.mgf( 0.2, 20, -1.0 )\ny = base.dists.negativeBinomial.mgf( 0.2, 20, 1.5 )\n",
	"base.dists.negativeBinomial.mode": "v = base.dists.negativeBinomial.mode( 100, 0.2 )\nv = base.dists.negativeBinomial.mode( 20, 0.5 )\n",
	"base.dists.negativeBinomial.NegativeBinomial": "nbinomial = base.dists.negativeBinomial.NegativeBinomial( 8.0, 0.5 );\nnbinomial.r\nnbinomial.p\nnbinomial.kurtosis\nnbinomial.mean\nnbinomial.mode\nnbinomial.skewness\nnbinomial.stdev\nnbinomial.variance\nnbinomial.cdf( 2.9 )\nnbinomial.logpmf( 3.0 )\nnbinomial.mgf( 0.2 )\nnbinomial.pmf( 3.0 )\nnbinomial.quantile( 0.8 )\n",
	"base.dists.negativeBinomial.pmf": "y = base.dists.negativeBinomial.pmf( 5.0, 20.0, 0.8 )\ny = base.dists.negativeBinomial.pmf( 21.0, 20.0, 0.5 )\ny = base.dists.negativeBinomial.pmf( 5.0, 10.0, 0.4 )\ny = base.dists.negativeBinomial.pmf( 0.0, 10.0, 0.9 )\ny = base.dists.negativeBinomial.pmf( 21.0, 15.5, 0.5 )\ny = base.dists.negativeBinomial.pmf( 5.0, 7.4, 0.4 )\ny = base.dists.negativeBinomial.pmf( 2.0, 0.0, 0.5 )\ny = base.dists.negativeBinomial.pmf( 2.0, -2.0, 0.5 )\ny = base.dists.negativeBinomial.pmf( 2.0, 20, -1.0 )\ny = base.dists.negativeBinomial.pmf( 2.0, 20, 1.5 )\ny = base.dists.negativeBinomial.pmf( NaN, 20.0, 0.5 )\ny = base.dists.negativeBinomial.pmf( 0.0, NaN, 0.5 )\ny = base.dists.negativeBinomial.pmf( 0.0, 20.0, NaN )\n",
	"base.dists.negativeBinomial.quantile": "y = base.dists.negativeBinomial.quantile( 0.9, 20.0, 0.2 )\ny = base.dists.negativeBinomial.quantile( 0.9, 20.0, 0.8 )\ny = base.dists.negativeBinomial.quantile( 0.5, 10.0, 0.4 )\ny = base.dists.negativeBinomial.quantile( 0.0, 10.0, 0.9 )\ny = base.dists.negativeBinomial.quantile( 1.1, 20.0, 0.5 )\ny = base.dists.negativeBinomial.quantile( -0.1, 20.0, 0.5 )\ny = base.dists.negativeBinomial.quantile( 21.0, 15.5, 0.5 )\ny = base.dists.negativeBinomial.quantile( 5.0, 7.4, 0.4 )\ny = base.dists.negativeBinomial.quantile( 0.5, 0.0, 0.5 )\ny = base.dists.negativeBinomial.quantile( 0.5, -2.0, 0.5 )\ny = base.dists.negativeBinomial.quantile( 0.3, 20.0, -1.0 )\ny = base.dists.negativeBinomial.quantile( 0.3, 20.0, 1.5 )\ny = base.dists.negativeBinomial.quantile( NaN, 20.0, 0.5 )\ny = base.dists.negativeBinomial.quantile( 0.3, NaN, 0.5 )\ny = base.dists.negativeBinomial.quantile( 0.3, 20.0, NaN )\n",
	"base.dists.negativeBinomial.skewness": "v = base.dists.negativeBinomial.skewness( 100, 0.2 )\nv = base.dists.negativeBinomial.skewness( 20, 0.5 )\n",
	"base.dists.negativeBinomial.stdev": "v = base.dists.negativeBinomial.stdev( 100, 0.2 )\nv = base.dists.negativeBinomial.stdev( 20, 0.5 )\n",
	"base.dists.negativeBinomial.variance": "v = base.dists.negativeBinomial.variance( 100, 0.2 )\nv = base.dists.negativeBinomial.variance( 20, 0.5 )\n",
	"base.dists.normal.cdf": "y = base.dists.normal.cdf( 2.0, 0.0, 1.0 )\ny = base.dists.normal.cdf( -1.0, -1.0, 2.0 )\ny = base.dists.normal.cdf( -1.0, 4.0, 2.0 )\ny = base.dists.normal.cdf( NaN, 0.0, 1.0 )\ny = base.dists.normal.cdf( 0.0, NaN, 1.0 )\ny = base.dists.normal.cdf( 0.0, 0.0, NaN )\n\n// Negative standard deviation:\ny = base.dists.normal.cdf( 2.0, 0.0, -1.0 )\n\n// Degenerate distribution centered at `μ` when `σ = 0.0`:\ny = base.dists.normal.cdf( 2.0, 8.0, 0.0 )\ny = base.dists.normal.cdf( 8.0, 8.0, 0.0 )\ny = base.dists.normal.cdf( 10.0, 8.0, 0.0 )\n",
	"base.dists.normal.entropy": "y = base.dists.normal.entropy( 0.0, 1.0 )\ny = base.dists.normal.entropy( 4.0, 3.0 )\ny = base.dists.normal.entropy( NaN, 1.0 )\ny = base.dists.normal.entropy( 0.0, NaN )\ny = base.dists.normal.entropy( 0.0, 0.0 )\n",
	"base.dists.normal.kurtosis": "y = base.dists.normal.kurtosis( 0.0, 1.0 )\ny = base.dists.normal.kurtosis( 4.0, 3.0 )\ny = base.dists.normal.kurtosis( NaN, 1.0 )\ny = base.dists.normal.kurtosis( 0.0, NaN )\ny = base.dists.normal.kurtosis( 0.0, 0.0 )\n",
	"base.dists.normal.logpdf": "y = base.dists.normal.logpdf( 2.0, 0.0, 1.0 )\ny = base.dists.normal.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.normal.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.normal.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.normal.logpdf( 0.0, 0.0, NaN )\n\n// Negative standard deviation:\ny = base.dists.normal.logpdf( 2.0, 0.0, -1.0 )\n\n// Degenerate distribution centered at `μ` when `σ = 0.0`:\ny = base.dists.normal.logpdf( 2.0, 8.0, 0.0 )\ny = base.dists.normal.logpdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.normal.mean": "y = base.dists.normal.mean( 0.0, 1.0 )\ny = base.dists.normal.mean( 4.0, 2.0 )\ny = base.dists.normal.mean( NaN, 1.0 )\ny = base.dists.normal.mean( 0.0, NaN )\ny = base.dists.normal.mean( 0.0, 0.0 )\n",
	"base.dists.normal.median": "y = base.dists.normal.median( 0.0, 1.0 )\ny = base.dists.normal.median( 4.0, 2.0 )\ny = base.dists.normal.median( NaN, 1.0 )\ny = base.dists.normal.median( 0.0, NaN )\ny = base.dists.normal.median( 0.0, 0.0 )\n",
	"base.dists.normal.mgf": "y = base.dists.normal.mgf( 2.0, 0.0, 1.0 )\ny = base.dists.normal.mgf( 0.0, 0.0, 1.0 )\ny = base.dists.normal.mgf( -1.0, 4.0, 2.0 )\ny = base.dists.normal.mgf( NaN, 0.0, 1.0 )\ny = base.dists.normal.mgf( 0.0, NaN, 1.0 )\ny = base.dists.normal.mgf( 0.0, 0.0, NaN )\ny = base.dists.normal.mgf( 2.0, 0.0, 0.0 )\n",
	"base.dists.normal.mode": "y = base.dists.normal.mode( 0.0, 1.0 )\ny = base.dists.normal.mode( 4.0, 2.0 )\ny = base.dists.normal.mode( NaN, 1.0 )\ny = base.dists.normal.mode( 0.0, NaN )\ny = base.dists.normal.mode( 0.0, 0.0 )\n",
	"base.dists.normal.Normal": "normal = base.dists.normal.Normal( -2.0, 3.0 );\nnormal.mu\nnormal.sigma\nnormal.entropy\nnormal.kurtosis\nnormal.mean\nnormal.median\nnormal.mode\nnormal.skewness\nnormal.stdev\nnormal.variance\nnormal.cdf( 0.8 )\nnormal.logpdf( 2.0 )\nnormal.mgf( 0.2 )\nnormal.pdf( 2.0 )\nnormal.quantile( 0.9 )\n",
	"base.dists.normal.pdf": "y = base.dists.normal.pdf( 2.0, 0.0, 1.0 )\ny = base.dists.normal.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.normal.pdf( NaN, 0.0, 1.0 )\ny = base.dists.normal.pdf( 0.0, NaN, 1.0 )\ny = base.dists.normal.pdf( 0.0, 0.0, NaN )\n\n// Negative standard deviation:\ny = base.dists.normal.pdf( 2.0, 0.0, -1.0 )\n\n// Degenerate distribution centered at `μ` when `σ = 0.0`:\ny = base.dists.normal.pdf( 2.0, 8.0, 0.0 )\ny = base.dists.normal.pdf( 8.0, 8.0, 0.0 )\n",
	"base.dists.normal.quantile": "y = base.dists.normal.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.normal.quantile( 0.5, 4.0, 2.0 )\ny = base.dists.normal.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.normal.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.normal.quantile( NaN, 0.0, 1.0 )\ny = base.dists.normal.quantile( 0.0, NaN, 1.0 )\ny = base.dists.normal.quantile( 0.0, 0.0, NaN )\n\n// Negative standard deviation:\ny = base.dists.normal.quantile( 0.5, 0.0, -1.0 )\n\n// Degenerate distribution centered at `μ` when `σ = 0.0`:\ny = base.dists.normal.quantile( 0.3, 8.0, 0.0 );\ny = base.dists.normal.quantile( 0.9, 8.0, 0.0 );\n",
	"base.dists.normal.skewness": "y = base.dists.normal.skewness( 0.0, 1.0 )\ny = base.dists.normal.skewness( 4.0, 3.0 )\ny = base.dists.normal.skewness( NaN, 1.0 )\ny = base.dists.normal.skewness( 0.0, NaN )\ny = base.dists.normal.skewness( 0.0, 0.0 )\n",
	"base.dists.normal.stdev": "y = base.dists.normal.stdev( 0.0, 1.0 )\ny = base.dists.normal.stdev( 4.0, 3.0 )\ny = base.dists.normal.stdev( NaN, 1.0 )\ny = base.dists.normal.stdev( 0.0, NaN )\ny = base.dists.normal.stdev( 0.0, 0.0 )\n",
	"base.dists.normal.variance": "y = base.dists.normal.variance( 0.0, 1.0 )\ny = base.dists.normal.variance( 4.0, 3.0 )\ny = base.dists.normal.variance( NaN, 1.0 )\ny = base.dists.normal.variance( 0.0, NaN )\ny = base.dists.normal.variance( 0.0, 0.0 )\n",
	"base.dists.pareto1.cdf": "y = base.dists.pareto1.cdf( 2.0, 1.0, 1.0 )\ny = base.dists.pareto1.cdf( 5.0, 2.0, 4.0 )\ny = base.dists.pareto1.cdf( 4.0, 2.0, 2.0 )\ny = base.dists.pareto1.cdf( 1.9, 2.0, 2.0 )\ny = base.dists.pareto1.cdf( PINF, 4.0, 2.0 )\ny = base.dists.pareto1.cdf( 2.0, -1.0, 0.5 )\ny = base.dists.pareto1.cdf( 2.0, 0.5, -1.0 )\ny = base.dists.pareto1.cdf( NaN, 1.0, 1.0 )\ny = base.dists.pareto1.cdf( 0.0, NaN, 1.0 )\ny = base.dists.pareto1.cdf( 0.0, 1.0, NaN )\n",
	"base.dists.pareto1.entropy": "v = base.dists.pareto1.entropy( 0.8, 1.0 )\nv = base.dists.pareto1.entropy( 4.0, 12.0 )\nv = base.dists.pareto1.entropy( 8.0, 2.0 )\n",
	"base.dists.pareto1.kurtosis": "v = base.dists.pareto1.kurtosis( 5.0, 1.0 )\nv = base.dists.pareto1.kurtosis( 4.5, 12.0 )\nv = base.dists.pareto1.kurtosis( 8.0, 2.0 )\n",
	"base.dists.pareto1.logcdf": "y = base.dists.pareto1.logcdf( 2.0, 1.0, 1.0 )\ny = base.dists.pareto1.logcdf( 5.0, 2.0, 4.0 )\ny = base.dists.pareto1.logcdf( 4.0, 2.0, 2.0 )\ny = base.dists.pareto1.logcdf( 1.9, 2.0, 2.0 )\ny = base.dists.pareto1.logcdf( PINF, 4.0, 2.0 )\ny = base.dists.pareto1.logcdf( 2.0, -1.0, 0.5 )\ny = base.dists.pareto1.logcdf( 2.0, 0.5, -1.0 )\ny = base.dists.pareto1.logcdf( NaN, 1.0, 1.0 )\ny = base.dists.pareto1.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.pareto1.logcdf( 0.0, 1.0, NaN )\n",
	"base.dists.pareto1.logpdf": "y = base.dists.pareto1.logpdf( 4.0, 1.0, 1.0 )\ny = base.dists.pareto1.logpdf( 20.0, 1.0, 10.0 )\ny = base.dists.pareto1.logpdf( 7.0, 2.0, 6.0 )\ny = base.dists.pareto1.logpdf( 7.0, 6.0, 3.0 )\ny = base.dists.pareto1.logpdf( 1.0, 4.0, 2.0 )\ny = base.dists.pareto1.logpdf( 1.5, 4.0, 2.0 )\ny = base.dists.pareto1.logpdf( 0.5, -1.0, 0.5 )\ny = base.dists.pareto1.logpdf( 0.5, 0.5, -1.0 )\ny = base.dists.pareto1.logpdf( NaN, 1.0, 1.0 )\ny = base.dists.pareto1.logpdf( 0.5, NaN, 1.0 )\ny = base.dists.pareto1.logpdf( 0.5, 1.0, NaN )\n",
	"base.dists.pareto1.mean": "v = base.dists.pareto1.mean( 0.8, 1.0 )\nv = base.dists.pareto1.mean( 4.0, 12.0 )\nv = base.dists.pareto1.mean( 8.0, 2.0 )\n",
	"base.dists.pareto1.median": "v = base.dists.pareto1.median( 0.8, 1.0 )\nv = base.dists.pareto1.median( 4.0, 12.0 )\nv = base.dists.pareto1.median( 8.0, 2.0 )\n",
	"base.dists.pareto1.mode": "v = base.dists.pareto1.mode( 0.8, 1.0 )\nv = base.dists.pareto1.mode( 4.0, 12.0 )\nv = base.dists.pareto1.mode( 8.0, 2.0 )\n",
	"base.dists.pareto1.Pareto1": "pareto1 = base.dists.pareto1.Pareto1( 6.0, 5.0 );\npareto1.alpha\npareto1.beta\npareto1.entropy\npareto1.kurtosis\npareto1.mean\npareto1.median\npareto1.mode\npareto1.skewness\npareto1.variance\npareto1.cdf( 7.0 )\npareto1.logcdf( 7.0 )\npareto1.logpdf( 5.0 )\npareto1.pdf( 5.0 )\npareto1.quantile( 0.8 )\n",
	"base.dists.pareto1.pdf": "y = base.dists.pareto1.pdf( 4.0, 1.0, 1.0 )\ny = base.dists.pareto1.pdf( 20.0, 1.0, 10.0 )\ny = base.dists.pareto1.pdf( 7.0, 2.0, 6.0 )\ny = base.dists.pareto1.pdf( 7.0, 6.0, 3.0 )\ny = base.dists.pareto1.pdf( 1.0, 4.0, 2.0 )\ny = base.dists.pareto1.pdf( 1.5, 4.0, 2.0 )\ny = base.dists.pareto1.pdf( 0.5, -1.0, 0.5 )\ny = base.dists.pareto1.pdf( 0.5, 0.5, -1.0 )\ny = base.dists.pareto1.pdf( NaN, 1.0, 1.0 )\ny = base.dists.pareto1.pdf( 0.5, NaN, 1.0 )\ny = base.dists.pareto1.pdf( 0.5, 1.0, NaN )\n",
	"base.dists.pareto1.quantile": "y = base.dists.pareto1.quantile( 0.8, 2.0, 1.0 )\ny = base.dists.pareto1.quantile( 0.8, 1.0, 10.0 )\ny = base.dists.pareto1.quantile( 0.1, 1.0, 10.0 )\ny = base.dists.pareto1.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.pareto1.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.pareto1.quantile( NaN, 1.0, 1.0 )\ny = base.dists.pareto1.quantile( 0.5, NaN, 1.0 )\ny = base.dists.pareto1.quantile( 0.5, 1.0, NaN )\ny = base.dists.pareto1.quantile( 0.5, -1.0, 1.0 )\ny = base.dists.pareto1.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.pareto1.skewness": "v = base.dists.pareto1.skewness( 3.5, 1.0 )\nv = base.dists.pareto1.skewness( 4.0, 12.0 )\nv = base.dists.pareto1.skewness( 8.0, 2.0 )\n",
	"base.dists.pareto1.variance": "v = base.dists.pareto1.variance( 0.8, 1.0 )\nv = base.dists.pareto1.variance( 4.0, 12.0 )\nv = base.dists.pareto1.variance( 8.0, 2.0 )\n",
	"base.dists.poisson.cdf": "y = base.dists.poisson.cdf( 2.0, 0.5 )\ny = base.dists.poisson.cdf( 2.0, 10.0 )\ny = base.dists.poisson.cdf( -1.0, 4.0 )\ny = base.dists.poisson.cdf( NaN, 1.0 )\ny = base.dists.poisson.cdf( 0.0, NaN )\n\n// Negative mean parameter:\ny = base.dists.poisson.cdf( 2.0, -1.0 )\n\n// Degenerate distribution at `λ = 0`:\ny = base.dists.poisson.cdf( -2.0, 0.0 );\ny = base.dists.poisson.cdf( 0.0, 0.0 );\ny = base.dists.poisson.cdf( 10.0, 0.0 );\n",
	"base.dists.poisson.entropy": "v = base.dists.poisson.entropy( 11.0 )\nv = base.dists.poisson.entropy( 4.5 )\n",
	"base.dists.poisson.kurtosis": "v = base.dists.poisson.kurtosis( 11.0 )\nv = base.dists.poisson.kurtosis( 4.5 )\n",
	"base.dists.poisson.logpmf": "y = base.dists.poisson.logpmf( 4.0, 3.0 )\ny = base.dists.poisson.logpmf( 1.0, 3.0 )\ny = base.dists.poisson.logpmf( -1.0, 2.0 )\ny = base.dists.poisson.logpmf( 0.0, NaN )\ny = base.dists.poisson.logpmf( NaN, 0.5 )\n\n// Negative mean parameter:\ny = base.dists.poisson.logpmf( 2.0, -0.5 )\n\n// Degenerate distribution at `λ = 0`:\ny = base.dists.poisson.logpmf( 2.0, 0.0 )\ny = base.dists.poisson.logpmf( 0.0, 0.0 )\n",
	"base.dists.poisson.mean": "v = base.dists.poisson.mean( 11.0 )\nv = base.dists.poisson.mean( 4.5 )\n",
	"base.dists.poisson.median": "v = base.dists.poisson.median( 11.0 )\nv = base.dists.poisson.median( 4.5 )\n",
	"base.dists.poisson.mode": "v = base.dists.poisson.mode( 11.0 )\nv = base.dists.poisson.mode( 4.5 )\n",
	"base.dists.poisson.pmf": "y = base.dists.poisson.pmf( 4.0, 3.0 )\ny = base.dists.poisson.pmf( 1.0, 3.0 )\ny = base.dists.poisson.pmf( -1.0, 2.0 )\ny = base.dists.poisson.pmf( 0.0, NaN )\ny = base.dists.poisson.pmf( NaN, 0.5 )\n\n// Negative mean parameter:\ny = base.dists.poisson.pmf( 2.0, -0.5 )\n\n// Degenerate distribution at `λ = 0`:\ny = base.dists.poisson.pmf( 2.0, 0.0 )\ny = base.dists.poisson.pmf( 0.0, 0.0 )\n",
	"base.dists.poisson.Poisson": "poisson = base.dists.poisson.Poisson( 6.0 );\npoisson.lambda\npoisson.entropy\npoisson.kurtosis\npoisson.mean\npoisson.median\npoisson.mode\npoisson.skewness\npoisson.stdev\npoisson.variance\npoisson.cdf( 4.0 )\npoisson.logpmf( 2.0 )\npoisson.mgf( 0.5 )\npoisson.pmf( 2.0 )\npoisson.quantile( 0.5 )\n",
	"base.dists.poisson.quantile": "y = base.dists.poisson.quantile( 0.5, 2.0 )\ny = base.dists.poisson.quantile( 0.9, 4.0 )\ny = base.dists.poisson.quantile( 0.1, 200.0 )\ny = base.dists.poisson.quantile( 1.1, 0.0 )\ny = base.dists.poisson.quantile( -0.2, 0.0 )\ny = base.dists.poisson.quantile( NaN, 0.5 )\ny = base.dists.poisson.quantile( 0.0, NaN )\n\n// Negative mean parameter:\ny = base.dists.poisson.quantile( 2.0, -1.0 )\n\n// Degenerate distribution at `λ = 0`:\ny = base.dists.poisson.quantile( 0.1, 0.0 );\ny = base.dists.poisson.quantile( 0.9, 0.0 );\n",
	"base.dists.poisson.skewness": "v = base.dists.poisson.skewness( 11.0 )\nv = base.dists.poisson.skewness( 4.5 )\n",
	"base.dists.poisson.stdev": "v = base.dists.poisson.stdev( 11.0 )\nv = base.dists.poisson.stdev( 4.5 )\n",
	"base.dists.poisson.variance": "v = base.dists.poisson.variance( 11.0 )\nv = base.dists.poisson.variance( 4.5 )\n",
	"base.dists.rayleigh.cdf": "y = base.dists.rayleigh.cdf( 2.0, 3.0 )\ny = base.dists.rayleigh.cdf( 1.0, 2.0 )\ny = base.dists.rayleigh.cdf( -1.0, 4.0 )\ny = base.dists.rayleigh.cdf( NaN, 1.0 )\ny = base.dists.rayleigh.cdf( 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.rayleigh.cdf( 2.0, -1.0 )\n\n// Degenerate distribution when `sigma = 0.0`:\ny = base.dists.rayleigh.cdf( -2.0, 0.0 );\ny = base.dists.rayleigh.cdf( 0.0, 0.0 );\ny = base.dists.rayleigh.cdf( 2.0, 0.0 );\n",
	"base.dists.rayleigh.entropy": "v = base.dists.rayleigh.entropy( 11.0 )\nv = base.dists.rayleigh.entropy( 4.5 )\n",
	"base.dists.rayleigh.kurtosis": "v = base.dists.rayleigh.kurtosis( 11.0 )\nv = base.dists.rayleigh.kurtosis( 4.5 )\n",
	"base.dists.rayleigh.logcdf": "y = base.dists.rayleigh.logcdf( 2.0, 3.0 )\ny = base.dists.rayleigh.logcdf( 1.0, 2.0 )\ny = base.dists.rayleigh.logcdf( -1.0, 4.0 )\ny = base.dists.rayleigh.logcdf( NaN, 1.0 )\ny = base.dists.rayleigh.logcdf( 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.rayleigh.logcdf( 2.0, -1.0 )\n",
	"base.dists.rayleigh.logpdf": "y = base.dists.rayleigh.logpdf( 0.3, 1.0 )\ny = base.dists.rayleigh.logpdf( 2.0, 0.8 )\ny = base.dists.rayleigh.logpdf( -1.0, 0.5 )\ny = base.dists.rayleigh.logpdf( 0.0, NaN )\ny = base.dists.rayleigh.logpdf( NaN, 2.0 )\n\n// Negative scale parameter:\ny = base.dists.rayleigh.logpdf( 2.0, -1.0 )\n",
	"base.dists.rayleigh.mean": "v = base.dists.rayleigh.mean( 11.0 )\nv = base.dists.rayleigh.mean( 4.5 )\n",
	"base.dists.rayleigh.median": "v = base.dists.rayleigh.median( 11.0 )\nv = base.dists.rayleigh.median( 4.5 )\n",
	"base.dists.rayleigh.mgf": "y = base.dists.rayleigh.mgf( 1.0, 3.0 )\ny = base.dists.rayleigh.mgf( 1.0, 2.0 )\ny = base.dists.rayleigh.mgf( -1.0, 4.0 )\ny = base.dists.rayleigh.mgf( NaN, 1.0 )\ny = base.dists.rayleigh.mgf( 0.0, NaN )\ny = base.dists.rayleigh.mgf( 0.5, -1.0 )\n",
	"base.dists.rayleigh.mode": "v = base.dists.rayleigh.mode( 11.0 )\nv = base.dists.rayleigh.mode( 4.5 )\n",
	"base.dists.rayleigh.pdf": "y = base.dists.rayleigh.pdf( 0.3, 1.0 )\ny = base.dists.rayleigh.pdf( 2.0, 0.8 )\ny = base.dists.rayleigh.pdf( -1.0, 0.5 )\ny = base.dists.rayleigh.pdf( 0.0, NaN )\ny = base.dists.rayleigh.pdf( NaN, 2.0 )\n\n// Negative scale parameter:\ny = base.dists.rayleigh.pdf( 2.0, -1.0 )\n\n// Degenerate distribution when `sigma = 0.0`:\ny = base.dists.rayleigh.pdf( -2.0, 0.0 )\ny = base.dists.rayleigh.pdf( 0.0, 0.0 )\ny = base.dists.rayleigh.pdf( 2.0, 0.0 )\n",
	"base.dists.rayleigh.Rayleigh": "rayleigh = base.dists.rayleigh.Rayleigh( 6.0 );\nrayleigh.sigma\nrayleigh.entropy\nrayleigh.kurtosis\nrayleigh.mean\nrayleigh.median\nrayleigh.mode\nrayleigh.skewness\nrayleigh.stdev\nrayleigh.variance\nrayleigh.cdf( 1.0 )\nrayleigh.logcdf( 1.0 )\nrayleigh.logpdf( 1.5 )\nrayleigh.mgf( -0.5 )\nrayleigh.pdf( 1.5 )\nrayleigh.quantile( 0.5 )\n",
	"base.dists.rayleigh.quantile": "y = base.dists.rayleigh.quantile( 0.8, 1.0 )\ny = base.dists.rayleigh.quantile( 0.5, 4.0 )\ny = base.dists.rayleigh.quantile( 1.1, 1.0 )\ny = base.dists.rayleigh.quantile( -0.2, 1.0 )\ny = base.dists.rayleigh.quantile( NaN, 1.0 )\ny = base.dists.rayleigh.quantile( 0.0, NaN )\n\n// Negative scale parameter:\ny = base.dists.rayleigh.quantile( 0.5, -1.0 )\n",
	"base.dists.rayleigh.skewness": "v = base.dists.rayleigh.skewness( 11.0 )\nv = base.dists.rayleigh.skewness( 4.5 )\n",
	"base.dists.rayleigh.stdev": "v = base.dists.rayleigh.stdev( 9.0 )\nv = base.dists.rayleigh.stdev( 4.5 )\n",
	"base.dists.rayleigh.variance": "v = base.dists.rayleigh.variance( 9.0 )\nv = base.dists.rayleigh.variance( 4.5 )\n",
	"base.dists.t.cdf": "y = base.dists.t.cdf( 2.0, 0.1 )\ny = base.dists.t.cdf( 1.0, 2.0 )\ny = base.dists.t.cdf( -1.0, 4.0 )\ny = base.dists.t.cdf( NaN, 1.0 )\ny = base.dists.t.cdf( 0.0, NaN )\ny = base.dists.t.cdf( 2.0, -1.0 )\n",
	"base.dists.t.entropy": "v = base.dists.t.entropy( 11.0 )\nv = base.dists.t.entropy( 4.5 )\n",
	"base.dists.t.kurtosis": "v = base.dists.t.kurtosis( 11.0 )\nv = base.dists.t.kurtosis( 4.5 )\n",
	"base.dists.t.mean": "v = base.dists.t.mean( 11.0 )\nv = base.dists.t.mean( 4.5 )\n",
	"base.dists.t.median": "v = base.dists.t.median( 11.0 )\nv = base.dists.t.median( 4.5 )\n",
	"base.dists.t.mode": "v = base.dists.t.mode( 11.0 )\nv = base.dists.t.mode( 4.5 )\n",
	"base.dists.t.pdf": "y = base.dists.t.pdf( 0.3, 4.0 )\ny = base.dists.t.pdf( 2.0, 0.7 )\ny = base.dists.t.pdf( -1.0, 0.5 )\ny = base.dists.t.pdf( 0.0, NaN )\ny = base.dists.t.pdf( NaN, 2.0 )\ny = base.dists.t.pdf( 2.0, -1.0 )\n",
	"base.dists.t.T": "t = base.dists.t.T( 6.0 );\nt.v\nt.entropy\nt.kurtosis\nt.mean\nt.median\nt.mode\nt.skewness\nt.stdev\nt.variance\nt.cdf( 1.0 )\nt.logcdf( 1.0 )\nt.logpdf( 1.5 )\nt.pdf( 1.5 )\nt.quantile( 0.8 )\n",
	"base.dists.t.quantile": "y = base.dists.t.quantile( 0.8, 1.0 )\ny = base.dists.t.quantile( 0.1, 1.0 )\ny = base.dists.t.quantile( 0.5, 0.1 )\ny = base.dists.t.quantile( -0.2, 0.1 )\ny = base.dists.t.quantile( NaN, 1.0 )\ny = base.dists.t.quantile( 0.0, NaN )\ny = base.dists.t.quantile( 0.5, -1.0 )\n",
	"base.dists.t.skewness": "v = base.dists.t.skewness( 11.0 )\nv = base.dists.t.skewness( 4.5 )\n",
	"base.dists.t.stdev": "v = base.dists.t.stdev( 9.0 )\nv = base.dists.t.stdev( 4.5 )\n",
	"base.dists.t.variance": "v = base.dists.t.variance( 9.0 )\nv = base.dists.t.variance( 4.5 )\n",
	"base.dists.triangular.cdf": "y = base.dists.triangular.cdf( 0.5, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.cdf( 0.5, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.cdf( -10.0, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.cdf( -2.0, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.cdf( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.cdf( 0.0, NaN, 1.0, 0.5 )\ny = base.dists.triangular.cdf( 0.0, 0.0, NaN, 0.5 )\ny = base.dists.triangular.cdf( 2.0, 1.0, 0.0, NaN )\ny = base.dists.triangular.cdf( 2.0, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.entropy": "v = base.dists.triangular.entropy( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.entropy( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.entropy( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.kurtosis": "v = base.dists.triangular.kurtosis( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.kurtosis( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.kurtosis( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.logcdf": "y = base.dists.triangular.logcdf( 0.5, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.logcdf( 0.5, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.logcdf( -10.0, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.logcdf( -2.0, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.logcdf( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.logcdf( 0.0, NaN, 1.0, 0.5 )\ny = base.dists.triangular.logcdf( 0.0, 0.0, NaN, 0.5 )\ny = base.dists.triangular.logcdf( 2.0, 1.0, 0.0, NaN )\ny = base.dists.triangular.logcdf( 2.0, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.logpdf": "y = base.dists.triangular.logpdf( 0.5, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.logpdf( 0.5, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.logpdf( -10.0, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.logpdf( -2.0, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.logpdf( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.logpdf( 0.0, NaN, 1.0, 0.5 )\ny = base.dists.triangular.logpdf( 0.0, 0.0, NaN, 0.5 )\ny = base.dists.triangular.logpdf( 2.0, 1.0, 0.0, NaN )\ny = base.dists.triangular.logpdf( 2.0, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.mean": "v = base.dists.triangular.mean( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.mean( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.mean( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.median": "v = base.dists.triangular.median( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.median( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.median( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.mgf": "y = base.dists.triangular.mgf( 0.5, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.mgf( 0.5, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.mgf( -0.3, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.mgf( -2.0, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.mgf( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.mgf( 0.0, NaN, 1.0, 0.5 )\ny = base.dists.triangular.mgf( 0.0, 0.0, NaN, 0.5 )\ny = base.dists.triangular.mgf( 0.5, 1.0, 0.0, NaN )\ny = base.dists.triangular.mgf( 0.5, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.mode": "v = base.dists.triangular.mode( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.mode( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.mode( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.pdf": "y = base.dists.triangular.pdf( 0.5, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.pdf( 0.5, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.pdf( -10.0, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.pdf( -2.0, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.pdf( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.pdf( 0.0, NaN, 1.0, 0.5 )\ny = base.dists.triangular.pdf( 0.0, 0.0, NaN, 0.5 )\ny = base.dists.triangular.pdf( 2.0, 1.0, 0.0, NaN )\ny = base.dists.triangular.pdf( 2.0, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.quantile": "y = base.dists.triangular.quantile( 0.9, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.quantile( 0.1, -1.0, 1.0, 0.5 )\ny = base.dists.triangular.quantile( 0.1, -20.0, 0.0, -2.0 )\ny = base.dists.triangular.quantile( 0.8, 0.0, 20.0, 0.0 )\ny = base.dists.triangular.quantile( 1.1, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.quantile( -0.1, -1.0, 1.0, 0.0 )\ny = base.dists.triangular.quantile( NaN, 0.0, 1.0, 0.5 )\ny = base.dists.triangular.quantile( 0.3, NaN, 1.0, 0.5 )\ny = base.dists.triangular.quantile( 0.3, 0.0, NaN, 0.5 )\ny = base.dists.triangular.quantile( 0.3, 1.0, 0.0, NaN )\ny = base.dists.triangular.quantile( 0.3, 1.0, 0.0, 1.5 )\n",
	"base.dists.triangular.skewness": "v = base.dists.triangular.skewness( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.skewness( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.skewness( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.stdev": "v = base.dists.triangular.stdev( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.stdev( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.stdev( 2.0, 8.0, 5.0 )\n",
	"base.dists.triangular.Triangular": "triangular = base.dists.triangular.Triangular( 0.0, 1.0, 0.5 );\ntriangular.a\ntriangular.b\ntriangular.c\ntriangular.entropy\ntriangular.kurtosis\ntriangular.mean\ntriangular.median\ntriangular.mode\ntriangular.skewness\ntriangular.stdev\ntriangular.variance\ntriangular.cdf( 0.8 )\ntriangular.logcdf( 0.8 )\ntriangular.logpdf( 0.8 )\ntriangular.mgf( 0.8 )\ntriangular.pdf( 0.8 )\ntriangular.quantile( 0.8 )\n",
	"base.dists.triangular.variance": "v = base.dists.triangular.variance( 0.0, 1.0, 0.8 )\nv = base.dists.triangular.variance( 4.0, 12.0, 5.0 )\nv = base.dists.triangular.variance( 2.0, 8.0, 5.0 )\n",
	"base.dists.uniform.cdf": "y = base.dists.uniform.cdf( 9.0, 0.0, 10.0 )\ny = base.dists.uniform.cdf( 0.5, 0.0, 2.0 )\ny = base.dists.uniform.cdf( PINF, 2.0, 4.0 )\ny = base.dists.uniform.cdf( NINF, 2.0, 4.0 )\ny = base.dists.uniform.cdf( NaN, 0.0, 1.0 )\ny = base.dists.uniform.cdf( 0.0, NaN, 1.0 )\ny = base.dists.uniform.cdf( 0.0, 0.0, NaN )\ny = base.dists.uniform.cdf( 2.0, 1.0, 0.0 )\n",
	"base.dists.uniform.entropy": "v = base.dists.uniform.entropy( 0.0, 1.0 )\nv = base.dists.uniform.entropy( 4.0, 12.0 )\nv = base.dists.uniform.entropy( 2.0, 8.0 )\n",
	"base.dists.uniform.kurtosis": "v = base.dists.uniform.kurtosis( 0.0, 1.0 )\nv = base.dists.uniform.kurtosis( 4.0, 12.0 )\nv = base.dists.uniform.kurtosis( 2.0, 8.0 )\n",
	"base.dists.uniform.logcdf": "y = base.dists.uniform.logcdf( 9.0, 0.0, 10.0 )\ny = base.dists.uniform.logcdf( 0.5, 0.0, 2.0 )\ny = base.dists.uniform.logcdf( PINF, 2.0, 4.0 )\ny = base.dists.uniform.logcdf( NINF, 2.0, 4.0 )\ny = base.dists.uniform.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.uniform.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.uniform.logcdf( 0.0, 0.0, NaN )\ny = base.dists.uniform.logcdf( 2.0, 1.0, 0.0 )\n",
	"base.dists.uniform.logpdf": "y = base.dists.uniform.logpdf( 2.0, 0.0, 4.0 )\ny = base.dists.uniform.logpdf( 5.0, 0.0, 4.0 )\ny = base.dists.uniform.logpdf( 0.25, 0.0, 1.0 )\ny = base.dists.uniform.logpdf( NaN, 0.0, 1.0 )\ny = base.dists.uniform.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.uniform.logpdf( 0.0, 0.0, NaN )\ny = base.dists.uniform.logpdf( 2.0, 3.0, 1.0 )\n",
	"base.dists.uniform.mean": "v = base.dists.uniform.mean( 0.0, 1.0 )\nv = base.dists.uniform.mean( 4.0, 12.0 )\nv = base.dists.uniform.mean( 2.0, 8.0 )\n",
	"base.dists.uniform.median": "v = base.dists.uniform.median( 0.0, 1.0 )\nv = base.dists.uniform.median( 4.0, 12.0 )\nv = base.dists.uniform.median( 2.0, 8.0 )\n",
	"base.dists.uniform.mgf": "y = base.dists.uniform.mgf( 2.0, 0.0, 4.0 )\ny = base.dists.uniform.mgf( -0.2, 0.0, 4.0 )\ny = base.dists.uniform.mgf( 2.0, 0.0, 1.0 )\ny = base.dists.uniform.mgf( 0.5, 3.0, 2.0 )\ny = base.dists.uniform.mgf( 0.5, 3.0, 3.0 )\ny = base.dists.uniform.mgf( NaN, 0.0, 1.0 )\ny = base.dists.uniform.mgf( 0.0, NaN, 1.0 )\ny = base.dists.uniform.mgf( 0.0, 0.0, NaN )\n",
	"base.dists.uniform.pdf": "y = base.dists.uniform.pdf( 2.0, 0.0, 4.0 )\ny = base.dists.uniform.pdf( 5.0, 0.0, 4.0 )\ny = base.dists.uniform.pdf( 0.25, 0.0, 1.0 )\ny = base.dists.uniform.pdf( NaN, 0.0, 1.0 )\ny = base.dists.uniform.pdf( 0.0, NaN, 1.0 )\ny = base.dists.uniform.pdf( 0.0, 0.0, NaN )\ny = base.dists.uniform.pdf( 2.0, 3.0, 1.0 )\n",
	"base.dists.uniform.quantile": "y = base.dists.uniform.quantile( 0.8, 0.0, 1.0 )\ny = base.dists.uniform.quantile( 0.5, 0.0, 10.0 )\ny = base.dists.uniform.quantile( 1.1, 0.0, 1.0 )\ny = base.dists.uniform.quantile( -0.2, 0.0, 1.0 )\ny = base.dists.uniform.quantile( NaN, 0.0, 1.0 )\ny = base.dists.uniform.quantile( 0.0, NaN, 1.0 )\ny = base.dists.uniform.quantile( 0.0, 0.0, NaN )\ny = base.dists.uniform.quantile( 0.5, 2.0, 1.0 )\n",
	"base.dists.uniform.skewness": "v = base.dists.uniform.skewness( 0.0, 1.0 )\nv = base.dists.uniform.skewness( 4.0, 12.0 )\nv = base.dists.uniform.skewness( 2.0, 8.0 )\n",
	"base.dists.uniform.stdev": "v = base.dists.uniform.stdev( 0.0, 1.0 )\nv = base.dists.uniform.stdev( 4.0, 12.0 )\nv = base.dists.uniform.stdev( 2.0, 8.0 )\n",
	"base.dists.uniform.Uniform": "uniform = base.dists.uniform.Uniform( 0.0, 1.0 );\nuniform.a\nuniform.b\nuniform.entropy\nuniform.kurtosis\nuniform.mean\nuniform.median\nuniform.skewness\nuniform.stdev\nuniform.variance\nuniform.cdf( 0.8 )\nuniform.logcdf( 0.5 )\nuniform.logpdf( 1.0 )\nuniform.mgf( 0.8 )\nuniform.pdf( 0.8 )\nuniform.quantile( 0.8 )\n",
	"base.dists.uniform.variance": "v = base.dists.uniform.variance( 0.0, 1.0 )\nv = base.dists.uniform.variance( 4.0, 12.0 )\nv = base.dists.uniform.variance( 2.0, 8.0 )\n",
	"base.dists.weibull.cdf": "y = base.dists.weibull.cdf( 2.0, 1.0, 1.0 )\ny = base.dists.weibull.cdf( -1.0, 2.0, 2.0 )\ny = base.dists.weibull.cdf( PINF, 4.0, 2.0 )\ny = base.dists.weibull.cdf( NINF, 4.0, 2.0 )\ny = base.dists.weibull.cdf( NaN, 0.0, 1.0 )\ny = base.dists.weibull.cdf( 0.0, NaN, 1.0 )\ny = base.dists.weibull.cdf( 0.0, 0.0, NaN )\ny = base.dists.weibull.cdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.weibull.entropy": "v = base.dists.weibull.entropy( 1.0, 1.0 )\nv = base.dists.weibull.entropy( 4.0, 12.0 )\nv = base.dists.weibull.entropy( 8.0, 2.0 )\n",
	"base.dists.weibull.kurtosis": "v = base.dists.weibull.kurtosis( 1.0, 1.0 )\nv = base.dists.weibull.kurtosis( 4.0, 12.0 )\nv = base.dists.weibull.kurtosis( 8.0, 2.0 )\n",
	"base.dists.weibull.logcdf": "y = cdf( 2.0, 1.0, 1.0 )\ny = base.dists.weibull.logcdf( -1.0, 2.0, 2.0 )\ny = base.dists.weibull.logcdf( PINF, 4.0, 2.0 )\ny = base.dists.weibull.logcdf( NINF, 4.0, 2.0 )\ny = base.dists.weibull.logcdf( NaN, 0.0, 1.0 )\ny = base.dists.weibull.logcdf( 0.0, NaN, 1.0 )\ny = base.dists.weibull.logcdf( 0.0, 0.0, NaN )\ny = base.dists.weibull.logcdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.weibull.logpdf": "y = base.dists.weibull.logpdf( 2.0, 1.0, 0.5 )\ny = base.dists.weibull.logpdf( 0.1, 1.0, 1.0 )\ny = base.dists.weibull.logpdf( -1.0, 4.0, 2.0 )\ny = base.dists.weibull.logpdf( NaN, 0.6, 1.0 )\ny = base.dists.weibull.logpdf( 0.0, NaN, 1.0 )\ny = base.dists.weibull.logpdf( 0.0, 0.0, NaN )\ny = base.dists.weibull.logpdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.weibull.mean": "v = base.dists.weibull.mean( 1.0, 1.0 )\nv = base.dists.weibull.mean( 4.0, 12.0 )\nv = base.dists.weibull.mean( 8.0, 2.0 )\n",
	"base.dists.weibull.median": "v = base.dists.weibull.median( 1.0, 1.0 )\nv = base.dists.weibull.median( 4.0, 12.0 )\nv = base.dists.weibull.median( 8.0, 2.0 )\n",
	"base.dists.weibull.mgf": "y = base.dists.weibull.mgf( 1.0, 1.0, 0.5 )\ny = base.dists.weibull.mgf( -1.0, 4.0, 4.0 )\ny = base.dists.weibull.mgf( NaN, 1.0, 1.0 )\ny = base.dists.weibull.mgf( 0.0, NaN, 1.0 )\ny = base.dists.weibull.mgf( 0.0, 1.0, NaN )\ny = base.dists.weibull.mgf( 0.2, -1.0, 0.5 )\ny = base.dists.weibull.mgf( 0.2, 0.0, 0.5 )\ny = base.dists.weibull.mgf( 0.2, 0.5, -1.0 )\ny = base.dists.weibull.mgf( 0.2, 0.5, 0.0 )\n",
	"base.dists.weibull.mode": "v = base.dists.weibull.mode( 1.0, 1.0 )\nv = base.dists.weibull.mode( 4.0, 12.0 )\nv = base.dists.weibull.mode( 8.0, 2.0 )\n",
	"base.dists.weibull.pdf": "y = base.dists.weibull.pdf( 2.0, 1.0, 0.5 )\ny = base.dists.weibull.pdf( 0.1, 1.0, 1.0 )\ny = base.dists.weibull.pdf( -1.0, 4.0, 2.0 )\ny = base.dists.weibull.pdf( NaN, 0.6, 1.0 )\ny = base.dists.weibull.pdf( 0.0, NaN, 1.0 )\ny = base.dists.weibull.pdf( 0.0, 0.0, NaN )\ny = base.dists.weibull.pdf( 2.0, 0.0, -1.0 )\n",
	"base.dists.weibull.quantile": "y = base.dists.weibull.quantile( 0.8, 1.0, 1.0 )\ny = base.dists.weibull.quantile( 0.5, 2.0, 4.0 )\ny = base.dists.weibull.quantile( 1.1, 1.0, 1.0 )\ny = base.dists.weibull.quantile( -0.2, 1.0, 1.0 )\ny = base.dists.weibull.quantile( NaN, 0.0, 1.0 )\ny = base.dists.weibull.quantile( 0.0, NaN, 1.0 )\ny = base.dists.weibull.quantile( 0.0, 0.0, NaN )\ny = base.dists.weibull.quantile( 0.5, 1.0, -1.0 )\n",
	"base.dists.weibull.skewness": "v = base.dists.weibull.skewness( 1.0, 1.0 )\nv = base.dists.weibull.skewness( 4.0, 12.0 )\nv = base.dists.weibull.skewness( 8.0, 2.0 )\n",
	"base.dists.weibull.stdev": "v = base.dists.weibull.stdev( 1.0, 1.0 )\nv = base.dists.weibull.stdev( 4.0, 12.0 )\nv = base.dists.weibull.stdev( 8.0, 2.0 )\n",
	"base.dists.weibull.variance": "v = base.dists.weibull.variance( 1.0, 1.0 )\nv = base.dists.weibull.variance( 4.0, 12.0 )\nv = base.dists.weibull.variance( 8.0, 2.0 )\n",
	"base.dists.weibull.Weibull": "weibull = base.dists.weibull.Weibull( 6.0, 5.0 );\nweibull.k\nweibull.lambda\nweibull.entropy\nweibull.kurtosis\nweibull.mean\nweibull.median\nweibull.mode\nweibull.skewness\nweibull.stdev\nweibull.variance\nweibull.cdf( 3.0 )\nweibull.logcdf( 3.0 )\nweibull.logpdf( 1.0 )\nweibull.mgf( -0.5 )\nweibull.pdf( 3.0 )\nweibull.quantile( 0.8 )\n",
	"base.epsdiff": "d = base.epsdiff( 12.15, 12.149999999999999 )\nd = base.epsdiff( 2.4341309458983933, 2.4341309458633909, 'mean-abs' )\n\n// Custom scale function:\nfunction scale( x, y ) { return ( x > y ) ? y : x; };\nd = base.epsdiff( 1.0000000000000002, 1.0000000000000100, scale )\n",
	"base.eta": "y = base.eta( 0.0 )\ny = base.eta( -1.0 )\ny = base.eta( 1.0 )\ny = base.eta( 3.14 )\ny = base.eta( NaN )\n",
	"base.erf": "y = base.erf( 2.0 )\ny = base.erf( -1.0 )\ny = base.erf( -0.0 )\ny = base.erf( NaN )\n",
	"base.erfc": "y = base.erfc( 2.0 )\ny = base.erfc( -1.0 )\ny = base.erfc( 0.0 )\ny = base.erfc( PINF )\ny = base.erfc( NINF )\ny = base.erfc( NaN )\n",
	"base.erfcinv": "y = base.erfcinv( 0.5 )\ny = base.erfcinv( 0.8 )\ny = base.erfcinv( 0.0 )\ny = base.erfcinv( 2.0 )\ny = base.erfcinv( NaN )\n",
	"base.erfinv": "y = base.erfinv( 0.5 )\ny = base.erfinv( 0.8 )\ny = base.erfinv( 0.0 )\ny = base.erfinv( -0.0 )\ny = base.erfinv( -1.0 )\ny = base.erfinv( 1.0 )\ny = base.erfinv( NaN )\n",
	"base.evalpoly": "arr = [ 3.0, 2.0, 1.0 ];\n\n// 3*10^0 + 2*10^1 + 1*10^2\nv = base.evalpoly( arr, 10.0 )\n",
	"base.evalrational": "\n// 2x^3 + 4x^2 - 5x^1 - 6x^0\nP = [ -6.0, -5.0, 4.0, 2.0 ];\n\n// 0.5x^1 + 3x^0\nQ = [ 3.0, 0.5, 0.0, 0.0 ]; // zero-padded\n\n// Evaluate the rational function:\nv = base.evalrational( P, Q, 6.0 )\n",
	"base.exp": "y = base.exp( 4.0 )\ny = base.exp( -9.0 )\ny = base.exp( 0.0 )\ny = base.exp( NaN )\n",
	"base.exponent": "exponent = base.exponent( 3.14e-307 )\nexponent = base.exponent( -3.14 )\nexponent = base.exponent( 0.0 )\nexponent = base.exponent( NaN )\n",
	"base.exponentf": "exponent = base.exponentf( base.float64ToFloat32( 3.14e34 ) )\nexponent = base.exponentf( base.float64ToFloat32( 3.14e-34 ) )\nexponent = base.exponentf( base.float64ToFloat32( -3.14 ) )\nexponent = base.exponentf( 0.0 )\nexponent = base.exponentf( NaN )\n",
	"base.exp10": "y = base.exp10( 3.0 )\ny = base.exp10( -9.0 )\ny = base.exp10( 0.0 )\ny = base.exp10( NaN )\n",
	"base.exp2": "y = base.exp2( 3.0 )\ny = base.exp2( -9.0 )\ny = base.exp2( 0.0 )\ny = base.exp2( NaN )\n",
	"base.expm1": "y = base.expm1( 0.2 )\ny = base.expm1( -9.0 )\ny = base.expm1( 0.0 )\ny = base.expm1( NaN )\n",
	"base.factorial": "y = base.factorial( 3.0 )\ny = base.factorial( -1.5 )\ny = base.factorial( -0.5 )\ny = base.factorial( 0.5 )\ny = base.factorial( -10.0 )\ny = base.factorial( 171.0 )\ny = base.factorial( NaN )\n",
	"base.factorialln": "y = base.factorialln( 3.0 )\ny = base.factorialln( 2.4 )\ny = base.factorialln( -1.0 )\ny = base.factorialln( -1.5 )\ny = base.factorialln( NaN )\n",
	"base.fallingFactorial": "v = base.fallingFactorial( 0.9, 5 )\nv = base.fallingFactorial( -9.0, 3 )\nv = base.fallingFactorial( 0.0, 2 )\nv = base.fallingFactorial( 3.0, -2 )\n",
	"base.fibonacci": "y = base.fibonacci( 0 )\ny = base.fibonacci( 1 )\ny = base.fibonacci( 2 )\ny = base.fibonacci( 3 )\ny = base.fibonacci( 4 )\ny = base.fibonacci( 79 )\ny = base.fibonacci( NaN )\n",
	"base.fibonacciIndex": "n = base.fibonacciIndex( 2 )\nn = base.fibonacciIndex( 3 )\nn = base.fibonacciIndex( 5 )\nn = base.fibonacciIndex( NaN )\nn = base.fibonacciIndex( 1 )\n",
	"base.fibpoly": "\n// 2^4 + 3*2^2 + 1\nv = base.fibpoly( 5, 2.0 )\n",
	"base.flipsign": "z = base.flipsign( -3.14, 10.0 )\nz = base.flipsign( -3.14, -1.0 )\nz = base.flipsign( 1.0, -0.0 )\nz = base.flipsign( -3.14, -0.0 )\nz = base.flipsign( -0.0, 1.0 )\nz = base.flipsign( 0.0, -1.0 )\n",
	"base.floor": "y = base.floor( 3.14 )\ny = base.floor( -4.2 )\ny = base.floor( -4.6 )\ny = base.floor( 9.5 )\ny = base.floor( -0.0 )\n",
	"base.floor10": "y = base.floor10( 3.14 )\ny = base.floor10( -4.2 )\ny = base.floor10( -4.6 )\ny = base.floor10( 9.5 )\ny = base.floor10( 13.0 )\ny = base.floor10( -13.0 )\ny = base.floor10( -0.0 )\n",
	"base.floor2": "y = base.floor2( 3.14 )\ny = base.floor2( -4.2 )\ny = base.floor2( -4.6 )\ny = base.floor2( 9.5 )\ny = base.floor2( 13.0 )\ny = base.floor2( -13.0 )\ny = base.floor2( -0.0 )\n",
	"base.floorb": "\n// Round to 4 decimal places:\ny = base.floorb( 3.14159, -4, 10 )\n\n// If `n = 0` or `b = 1`, standard round behavior:\ny = base.floorb( 3.14159, 0, 2 )\n\n// Round to nearest multiple of two toward negative infinity:\ny = base.floorb( 5.0, 1, 2 )\n",
	"base.floorn": "\n// Round to 4 decimal places:\ny = base.floorn( 3.14159, -4 )\n\n// If `n = 0`, standard round toward negative infinity behavior:\ny = base.floorn( 3.14159, 0 )\n\n// Round to nearest thousand:\ny = base.floorn( 12368.0, 3 )\n",
	"base.floorsd": "y = base.floorsd( 3.14159, 5 )\ny = base.floorsd( 3.14159, 1 )\ny = base.floorsd( 12368.0, 2 )\ny = base.floorsd( 0.0313, 2, 2 )\n",
	"base.float32ToInt32": "y = base.float32ToInt32( base.float64ToFloat32( 4294967295.0 ) )\ny = base.float32ToInt32( base.float64ToFloat32( 3.14 ) )\ny = base.float32ToInt32( base.float64ToFloat32( -3.14 ) )\ny = base.float32ToInt32( base.float64ToFloat32( NaN ) )\ny = base.float32ToInt32( FLOAT32_PINF )\ny = base.float32ToInt32( FLOAT32_NINF )\n",
	"base.float32ToUint32": "y = base.float32ToUint32( base.float64ToFloat32( 4294967297.0 ) )\ny = base.float32ToUint32( base.float64ToFloat32( 3.14 ) )\ny = base.float32ToUint32( base.float64ToFloat32( -3.14 ) )\ny = base.float32ToUint32( base.float64ToFloat32( NaN ) )\ny = base.float32ToUint32( FLOAT32_PINF )\ny = base.float32ToUint32( FLOAT32_NINF )\n",
	"base.float64ToFloat32": "y = base.float64ToFloat32( 1.337 )\n",
	"base.float64ToInt32": "y = base.float64ToInt32( 4294967295.0 )\ny = base.float64ToInt32( 3.14 )\ny = base.float64ToInt32( -3.14 )\ny = base.float64ToInt32( NaN )\ny = base.float64ToInt32( PINF )\ny = base.float64ToInt32( NINF )\n",
	"base.float64ToUint32": "y = base.float64ToUint32( 4294967297.0 )\ny = base.float64ToUint32( 3.14 )\ny = base.float64ToUint32( -3.14 )\ny = base.float64ToUint32( NaN )\ny = base.float64ToUint32( PINF )\ny = base.float64ToUint32( NINF )\n",
	"base.fresnel": "y = base.fresnel( 0.0 )\ny = base.fresnel( 1.0 )\ny = base.fresnel( PINF )\ny = base.fresnel( NINF )\ny = base.fresnel( NaN )\nout = new Float64Array( 2 );\nv = base.fresnel( out, 0.0 )\nbool = ( v === out )\n",
	"base.fresnelc": "y = base.fresnelc( 0.0 )\ny = base.fresnelc( 1.0 )\ny = base.fresnelc( PINF )\ny = base.fresnelc( NINF )\ny = base.fresnelc( NaN )\n",
	"base.fresnels": "y = base.fresnels( 0.0 )\ny = base.fresnels( 1.0 )\ny = base.fresnels( PINF )\ny = base.fresnels( NINF )\ny = base.fresnels( NaN )\n",
	"base.frexp": "out = base.frexp( 4.0 )\nout = base.frexp( 0.0 )\nout = base.frexp( -0.0 )\nout = base.frexp( NaN )\nout = base.frexp( PINF )\nout = base.frexp( NINF )\n\n// Provide an output array:\nout = new Float64Array( 2 );\ny = base.frexp( 4.0 )\nbool = ( y === out )\n",
	"base.fromBinaryString": "bstr;\nbstr = '0100000000010000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\nbstr = '0100000000001001001000011111101101010100010001000010110100011000';\nval = base.fromBinaryString( bstr )\nbstr = '1111111111100001110011001111001110000101111010111100100010100000';\nval = base.fromBinaryString( bstr )\n\n// The function handles subnormals:\nbstr = '1000000000000000000000000000000000000000000000000001100011010011';\nval = base.fromBinaryString( bstr )\nbstr = '0000000000000000000000000000000000000000000000000000000000000001';\nval = base.fromBinaryString( bstr )\n\n// The function handles special values:\nbstr = '0000000000000000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\nbstr = '1000000000000000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\nbstr = '0111111111111000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\nbstr = '0111111111110000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\nbstr = '1111111111110000000000000000000000000000000000000000000000000000';\nval = base.fromBinaryString( bstr )\n",
	"base.fromBinaryStringf": "bstr = '01000000100000000000000000000000';\nval = base.fromBinaryStringf( bstr )\nbstr = '01000000010010010000111111011011';\nval = base.fromBinaryStringf( bstr )\nbstr = '11111111011011000011101000110011';\nval = base.fromBinaryStringf( bstr )\n\n// The function handles subnormals:\nbstr = '10000000000000000000000000010110';\nval = base.fromBinaryStringf( bstr )\nbstr = '00000000000000000000000000000001';\nval = base.fromBinaryStringf( bstr )\n\n// The function handles special values:\nbstr = '00000000000000000000000000000000';\nval = base.fromBinaryStringf( bstr )\nbstr = '10000000000000000000000000000000';\nval = base.fromBinaryStringf( bstr )\nbstr = '01111111110000000000000000000000';\nval = base.fromBinaryStringf( bstr )\nbstr = '01111111100000000000000000000000';\nval = base.fromBinaryStringf( bstr )\nbstr = '11111111100000000000000000000000';\nval = base.fromBinaryStringf( bstr )\n",
	"base.fromBinaryStringUint16": "bstr = '0101010101010101';\nval = base.fromBinaryStringUint16( bstr )\nbstr = '0000000000000000';\nval = base.fromBinaryStringUint16( bstr )\nbstr = '0000000000000010';\nval = base.fromBinaryStringUint16( bstr )\nbstr = '1111111111111111';\nval = base.fromBinaryStringUint16( bstr )\n",
	"base.fromBinaryStringUint32": "bstr = '01010101010101010101010101010101';\nval = base.fromBinaryStringUint32( bstr )\nbstr = '00000000000000000000000000000000';\nval = base.fromBinaryStringUint32( bstr )\nbstr = '00000000000000000000000000000010';\nval = base.fromBinaryStringUint32( bstr )\nbstr = '11111111111111111111111111111111';\nval = base.fromBinaryStringUint32( bstr )\n",
	"base.fromBinaryStringUint8": "bstr = '01010101';\nval = base.fromBinaryStringUint8( bstr )\nbstr = '00000000';\nval = base.fromBinaryStringUint8( bstr )\nbstr = '00000010';\nval = base.fromBinaryStringUint8( bstr )\nbstr = '11111111';\nval = base.fromBinaryStringUint8( bstr )\n",
	"base.fromWordf": "word = 1068180177; // => 0 01111111 01010110010001011010001\nf32 = base.fromWordf( word ) // when printed, promoted to float64\n",
	"base.fromWords": "v = base.fromWords( 1774486211, 2479577218 )\nv = base.fromWords( 3221823995, 1413754136 )\nv = base.fromWords( 0, 0 )\nv = base.fromWords( 2147483648, 0 )\nv = base.fromWords( 2146959360, 0 )\nv = base.fromWords( 2146435072, 0 )\nv = base.fromWords( 4293918720, 0 )\n",
	"base.gamma": "y = base.gamma( 4.0 )\ny = base.gamma( -1.5 )\ny = base.gamma( -0.5 )\ny = base.gamma( 0.5 )\ny = base.gamma( 0.0 )\ny = base.gamma( -0.0 )\ny = base.gamma( NaN )\n",
	"base.gamma1pm1": "y = base.gamma1pm1( 0.2 )\ny = base.gamma1pm1( -6.7 )\ny = base.gamma1pm1( 0.0 )\ny = base.gamma1pm1( NaN )\n",
	"base.gammaDeltaRatio": "y = base.gammaDeltaRatio( 2.0, 3.0 )\ny = base.gammaDeltaRatio( 4.0, 0.5 )\ny = base.gammaDeltaRatio( 100.0, 0.0 )\ny = base.gammaDeltaRatio( NaN, 3.0 )\ny = base.gammaDeltaRatio( 5.0, NaN )\ny = base.gammaDeltaRatio( NaN, NaN )\n",
	"base.gammainc": "y = base.gammainc( 6.0, 2.0 )\ny = base.gammainc( 1.0, 2.0, true, true )\ny = base.gammainc( 7.0, 5.0 )\ny = base.gammainc( 7.0, 5.0, false )\ny = base.gammainc( NaN, 2.0 )\ny = base.gammainc( 6.0, NaN )\n",
	"base.gammaincinv": "y = base.gammaincinv( 0.5, 2.0 )\ny = base.gammaincinv( 0.1, 10.0 )\ny = base.gammaincinv( 0.75, 3.0 )\ny = base.gammaincinv( 0.75, 3.0, true )\ny = base.gammaincinv( 0.75, NaN )\ny = base.gammaincinv( NaN, 3.0 )\n",
	"base.gammaLanczosSum": "y = base.gammaLanczosSum( 4.0 )\ny = base.gammaLanczosSum( -1.5 )\ny = base.gammaLanczosSum( -0.5 )\ny = base.gammaLanczosSum( 0.5 )\ny = base.gammaLanczosSum( 0.0 )\ny = base.gammaLanczosSum( NaN )\n",
	"base.gammaLanczosSumExpGScaled": "y = base.gammaLanczosSumExpGScaled( 4.0 )\ny = base.gammaLanczosSumExpGScaled( -1.5 )\ny = base.gammaLanczosSumExpGScaled( -0.5 )\ny = base.gammaLanczosSumExpGScaled( 0.5 )\ny = base.gammaLanczosSumExpGScaled( 0.0 )\ny = base.gammaLanczosSumExpGScaled( NaN )\n",
	"base.gammaln": "y = base.gammaln( 1.0 )\ny = base.gammaln( 2.0 )\ny = base.gammaln( 4.0 )\ny = base.gammaln( -0.5 )\ny = base.gammaln( 0.5 )\ny = base.gammaln( 0.0 )\ny = base.gammaln( NaN )\n",
	"base.gasum": "\n// Standard usage:\nx = [ -2.0, 1.0, 3.0, -5.0, 4.0, 0.0, -1.0, -3.0 ];\nsum = base.gasum( x.length, x, 1 )\n\n// Sum every other value:\nN = base.floor( x.length / 2 );\nstride = 2;\nsum = base.gasum( N, x, stride )\n\n// Use view offset; e.g., starting at 2nd element:\nx0 = new Float64Array( [ 1.0, -2.0, 3.0, -4.0, 5.0, -6.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\nN = base.floor( x0.length / 2 );\nsum = base.gasum( N, x1, stride )\n",
	"base.gaxpy": "\n// Standard usage:\nx = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\ny = [ 1.0, 1.0, 1.0, 1.0, 1.0 ];\nalpha = 5.0;\nbase.gaxpy( x.length, alpha, x, 1, y, 1 )\n\n// Using `N` and `stride` parameters:\nN = base.floor( x.length / 2 );\nbase.gaxpy( N, alpha, x, 2, y, -1 )\n\n// Using view offsets:\nx0 = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float64Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float64Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.gaxpy( N, 5.0, x1, -2, y1, 1 )\ny0\n",
	"base.gcd": "v = base.gcd( 48, 18 )\n",
	"base.gcopy": "\n// Standard usage:\nx = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\ny = [ 6.0, 7.0, 8.0, 9.0, 10.0 ];\nbase.gcopy( x.length, x, 1, y, 1 )\n\n// Advanced indexing:\nx = [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ];\ny = [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ];\nN = base.floor( x.length / 2 );\nbase.gcopy( N, x, -2, y, 1 )\n\n// Using typed array views:\nx0 = new Float64Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float64Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float64Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float64Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.gcopy( N, x1, -2, y1, 1 )\ny0\n",
	"base.getHighWord": "w = base.getHighWord( 3.14e201 )\n",
	"base.getLowWord": "w = base.getLowWord( 3.14e201 )\n",
	"base.hacovercos": "y = base.hacovercos( 3.14 )\ny = base.hacovercos( -4.2 )\ny = base.hacovercos( -4.6 )\ny = base.hacovercos( 9.5 )\ny = base.hacovercos( -0.0 )\n",
	"base.hacoversin": "y = base.hacoversin( 3.14 )\ny = base.hacoversin( -4.2 )\ny = base.hacoversin( -4.6 )\ny = base.hacoversin( 9.5 )\ny = base.hacoversin( -0.0 )\n",
	"base.havercos": "y = base.havercos( 3.14 )\ny = base.havercos( -4.2 )\ny = base.havercos( -4.6 )\ny = base.havercos( 9.5 )\ny = base.havercos( -0.0 )\n",
	"base.haversin": "y = base.haversin( 3.14 )\ny = base.haversin( -4.2 )\ny = base.haversin( -4.6 )\ny = base.haversin( 9.5 )\ny = base.haversin( -0.0 )\n",
	"base.heaviside": "y = base.heaviside( 3.14 )\ny = base.heaviside( -3.14 )\ny = base.heaviside( 0.0 )\ny = base.heaviside( 0.0, 'half-maximum' )\ny = base.heaviside( 0.0, 'left-continuous' )\ny = base.heaviside( 0.0, 'right-continuous' )\n",
	"base.hypot": "h = base.hypot( -5.0, 12.0 )\nh = base.hypot( NaN, 12.0 )\nh = base.hypot( -0.0, -0.0 )\n",
	"base.int32ToUint32": "y = base.int32ToUint32( base.float64ToInt32( -32 ) )\ny = base.int32ToUint32( base.float64ToInt32( 3 ) )\n",
	"base.inv": "y = base.inv( -1.0 )\ny = base.inv( 2.0 )\ny = base.inv( 0.0 )\ny = base.inv( -0.0 )\ny = base.inv( NaN )\n",
	"base.isEven": "bool = base.isEven( 5.0 )\nbool = base.isEven( -2.0 )\nbool = base.isEven( 0.0 )\nbool = base.isEven( NaN )\n",
	"base.isEvenInt32": "bool = base.isEvenInt32( 5 )\nbool = base.isEvenInt32( -2 )\nbool = base.isEvenInt32( 0 )\n",
	"base.isFinite": "bool = base.isFinite( 5.0 )\nbool = base.isFinite( -2.0e64 )\nbool = base.isFinite( PINF )\nbool = base.isFinite( NINF )\n",
	"base.isInfinite": "bool = base.isInfinite( PINF )\nbool = base.isInfinite( NINF )\nbool = base.isInfinite( 5.0 )\nbool = base.isInfinite( NaN )\n",
	"base.isInteger": "bool = base.isInteger( 1.0 )\nbool = base.isInteger( 3.14 )\n",
	"base.isnan": "bool = base.isnan( NaN )\nbool = base.isnan( 7.0 )\n",
	"base.isNegativeInteger": "bool = base.isNegativeInteger( -1.0 )\nbool = base.isNegativeInteger( 0.0 )\nbool = base.isNegativeInteger( 10.0 )\n",
	"base.isNegativeZero": "bool = base.isNegativeZero( -0.0 )\nbool = base.isNegativeZero( 0.0 )\n",
	"base.isNonNegativeInteger": "bool = base.isNonNegativeInteger( 1.0 )\nbool = base.isNonNegativeInteger( 0.0 )\nbool = base.isNonNegativeInteger( -10.0 )\n",
	"base.isNonPositiveInteger": "bool = base.isNonPositiveInteger( -1.0 )\nbool = base.isNonPositiveInteger( 0.0 )\nbool = base.isNonPositiveInteger( 10.0 )\n",
	"base.isOdd": "bool = base.isOdd( 5.0 )\nbool = base.isOdd( -2.0 )\nbool = base.isOdd( 0.0 )\nbool = base.isOdd( NaN )\n",
	"base.isOddInt32": "bool = base.isOddInt32( 5 )\nbool = base.isOddInt32( -2 )\nbool = base.isOddInt32( 0 )\n",
	"base.isPositiveInteger": "bool = base.isPositiveInteger( 1.0 )\nbool = base.isPositiveInteger( 0.0 )\nbool = base.isPositiveInteger( 10.0 )\n",
	"base.isPositiveZero": "bool = base.isPositiveZero( 0.0 )\nbool = base.isPositiveZero( -0.0 )\n",
	"base.isPow2Uint32": "bool = base.isPow2Uint32( 2 )\nbool = base.isPow2Uint32( 5 )\n",
	"base.isProbability": "bool = base.isProbability( 0.5 )\nbool = base.isProbability( 3.14 )\nbool = base.isProbability( NaN )\n",
	"base.isSafeInteger": "bool = base.isSafeInteger( 1.0 )\nbool = base.isSafeInteger( 2.0e200 )\nbool = base.isSafeInteger( 3.14 )\n",
	"base.kernelBetainc": "out = base.kernelBetainc( 2.0, 2.0, false, false )\nout = base.kernelBetainc( 0.2, 1.0, 2.0, true, false )\nout = new Array( 2 );\nv = base.kernelBetainc( out, 0.2, 1.0, 2.0, true, true )\nbool = ( v === out )\n",
	"base.kernelBetaincinv": "y = base.kernelBetaincinv( 3.0, 3.0, 0.2, 0.8 )\ny = base.kernelBetaincinv( 3.0, 3.0, 0.4, 0.6 )\ny = base.kernelBetaincinv( 1.0, 6.0, 0.4, 0.6 )\ny = base.kernelBetaincinv( 1.0, 6.0, 0.8, 0.2 )\n",
	"base.kernelCos": "out = base.kernelCos( 0.0, 0.0 )\nout = base.kernelCos( PI/6.0, 0.0 )\nout = base.kernelCos( 0.785, -1.144e-17 )\nout = base.kernelCos( NaN )\n",
	"base.kernelSin": "y = base.kernelSin( 0.0, 0.0 )\ny = base.kernelSin( PI/6.0, 0.0 )\ny = base.kernelSin( 0.619, 9.279e-18 )\ny = base.kernelSin( NaN, 0.0 )\ny = base.kernelSin( 2.0, NaN )\ny = base.kernelSin( NaN, NaN )\n",
	"base.kernelTan": "out = base.kernelTan( PI/4.0, 0.0, 1 )\nout = base.kernelTan( PI/4.0, 0.0, -1 )\nout = base.kernelTan( PI/6.0, 0.0, 1 )\nout = base.kernelTan( 0.664, 5.288e-17, 1 )\nout = base.kernelTan( NaN, 0.0, 1 )\nout = base.kernelTan( 3.0, NaN, 1 )\nout = base.kernelTan( 3.0, 0.0, NaN )\n",
	"base.kroneckerDelta": "y = base.kroneckerDelta( 3.14, 0.0 )\ny = base.kroneckerDelta( 3.14, 3.14 )\n",
	"base.lcm": "v = base.lcm( 21, 6 )\n",
	"base.ldexp": "x = base.ldexp( 0.5, 3 )\nx = base.ldexp( 4.0, -2 )\nx = base.ldexp( 0.0, 20 )\nx = base.ldexp( -0.0, 39 )\nx = base.ldexp( NaN, -101 )\nx = base.ldexp( PINF, 11 )\nx = base.ldexp( NINF, -118 )\n",
	"base.ln": "y = base.ln( 4.0 )\ny = base.ln( 0.0 )\ny = base.ln( PINF )\ny = base.ln( NaN )\ny = base.ln( -4.0 )\n",
	"base.log": "y = base.log( 100.0, 10.0 )\ny = base.log( 16.0, 2.0 )\ny = base.log( 5.0, 1.0 )\ny = base.log( NaN, 2.0 )\ny = base.log( 1.0, NaN )\ny = base.log( -4.0, 2.0 )\ny = base.log( 4.0, -2.0 )\n",
	"base.log10": "y = base.log10( 100.0 )\ny = base.log10( 8.0 )\ny = base.log10( 0.0 )\ny = base.log10( PINF )\ny = base.log10( NaN )\ny = base.log10( -4.0 )\n",
	"base.log1p": "y = base.log1p( 4.0 )\ny = base.log1p( -1.0 )\ny = base.log1p( 0.0 )\ny = base.log1p( -0.0 )\ny = base.log1p( -2.0 )\ny = base.log1p( NaN )\n",
	"base.log2": "y = base.log2( 4.0 )\ny = base.log2( 8.0 )\ny = base.log2( 0.0 )\ny = base.log2( PINF )\ny = base.log2( NaN )\ny = base.log2( -4.0 )\n",
	"base.logit": "y = base.logit( 0.2 )\ny = base.logit( 0.9 )\ny = base.logit( -4.0 )\ny = base.logit( 1.5 )\ny = base.logit( NaN )\n",
	"base.lucas": "y = base.lucas( 0 )\ny = base.lucas( 1 )\ny = base.lucas( 2 )\ny = base.lucas( 3 )\ny = base.lucas( 4 )\ny = base.lucas( 77 )\ny = base.lucas( NaN )\n",
	"base.lucaspoly": "\n// 2^5 + 5*2^3 + 5*2\nv = base.lucaspoly( 5, 2.0 )\n",
	"base.max": "v = base.max( 3.14, 4.2 )\nv = base.max( 5.9, 3.14, 4.2 )\nv = base.max( 3.14, NaN )\nv = base.max( +0.0, -0.0 )\n",
	"base.maxabs": "v = base.maxabs( 3.14, -4.2 )\nv = base.maxabs( 5.9, 3.14, 4.2 )\nv = base.maxabs( 3.14, NaN )\nv = base.maxabs( +0.0, -0.0 )\n",
	"base.min": "v = base.min( 3.14, 4.2 )\nv = base.min( 5.9, 3.14, 4.2 )\nv = base.min( 3.14, NaN )\nv = base.min( +0.0, -0.0 )\n",
	"base.minabs": "v = base.minabs( 3.14, -4.2 )\nv = base.minabs( 5.9, 3.14, 4.2 )\nv = base.minabs( 3.14, NaN )\nv = base.minabs( +0.0, -0.0 )\n",
	"base.minmax": "v = base.minmax( 3.14, 4.2 )\nv = base.minmax( 5.9, 3.14, 4.2 )\nv = base.minmax( 3.14, NaN )\nv = base.minmax( +0.0, -0.0 )\nv = base.minmax( 3.14 )\nout = new Array( 2 );\nv = base.minmax( out, 3.14 )\nbool = ( v === out )\n",
	"base.modf": "parts = base.modf( 3.14 )\nparts = base.modf( 3.14 )\nparts = base.modf( +0.0 )\nparts = base.modf( -0.0 )\nparts = base.modf( PINF )\nparts = base.modf( NINF )\nparts = base.modf( NaN )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nparts = base.modf( out, 3.14 )\nbool = ( parts === out )\n",
	"base.negafibonacci": "y = base.negafibonacci( 0 )\ny = base.negafibonacci( -1 )\ny = base.negafibonacci( -2 )\ny = base.negafibonacci( -3 )\ny = base.negafibonacci( -4 )\ny = base.negafibonacci( -79 )\ny = base.negafibonacci( -80 )\ny = base.negafibonacci( NaN )\n",
	"base.negalucas": "y = base.negalucas( 0 )\ny = base.negalucas( -1 )\ny = base.negalucas( -2 )\ny = base.negalucas( -3 )\ny = base.negalucas( -4 )\ny = base.negalucas( -77 )\ny = base.negalucas( -78 )\ny = base.negalucas( NaN )\n",
	"base.nonfibonacci": "v = base.nonfibonacci( 1 )\nv = base.nonfibonacci( 2 )\nv = base.nonfibonacci( 3 )\nv = base.nonfibonacci( NaN )\n",
	"base.normalize": "out = base.normalize( 3.14e-319 );\ny = out[ 0 ];\nexponent = out[ 1 ];\nbool = ( y*base.pow(2.0, exponent) === 3.14e-319 )\n\n// Special cases:\nout = base.normalize( 0.0 )\nout = base.normalize( PINF )\nout = base.normalize( NINF )\nout = base.normalize( NaN )\n\n// Provide an output array:\nout = new Float64Array( 2 );\nv = base.normalize( out, 3.14e-319 )\nbool = ( v === out )\n",
	"base.normalizef": "out = base.normalizef( base.float64ToFloat32( 1.401e-45 ) )\ny = out[ 0 ];\nexp = out[ 1 ];\nbool = ( y*base.pow(2,exp) === base.float64ToFloat32(1.401e-45) )\n\n// Special cases:\nout = base.normalizef( FLOAT32_PINF )\nout = base.normalizef( FLOAT32_NINF )\nout = base.normalizef( NaN )\n\n// Provide an output array:\nout = new Float32Array( 2 );\nv = base.normalizef( out, base.float64ToFloat32( 1.401e-45 ) )\nbool = ( v === out )\n",
	"base.pdiff": "v = base.pdiff( 5.9, 3.14 )\nv = base.pdiff( 3.14, 4.2 )\nv = base.pdiff( 3.14, NaN )\nv = base.pdiff( -0.0, +0.0 )\n",
	"base.polygamma": "v = base.polygamma( 3, 1.2 )\nv = base.polygamma( 5, 1.2 )\nv = base.polygamma( 3, -4.9 )\nv = base.polygamma( -1, 5.3 )\nv = base.polygamma( 2, -1.0 )\n",
	"base.pow": "y = base.pow( 2.0, 3.0 )\ny = base.pow( 4.0, 0.5 )\ny = base.pow( 100.0, 0.0 )\ny = base.pow( PI, 5.0 )\ny = base.pow( PI, -0.2 )\ny = base.pow( NaN, 3.0 )\ny = base.pow( 5.0, NaN )\ny = base.pow( NaN, NaN )\n",
	"base.powm1": "y = base.powm1( 2.0, 3.0 )\ny = base.powm1( 4.0, 0.5 )\ny = base.powm1( 0.0, 100.0 )\ny = base.powm1( 100.0, 0.0 )\ny = base.powm1( 0.0, 0.0 )\ny = base.powm1( PI, 5.0 )\ny = base.powm1( NaN, 3.0 )\ny = base.powm1( 5.0, NaN )\n",
	"base.rad2deg": "d = base.rad2deg( PI/2.0 )\nd = base.rad2deg( -PI/4.0 )\nd = base.rad2deg( NaN )\n\n// Due to finite precision, canonical values may not be returned:\nd = base.rad2deg( PI/6.0 )\n",
	"base.ramp": "y = base.ramp( 3.14 )\ny = base.ramp( -3.14 )\n",
	"base.random.arcsine": "r = base.random.arcsine( 2.0, 5.0 )\n",
	"base.random.beta": "r = base.random.beta( 2.0, 5.0 );\n",
	"base.random.betaprime": "r = base.random.betaprime( 2.0, 5.0 );\n",
	"base.random.binomial": "r = base.random.binomial( 20, 0.8 );\n",
	"base.random.boxMuller": "r = base.random.boxMuller();\n",
	"base.random.cauchy": "r = base.random.cauchy( 2.0, 5.0 );\n",
	"base.random.chi": "r = base.random.chi( 2 );\n",
	"base.random.chisquare": "r = base.random.chisquare( 2 );\n",
	"base.random.cosine": "r = base.random.cosine( 2.0, 5.0 );\n",
	"base.random.discreteUniform": "r = base.random.discreteUniform( 2, 50 );\n",
	"base.random.erlang": "r = base.random.erlang( 2, 5.0 );\n",
	"base.random.exponential": "r = base.random.exponential( 7.9 );\n",
	"base.random.f": "r = base.random.f( 2.0, 5.0 );\n",
	"base.random.frechet": "r = base.random.frechet( 2.0, 5.0, 3.33 );\n",
	"base.random.gamma": "r = base.random.gamma( 2.0, 5.0 );\n",
	"base.random.geometric": "r = base.random.geometric( 0.8 );\n",
	"base.random.gumbel": "r = base.random.gumbel( 2.0, 5.0 );\n",
	"base.random.hypergeometric": "r = base.random.hypergeometric( 20, 10, 7 );\n",
	"base.random.improvedZiggurat": "r = base.random.improvedZiggurat();\n",
	"base.random.invgamma": "r = base.random.invgamma( 2.0, 5.0 );\n",
	"base.random.kumaraswamy": "r = base.random.kumaraswamy( 2.0, 5.0 );\n",
	"base.random.laplace": "r = base.random.laplace( 2.0, 5.0 );\n",
	"base.random.levy": "r = base.random.levy( 2.0, 5.0 );\n",
	"base.random.logistic": "r = base.random.logistic( 2.0, 5.0 );\n",
	"base.random.lognormal": "r = base.random.lognormal( 2.0, 5.0 );\n",
	"base.random.minstd": "r = base.random.minstd();\n",
	"base.random.minstdShuffle": "r = base.random.minstdShuffle();\n",
	"base.random.negativeBinomial": "r = base.random.negativeBinomial( 20, 0.8 );\n",
	"base.random.normal": "r = base.random.normal( 2.0, 5.0 );\n",
	"base.random.pareto1": "r = base.random.pareto1( 2.0, 5.0 );\n",
	"base.random.poisson": "r = base.random.poisson( 7.9 );\n",
	"base.random.randi": "r = base.random.randi();\n",
	"base.random.randn": "r = base.random.randn();\n",
	"base.random.randu": "r = base.random.randu();\n",
	"base.random.rayleigh": "r = base.random.rayleigh( 2.5 );\n",
	"base.random.t": "r = base.random.t( 2.0 );\n",
	"base.random.triangular": "r = base.random.triangular( 2.0, 5.0, 3.33 );\n",
	"base.random.uniform": "r = base.random.uniform( 2.0, 5.0 );\n",
	"base.random.weibull": "r = base.random.weibull( 2.0, 5.0 );\n",
	"base.rempio2": "y = new Array( 2 );\nn = base.rempio2( 128.0, y )\ny1 = y[ 0 ]\ny2 = y[ 1 ]\n",
	"base.reldiff": "d = base.reldiff( 2.0, 5.0 )\nd = base.reldiff( -1.0, 3.14 )\nd = base.reldiff( -2.0, 5.0, 'max-abs' )\nd = base.reldiff( -2.0, 5.0, 'max' )\nd = base.reldiff( -2.0, 5.0, 'min-abs' )\nd = base.reldiff( -2.0, 5.0, 'min' )\nd = base.reldiff( -2.0, 5.0, 'mean-abs' )\nd = base.reldiff( -2.0, 5.0, 'mean' )\nd = base.reldiff( -2.0, 5.0, 'x' )\nd = base.reldiff( 5.0, -2.0, 'x' )\nd = base.reldiff( -2.0, 5.0, 'y' )\nd = base.reldiff( 5.0, -2.0, 'y' )\n\n// Custom scale function:\nfunction scale( x, y ) {\ns;\n\nx = base.abs( x );\ny = base.abs( y );\n\n// Maximum absolute value:\ns = (x < y ) ? y : x;\n\n// Scale in units of epsilon:\nreturn s * EPS;\n};\nd = base.reldiff( 12.15, 12.149999999999999, scale )\n",
	"base.rotl32": "x = 2147483649;\nbStr = base.toBinaryStringUint32( x )\ny = base.rotl32( x, 10 )\nbstr = base.toBinaryStringUint32( y )\n",
	"base.rotr32": "x = 1;\nbStr = base.toBinaryStringUint32( x )\ny = base.rotr32( x, 10 )\nbstr = base.toBinaryStringUint32( y )\n",
	"base.risingFactorial": "v = base.risingFactorial( 0.9, 5 )\nv = base.risingFactorial( -9.0, 3 )\nv = base.risingFactorial( 0.0, 2 )\nv = base.risingFactorial( 3.0, -2 )\n",
	"base.round": "y = base.round( 3.14 )\ny = base.round( -4.2 )\ny = base.round( -4.6 )\ny = base.round( 9.5 )\ny = base.round( -0.0 )\n",
	"base.round10": "y = base.round10( 3.14 )\ny = base.round10( -4.2 )\ny = base.round10( -4.6 )\ny = base.round10( 9.5 )\ny = base.round10( 13.0 )\ny = base.round10( -13.0 )\ny = base.round10( -0.0 )\n",
	"base.round2": "y = base.round2( 3.14 )\ny = base.round2( -4.2 )\ny = base.round2( -4.6 )\ny = base.round2( 9.5 )\ny = base.round2( 13.0 )\ny = base.round2( -13.0 )\ny = base.round2( -0.0 )\n",
	"base.roundb": "\n// Round to 2 decimal places:\ny = base.roundb( 3.14159, -2, 10 )\n\n// If `n = 0` or `b = 1`, standard round behavior:\ny = base.roundb( 3.14159, 0, 2 )\n\n// Round to nearest multiple of two:\ny = base.roundb( 5.0, 1, 2 )\n",
	"base.roundn": "\n// Round to 2 decimal places:\ny = base.roundn( 3.14159, -2 )\n\n// If `n = 0`, standard round behavior:\ny = base.roundn( 3.14159, 0 )\n\n// Round to nearest thousand:\ny = base.roundn( 12368.0, 3 )\n",
	"base.roundsd": "y = base.roundsd( 3.14159, 3 )\ny = base.roundsd( 3.14159, 1 )\ny = base.roundsd( 12368.0, 2 )\ny = base.roundsd( 0.0313, 2, 2 )\n",
	"base.sasum": "\n// Standard usage:\nx = new Float32Array( [ -2.0, 1.0, 3.0, -5.0, 4.0, 0.0, -1.0, -3.0 ] );\nsum = base.sasum( x.length, x, 1 )\n\n// Sum every other value:\nN = base.floor( x.length / 2 );\nstride = 2;\nsum = base.sasum( N, x, stride )\n\n// Use view offset; e.g., starting at 2nd element:\nx0 = new Float32Array( [ 1.0, -2.0, 3.0, -4.0, 5.0, -6.0 ] );\nx1 = new Float32Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\nN = base.floor( x0.length / 2 );\nsum = base.sasum( N, x1, stride )\n",
	"base.saxpy": "\n// Standard usage:\nx = new Float32Array( [ 1.0, 2.0, 3.0, 4.0, 5.0 ] );\ny = new Float32Array( [ 1.0, 1.0, 1.0, 1.0, 1.0 ] );\nalpha = 5.0;\nbase.saxpy( x.length, alpha, x, 1, y, 1 )\n\n// Using `N` and `stride` parameters:\nN = base.floor( x.length / 2 );\nbase.saxpy( N, alpha, x, 2, y, -1 )\n\n// Using view offsets:\nx0 = new Float32Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float32Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float32Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float32Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.saxpy( N, 5.0, x1, -2, y1, 1 )\ny0\n",
	"base.scopy": "\n// Standard usage:\nx = new Float32Array( [ 1.0, 2.0, 3.0, 4.0, 5.0 ] );\ny = new Float32Array( [ 6.0, 7.0, 8.0, 9.0, 10.0 ] );\nbase.scopy( x.length, x, 1, y, 1 )\n\n// Advanced indexing:\nx = new Float32Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny = new Float32Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nN = base.floor( x.length / 2 );\nbase.scopy( N, x, -2, y, 1 )\n\n// Using typed array views:\nx0 = new Float32Array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ] );\ny0 = new Float32Array( [ 7.0, 8.0, 9.0, 10.0, 11.0, 12.0 ] );\nx1 = new Float32Array( x0.buffer, x0.BYTES_PER_ELEMENT*1 );\ny1 = new Float32Array( y0.buffer, y0.BYTES_PER_ELEMENT*3 );\nN = base.floor( x0.length / 2 );\nbase.scopy( N, x1, -2, y1, 1 )\ny0\n",
	"base.setHighWord": "\n// Set the higher order bits of `+infinity` to return `1`:\nhigh = 1072693248 >>> 0;\ny = base.setHighWord( PINF, high )\n",
	"base.setLowWord": "low = 5 >>> 0;\nx = 3.14e201;\ny = base.setLowWord( x, low )\n\n// Special cases:\nlow = 12345678;\ny = base.setLowWord( PINF, low )\ny = base.setLowWord( NINF, low )\ny = base.setLowWord( NaN, low )\n",
	"base.sici": "y = base.sici( 3.0 )\ny = base.sici( 0.0 )\ny = base.sici( -9.0 )\ny = base.sici( NaN )\n\n// Provide an output array:\nout = new Float64Array( 2 );\ny = base.sici( 3.0 )\nbool = ( y === out )\n",
	"base.signbit": "bool = base.signbit( 4.0 )\nbool = base.signbit( -9.14e-34 )\nbool = base.signbit( 0.0 )\nbool = base.signbit( -0.0 )\n",
	"base.signbitf": "bool = base.signbitf( base.float64ToFloat32( 4.0 ) )\nbool = base.signbitf( base.float64ToFloat32( -9.14e-34 ) )\nbool = base.signbitf( 0.0 )\nbool = base.signbitf( -0.0 )\n",
	"base.significandf": "s = base.significandf( base.float64ToFloat32( 3.14e34 ) )\ns = base.significandf( base.float64ToFloat32( 3.14e-34 ) )\ns = base.significandf( base.float64ToFloat32( -3.14 ) )\ns = base.significandf( 0.0 )\ns = base.significandf( NaN )\n",
	"base.signum": "sign = base.signum( -5.0 )\nsign = base.signum( 5.0 )\nsign = base.signum( -0.0 )\nsign = base.signum( 0.0 )\nsign = base.signum( NaN )\n",
	"base.sin": "y = base.sin( 0.0 )\ny = base.sin( PI/2.0 )\ny = base.sin( -PI/6.0 )\ny = base.sin( NaN )\n",
	"base.sinc": "y = base.sinc( 0.5 )\ny = base.sinc( -1.2 )\ny = base.sinc( 0.0 )\ny = base.sinc( NaN )\n",
	"base.sincos": "y = base.sincos( 0.0 )\ny = base.sincos( PI/2.0 )\ny = base.sincos( -PI/6.0 )\ny = base.sincos( NaN )\nout = new Float64Array( 2 );\nv = base.sincos( out, 0.0 )\nbool = ( v === out )\n",
	"base.sincospi": "y = base.sincospi( 0.0 )\ny = base.sincospi( 0.5 )\ny = base.sincospi( 0.1 )\ny = base.sincospi( NaN )\nout = new Float64Array( 2 );\nv = base.sincospi( out, 0.0 )\nbool = ( v === out )\n",
	"base.sinh": "y = base.sinh( 0.0 )\ny = base.sinh( 2.0 )\ny = base.sinh( -2.0 )\ny = base.sinh( NaN )\n",
	"base.sinpi": "y = base.sinpi( 0.0 )\ny = base.sinpi( 0.5 )\ny = base.sinpi( 0.9 )\ny = base.sinpi( NaN )\n",
	"base.spence": "y = base.spence( 3.0 )\ny = base.spence( 0.0 )\ny = base.spence( -9.0 )\ny = base.spence( NaN )\n",
	"base.sqrt": "y = base.sqrt( 4.0 )\ny = base.sqrt( 9.0 )\ny = base.sqrt( 0.0 )\ny = base.sqrt( -4.0 )\ny = base.sqrt( NaN )\n",
	"base.sqrt1pm1": "y = base.sqrt1pm1( 3.0 )\ny = base.sqrt1pm1( 0.5 )\ny = base.sqrt1pm1( 0.02 )\ny = base.sqrt1pm1( -0.5 )\ny = base.sqrt1pm1( -1.1 )\ny = base.sqrt1pm1( NaN )\n",
	"base.sumSeries": "\n// Using an ES6 generator function:\nfunction* geometricSeriesGenerator( x ) {\nexponent = 0;\nwhile ( true ) {\nyield Math.pow( x, exponent );\nexponent += 1;\n}\n}\ngen = geometricSeriesGenerator( 0.9 );\nout = base.sumSeries( gen )\n\n// Using a closure:\nfunction geometricSeriesClosure( x ) {\nexponent = -1;\nreturn function() {\nexponent += 1;\nreturn Math.pow( x, exponent );\n};\n}\ngen = geometricSeriesClosure( 0.9 )\nout = base.sumSeries( gen )\n\n// Setting an initial value for the sum:\nout = base.sumSeries( geometricSeriesGenerator( 0.5 ), { 'initialValue': 1 } )\n\n// Changing the maximum number of terms to be summed:\nout = base.sumSeries( geometricSeriesGenerator( 0.5 ), { 'maxTerms': 10 } )\n\n// Adjusting the used tolerance:\nout = base.sumSeries( geometricSeriesGenerator( 0.5 ), { 'tolerance': 1e-3 } )\n",
	"base.tan": "y = base.tan( 0.0 )\ny = base.tan( -PI/4.0 )\ny = base.tan( PI/4.0 )\ny = base.tan( NaN )\n",
	"base.tanh": "y = base.tanh( 0.0 )\ny = base.tanh( -0.0 )\ny = base.tanh( 2.0 )\ny = base.tanh( -2.0 )\ny = base.tanh( NaN )\n",
	"base.toBinaryString": "str = base.toBinaryString( 4.0 )\nstr = base.toBinaryString( PI )\nstr = base.toBinaryString( -1.0e308 )\nstr = base.toBinaryString( -3.14e-320 )\nstr = base.toBinaryString( 5.0e-324 )\nstr = base.toBinaryString( 0.0 )\nstr = base.toBinaryString( -0.0 )\nstr = base.toBinaryString( NaN )\nstr = base.toBinaryString( PINF )\nstr = base.toBinaryString( NINF )\n",
	"base.toBinaryStringf": "str = base.toBinaryStringf( base.float64ToFloat32( 4.0 ) )\nstr = base.toBinaryStringf( base.float64ToFloat32( PI ) )\nstr = base.toBinaryStringf( base.float64ToFloat32( -1.0e38 ) )\nstr = base.toBinaryStringf( base.float64ToFloat32( -3.14e-39 ) )\nstr = base.toBinaryStringf( base.float64ToFloat32( 1.4e-45 ) )\nstr = base.toBinaryStringf( 0.0 )\nstr = base.toBinaryStringf( -0.0 )\nstr = base.toBinaryStringf( NaN )\nstr = base.toBinaryStringf( FLOAT32_PINF )\nstr = base.toBinaryStringf( FLOAT32_NINF )\n",
	"base.toBinaryStringUint16": "a = new Uint16Array( [ 1, 4, 9 ] );\nstr = base.toBinaryStringUint16( a[ 0 ] )\nstr = base.toBinaryStringUint16( a[ 1 ] )\nstr = base.toBinaryStringUint16( a[ 2 ] )\n",
	"base.toBinaryStringUint32": "a = new Uint32Array( [ 1, 4, 9 ] );\nstr = base.toBinaryStringUint32( a[ 0 ] )\nstr = base.toBinaryStringUint32( a[ 1 ] )\nstr = base.toBinaryStringUint32( a[ 2 ] )\n",
	"base.toBinaryStringUint8": "a = new Uint8Array( [ 1, 4, 9 ] );\nstr = base.toBinaryStringUint8( a[ 0 ] )\nstr = base.toBinaryStringUint8( a[ 1 ] )\nstr = base.toBinaryStringUint8( a[ 2 ] )\n",
	"base.toWordf": "f32 = base.float64ToFloat32( 1.337 )\nw = base.toWordf( f32 )\n",
	"base.toWords": "w = base.toWords( 3.14e201 )\n\n// Provide an output array:\nout = new Uint32Array( 2 );\nw = base.toWords( out, 3.14e201 )\nbool = ( w === out )\n",
	"base.trigamma": "y = base.trigamma( -2.5 )\ny = base.trigamma( 1.0 )\ny = base.trigamma( 10.0 )\ny = base.trigamma( NaN )\ny = base.trigamma( -1.0 )\n",
	"base.trunc": "y = base.trunc( 3.14 )\ny = base.trunc( -4.2 )\ny = base.trunc( -4.6 )\ny = base.trunc( 9.5 )\ny = base.trunc( -0.0 )\n",
	"base.trunc10": "y = base.trunc10( 3.14 )\ny = base.trunc10( -4.2 )\ny = base.trunc10( -4.6 )\ny = base.trunc10( 9.5 )\ny = base.trunc10( 13.0 )\ny = base.trunc10( -13.0 )\ny = base.trunc10( -0.0 )\n",
	"base.trunc2": "y = base.trunc2( 3.14 )\ny = base.trunc2( -4.2 )\ny = base.trunc2( -4.6 )\ny = base.trunc2( 9.5 )\ny = base.trunc2( 13.0 )\ny = base.trunc2( -13.0 )\ny = base.trunc2( -0.0 )\n",
	"base.truncb": "\n// Round to 4 decimal places:\ny = base.truncb( 3.14159, -4, 10 )\n\n// If `n = 0` or `b = 1`, standard round behavior:\ny = base.truncb( 3.14159, 0, 2 )\n\n// Round to nearest multiple of two toward zero:\ny = base.truncb( 5.0, 1, 2 )\n",
	"base.truncn": "\n// Round to 4 decimal places:\ny = base.truncn( 3.14159, -4 )\n\n// If `n = 0`, standard round behavior:\ny = base.truncn( 3.14159, 0 )\n\n// Round to nearest thousand:\ny = base.truncn( 12368.0, 3 )\n",
	"base.truncsd": "y = base.truncsd( 3.14159, 5 )\ny = base.truncsd( 3.14159, 1 )\ny = base.truncsd( 12368.0, 2 )\ny = base.truncsd( 0.0313, 2, 2 )\n",
	"base.uint32ToInt32": "y = base.uint32ToInt32( base.float64ToUint32( 4294967295 ) )\ny = base.uint32ToInt32( base.float64ToUint32( 3 ) )\n",
	"base.vercos": "y = base.vercos( 3.14 )\ny = base.vercos( -4.2 )\ny = base.vercos( -4.6 )\ny = base.vercos( 9.5 )\ny = base.vercos( -0.0 )\n",
	"base.versin": "y = base.versin( 3.14 )\ny = base.versin( -4.2 )\ny = base.versin( -4.6 )\ny = base.versin( 9.5 )\ny = base.versin( -0.0 )\n",
	"base.wrap": "y = base.wrap( 3.14, 0.0, 5.0 )\ny = base.wrap( -3.14, 0.0, 5.0 )\ny = base.wrap( 3.14, 0.0, 3.0 )\ny = base.wrap( -0.0, 0.0, 5.0 )\ny = base.wrap( 0.0, -3.14, -0.0 )\ny = base.wrap( NaN, 0.0, 5.0 )\n",
	"base.xlogy": "out = base.xlogy( 3.0, 2.0 )\nout = base.xlogy( 1.5, 5.9 )\nout = base.xlogy( 0.9, 1.0 )\nout = base.xlogy( 0.0, -2.0 )\nout = base.xlogy( 1.5, NaN )\nout = base.xlogy( 0.0, NaN )\nout = base.xlogy( NaN, 2.3 )\n",
	"base.xlog1py": "out = base.xlog1py( 3.0, 2.0 )\nout = base.xlog1py( 1.5, 5.9 )\nout = base.xlog1py( 0.9, 1.0 )\nout = base.xlog1py( 1.0, 0.0 )\nout = base.xlog1py( 0.0, -2.0 )\nout = base.xlog1py( 1.5, NaN )\nout = base.xlog1py( 0.0, NaN )\nout = base.xlog1py( NaN, 2.3 )\n",
	"base.zeta": "y = base.zeta( 1.1 )\ny = base.zeta( -4.0 )\ny = base.zeta( 70.0 )\ny = base.zeta( 0.5 )\ny = base.zeta( NaN )\n\n// Evaluate at a pole:\ny = base.zeta( 1.0 )\n",
	"bifurcate": "collection = [ 'beep', 'boop', 'foo', 'bar' ];\nf = [ true, true, false, true ];\nout = bifurcate( collection, f )\nf = [ 1, 1, 0, 1 ];\nout = bifurcate( collection, f )\n\n// Output group results as indices:\nf = [ true, true, false, true ];\nopts = { 'returns': 'indices' };\nout = bifurcate( collection, opts, f )\n\n// Output group results as index-element pairs:\nopts = { 'returns': '*' };\nout = bifurcate( collection, opts, f )\n",
	"bifurcateBy": "function predicate( v ) { v[ 0 ] === 'b' };\ncollection = [ 'beep', 'boop', 'foo', 'bar' ];\nout = bifurcateBy( collection, predicate )\n\n// Output group results as indices:\nopts = { 'returns': 'indices' };\nout = bifurcateBy( collection, opts, predicate )\n\n// Output group results as index-value pairs:\nopts = { 'returns': '*' };\nout = bifurcateBy( collection, opts, predicate )\n",
	"bifurcateByAsync": "\n// Basic usage:\nfunction predicate( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\narr = [ 3000, 2500, 1000 ];\nbifurcateByAsync( arr, predicate, done )\n\n// Output group results as indices:\nopts = { 'returns': 'indices' };\nbifurcateByAsync( arr, opts, predicate, done )\n\n// Output group results as index-value pairs:\nopts = { 'returns': '*' };\nbifurcateByAsync( arr, opts, predicate done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nbifurcateByAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\nbifurcateByAsync( arr, opts, predicate, done )\n",
	"bifurcateIn": "function Foo() { this.a = 'beep'; this.b = 'boop'; return this; };\nFoo.prototype = Object.create( null );\nFoo.prototype.c = 'foo';\nFoo.prototype.d = 'bar';\nobj = new Foo();\nfunction predicate( v ) { v[ 0 ] === 'b' };\nout = bifurcateIn( obj, predicate )\n\n// Output group results as keys:\nopts = { 'returns': 'keys' };\nout = bifurcateIn( obj, opts, predicate )\n\n// Output group results as key-value pairs:\nopts = { 'returns': '*' };\nout = bifurcateIn( obj, opts, predicate )\n",
	"bifurcateOwn": "function predicate( v ) { v[ 0 ] === 'b' };\nobj = { 'a': 'beep', 'b': 'boop', 'c': 'foo', 'd': 'bar' };\nout = bifurcateOwn( obj, predicate )\n\n// Output group results as keys:\nopts = { 'returns': 'keys' };\nout = bifurcateOwn( obj, opts, predicate )\n\n// Output group results as key-value pairs:\nopts = { 'returns': '*' };\nout = bifurcateOwn( obj, opts, predicate )\n",
	"Buffer": "b = new Buffer( 4 )\n",
	"buffer2json": "buf = new allocUnsafe( 2 );\nbuf[ 0 ] = 1;\nbuf[ 1 ] = 2;\njson = buffer2json( buf )\n",
	"capitalize": "out = capitalize( 'beep' )\nout = capitalize( 'Boop' )\n",
	"capitalizeKeys": "obj = { 'aa': 1, 'bb': 2 };\nout = capitalizeKeys( obj )\n",
	"CATALAN": "CATALAN\n",
	"CBRT_EPS": "CBRT_EPS\n",
	"chi2gof": "\n// Use probabilities for `y`:\nx = [ 89, 37, 30, 28, 2 ];\np = [ 0.40, 0.20, 0.20, 0.15, 0.05 ];\nout = chi2gof( x, p )\ntable = out.print()\n\n// Set significance level:\nout = chi2gof( x, p, { 'alpha': 0.01 });\ntable = out.print()\n\n// Calculate the p-value via Monte Carlo simulation:\nx = [ 89, 37, 30, 28, 2 ];\np = [ 0.40, 0.20, 0.20, 0.15, 0.05 ];\nout = chi2gof( x, p, { 'simulate': true, 'iterations': 1000 })\n\n// Verify that data comes from Poisson distribution:\nlambda = 3.0;\nrpois = base.random.poisson.factory( lambda );\nlen = 400;\nx = new Array( len );\nfor ( var i = 0; i < len; i++ ) { x[ i ] = rpois(); }\n\n// Generate frequency table:\nfreqs = [];\nfor ( i = 0; i < len; i++ ) {\n  val = x[ i ];\n  freqs[ val ] === void 0 ? freqs[ val ] = 1 : freqs[ val ] += 1;\n}\n\n// Fill holes in array:\nfor ( i = 0; i < freqs.length; i++ ) {\n  if ( freqs[ i ] === void 0 ) { freqs[ i ] = 0; }\n}\nout = chi2gof( freqs, 'poisson', lambda );\n",
	"complex": "z = complex( 5.0, 3.0, 'float64' )\nz = complex( 5.0, 3.0, 'float32' )\n",
	"Complex128": "z = Complex128( 5.0, 3.0 )\nz.re\nz.im\n",
	"COMPLEX128_NUM_BYTES": "COMPLEX128_NUM_BYTES\n",
	"Complex64": "z = Complex64( 5.0, 3.0 )\nz.re\nz.im\n",
	"COMPLEX64_NUM_BYTES": "COMPLEX64_NUM_BYTES\n",
	"compose": "function a( x ) {\n   return 2 * x;\n}\nfunction b( x ) {\n   return x + 3;\n}\nfunction c( x ) {\n   return x / 5;\n}\nf = compose( c, b, a );\nz = f( 6 )\n",
	"composeAsync": "function a( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, 2*x );\n   }\n};\nfunction b( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, x+3 );\n   }\n};\nfunction c( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, x/5 );\n   }\n};\nf = composeAsync( c, b, a );\nfunction done( error, result ) {\n   if ( error ) {\n     throw error;\n   }\n   console.log( result );\n};\nf( 6, done )\n",
	"configdir": "dir = configdir()\ndir = configdir( 'appname/config' )\n",
	"conj": "z = new Complex128( 5.0, 3.0 );\nz.toString()\nv = conj( z );\nv.toString()\n",
	"constantFunction": "fcn = constantFunction( 3.14 );\nv = fcn()\nv = fcn()\nv = fcn()\n",
	"constructorName": "v = constructorName( 'a' )\nv = constructorName( {} )\nv = constructorName( true )\n",
	"contains": "bool = contains( 'Hello World', 'World' )\nbool = contains( 'Hello World', 'world' )\nbool = contains( [ 1, 2, 3, 4 ], 2 )\nbool = contains( [ NaN, 2, 3, 4 ], NaN )\n\n// Supply a position:\nbool = contains( 'Hello World', 'Hello', 6 )\nbool = contains( [ true, NaN, false ], true, 1 )\n",
	"convertArray": "arr = [ 1.0, 2.0, 3.0, 4.0 ];\nout = convertArray( arr, 'float32' )\n",
	"convertArraySame": "x = [ 1.0, 2.0, 3.0, 4.0 ];\ny = Float32Array( 0 );\nout = convertArraySame( x, y )\n",
	"convertPath": "out = convertPath( '/c/foo/bar/beep.c', 'win32' )\nout = convertPath( '/c/foo/bar/beep.c', 'mixed' )\nout = convertPath( '/c/foo/bar/beep.c', 'posix' )\nout = convertPath( 'C:\\\\\\\\foo\\\\bar\\\\beep.c', 'win32' )\nout = convertPath( 'C:\\\\\\\\foo\\\\bar\\\\beep.c', 'mixed' )\nout = convertPath( 'C:\\\\\\\\foo\\\\bar\\\\beep.c', 'posix' )\n",
	"copy": "value = [ { 'a': 1, 'b': true, 'c': [ 1, 2, 3 ] } ];\nout = copy( value )\nbool = ( value[ 0 ].c === out[ 0 ].c )\n\n// Set the `level` option to limit the copy depth:\nvalue = [ { 'a': 1, 'b': true, 'c': [ 1, 2, 3 ] } ];\nout = copy( value, 1 );\nbool = ( value[ 0 ] === out[ 0 ] )\nbool = ( value[ 0 ].c === out[ 0 ].c )\n",
	"copyBuffer": "b1 = array2buffer( [ 1, 2, 3, 4 ] );\nb2 = copyBuffer( b1 )\n",
	"countBy": "function indicator( v ) {\n  if ( v[ 0 ] === 'b' ) {\n      return 'b';\n  }\n  return 'other';\n};\ncollection = [ 'beep', 'boop', 'foo', 'bar' ];\nout = countBy( collection, indicator )\n",
	"countByAsync": "\n// Basic usage:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even': 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\narr = [ 3000, 2500, 1000 ];\ncountByAsync( arr, indicator, done )\n\n// Limit number of concurrent invocations:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even' : 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\ncountByAsync( arr, opts, indicator, done )\n\n// Process sequentially:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even' : 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\ncountByAsync( arr, opts, indicator, done )\n",
	"curry": "function add( x, y ) { return x + y; };\nf = curry( add );\nsum = f( 2 )( 3 )\n\n// Supply arity:\nfunction add() { return arguments[ 0 ] + arguments[ 1 ]; };\nf = curry( add, 2 );\nsum = f( 2 )( 3 )\n\n// Provide function context:\nobj = {\n  'name': 'Ada',\n  'greet': function greet( word1, word2 ) {\n     return word1 + ' ' + word2 + ', ' + this.name + '!'\n  }\n};\nf = curry( obj.greet, obj );\nstr = f( 'Hello' )( 'there' )\n",
	"curryRight": "function add( x, y ) { return x + y; };\nf = curryRight( add );\nsum = f( 2 )( 3 )\n\n// Supply arity:\nfunction add() { return arguments[ 0 ] + arguments[ 1 ]; };\nf = curryRight( add, 2 );\nsum = f( 2 )( 3 )\n\n// Provide function context:\nobj = {\n  'name': 'Ada',\n  'greet': function greet( word1, word2 ) {\n      return word1 + ' ' + word2 + ', ' + this.name + '!'\n  }\n};\nf = curryRight( obj.greet, obj );\nstr = f( 'Hello' )( 'there' )\n",
	"cwd": "dir = cwd()\n",
	"DALE_CHALL_NEW": "list = DALE_CHALL_NEW()\n",
	"datasets": "out = datasets( 'MONTH_NAMES_EN' )\nopts = { 'data': 'cities' };\nout = datasets( 'MINARD_NAPOLEONS_MARCH', opts )\n",
	"dayOfQuarter": "day = dayOfQuarter()\nday = dayOfQuarter( new Date() )\nday = dayOfQuarter( 12, 31, 2017 )\n\n// Other ways to supply month:\nday = dayOfQuarter( 'dec', 31, 2017 )\nday = dayOfQuarter( 'december', 31, 2017 )\n",
	"dayOfYear": "day = dayOfYear()\nday = dayOfYear( new Date() )\nday = dayOfYear( 12, 31, 2016 )\n\n// Other ways to supply month:\nday = dayOfYear( 'dec', 31, 2016 )\nday = dayOfYear( 'december', 31, 2016 )\n",
	"daysInMonth": "num = daysInMonth()\nnum = daysInMonth( 2 )\nnum = daysInMonth( 2, 2016 )\nnum = daysInMonth( 2, 2017 )\n\n// Other ways to supply month:\nnum = daysInMonth( 'feb', 2016 )\nnum = daysInMonth( 'february', 2016 )\n",
	"daysInYear": "num = daysInYear()\nnum = daysInYear( 2016 )\nnum = daysInYear( 2017 )\n",
	"deepGet": "obj = { 'a': { 'b': { 'c': 'd' } } };\nval = deepGet( obj, 'a.b.c' )\n\n// Specify a custom separator via the `sep` option:\nobj = { 'a': { 'b': { 'c': 'd' } } };\nval = deepGet( obj, 'a/b/c', { 'sep': '/' } )\n",
	"deepHasOwnProp": "obj = { 'a': { 'b': { 'c': 'd' } } };\nbool = deepHasOwnProp( obj, 'a.b.c' )\n\n// Specify a custom separator via the `sep` option:\nobj = { 'a': { 'b': { 'c': 'd' } } };\nbool = deepHasOwnProp( obj, 'a/b/c', { 'sep': '/' } )\n",
	"deepHasProp": "function Foo() { return this; };\nFoo.prototype.b = { 'c': 'd' };\nobj = { 'a': new Foo() };\nbool = deepHasProp( obj, 'a.b.c' )\n\n// Specify a custom separator via the `sep` option:\nbool = deepHasProp( obj, 'a/b/c', { 'sep': '/' } )\n",
	"deepPluck": "arr = [\n  { 'a': { 'b': { 'c': 1 } } },\n  { 'a': { 'b': { 'c': 2 } } }\n];\nout = deepPluck( arr, 'a.b.c' )\narr = [\n  { 'a': [ 0, 1, 2 ] },\n  { 'a': [ 3, 4, 5 ] }\n];\nout = deepPluck( arr, [ 'a', 1 ] )\n",
	"deepSet": "obj = { 'a': { 'b': { 'c': 'd' } } };\nbool = deepSet( obj, 'a.b.c', 'beep' )\n\n// Specify an alternative separator via the sep option:\nobj = { 'a': { 'b': { 'c': 'd' } } };\nbool = deepSet( obj, 'a/b/c', 'beep', { 'sep': '/' } );\nobj\n\n// To create a key path which does not exist, set the create option to true:\nbool = deepSet( obj, 'a.e.c', 'boop', { 'create': true } );\nobj\n",
	"dirname": "dir = dirname( './foo/bar/index.js' )\n",
	"doUntil": "function predicate( i ) { return ( i >= 5 ); };\nfunction beep( i ) { console.log( 'boop: %d', i ); };\ndoUntil( beep, predicate )\n",
	"doUntilAsync": "function fcn( i, next ) {\n  setTimeout( onTimeout, i );\n  function onTimeout() {\n      next( null, 'boop'+i );\n  }\n};\nfunction predicate( i, clbk ) { clbk( null, i >= 5 ); };\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\ndoUntilAsync( fcn, predicate, done )\n",
	"doUntilEach": "function predicate( v ) { return v !== v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4, NaN, 5 ];\ndoUntilEach( arr, logger, predicate )\n",
	"doUntilEachRight": "function predicate( v ) { return v !== v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, NaN, 2, 3, 4, 5 ];\ndoUntilEachRight( arr, logger, predicate )\n",
	"doWhile": "function predicate( i ) { return ( i < 5 ); };\nfunction beep( i ) { console.log( 'boop: %d', i ); };\ndoWhile( beep, predicate )\n",
	"doWhileAsync": "function fcn( i, next ) {\n  setTimeout( onTimeout, i );\n  function onTimeout() {\n      next( null, 'boop'+i );\n  }\n};\nfunction predicate( i, clbk ) { clbk( null, i < 5 ); };\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\ndoWhileAsync( fcn, predicate, done )\n",
	"doWhileEach": "function predicate( v ) { return v === v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4, NaN, 5 ];\ndoWhileEach( arr, logger, predicate )\n",
	"doWhileEachRight": "function predicate( v ) { return v === v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, NaN, 2, 3, 4, 5 ];\ndoWhileEachRight( arr, logger, predicate )\n",
	"E": "E\n",
	"endsWith": "bool = endsWith( 'beep', 'ep' )\nbool = endsWith( 'Beep', 'op' )\nbool = endsWith( 'Beep', 'ee', 3 )\nbool = endsWith( 'Beep', 'ee', -1 )\nbool = endsWith( 'beep', '' )\n",
	"ENV": "user = ENV.USER\n",
	"EPS": "EPS\n",
	"EULERGAMMA": "EULERGAMMA\n",
	"error2json": "err = new Error( 'beep' );\njson = error2json( err )\n",
	"evil": "v = evil( '5*4*3*2*1' );\n",
	"every": "arr = [ 1, 1, 1, 1, 1 ];\nbool = every( arr )\n",
	"everyBy": "function positive( v ) { return ( v > 0 ); };\narr = [ 1, 2, 3, 4 ];\nbool = everyBy( arr, positive )\n",
	"everyByAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 3000, 2500, 1000 ];\neveryByAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\neveryByAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\neveryByAsync( arr, opts, predicate, done )\n",
	"everyByRight": "function positive( v ) { return ( v > 0 ); };\narr = [ 1, 2, 3, 4 ];\nbool = everyByRight( arr, positive )\n",
	"everyByRightAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 1000, 2500, 3000 ];\neveryByRightAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\neveryByRightAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, true );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\neveryByRightAsync( arr, opts, predicate, done )\n",
	"exists": "function done( error, bool ) { console.log( bool ); };\nexists( './beep/boop', done );\n",
	"expandContractions": "str = 'I won\\'t be able to get y\\'all out of this one.';\nout = expandContractions( str )\nstr = 'It oughtn't to be my fault, because, you know, I didn't know';\nout = expandContractions( str )\n",
	"extname": "ext = extname( 'index.js' )\n",
	"fastmath.abs": "v = fastmath.abs( -1.0 )\nv = fastmath.abs( 2.0 )\nv = fastmath.abs( 0.0 )\nv = fastmath.abs( -0.0 )\nv = fastmath.abs( NaN )\n",
	"fastmath.acosh": "v = fastmath.acosh( 1.0 )\nv = fastmath.acosh( 2.0 )\nv = fastmath.acosh( NaN )\n\n// The function overflows for large `x`:\nv = fastmath.acosh( 1.0e308 )\n",
	"fastmath.ampbm": "h = fastmath.ampbm( 5.0, 12.0 )\n",
	"fastmath.asinh": "v = fastmath.asinh( 0.0 )\nv = fastmath.asinh( 2.0 )\nv = fastmath.asinh( -2.0 )\nv = fastmath.asinh( NaN )\n\n// The function overflows for large `x`:\nv = fastmath.asinh( 1.0e200 )\n\n// The function underflows for small `x`:\nv = fastmath.asinh( 1.0e-50 )\n",
	"fastmath.atanh": "v = fastmath.atanh( 0.0 )\nv = fastmath.atanh( 0.9 )\nv = fastmath.atanh( 1.0 )\nv = fastmath.atanh( -1.0 )\nv = fastmath.atanh( NaN )\n\n// The function underflows for small `x`:\nv = fastmath.atanh( 1.0e-17 )\n",
	"fastmath.hypot": "h = fastmath.hypot( -5.0, 12.0 )\n\n// For a sufficiently large `x` and/or `y`, the function overflows:\nh = fastmath.hypot( 1.0e154, 1.0e154 )\n\n// For sufficiently small `x` and/or `y`, the function underflows:\nh = fastmath.hypot( 1e-200, 1.0e-200 )\n",
	"fastmath.log2Uint32": "v = fastmath.log2Uint32( 4 >>> 0 )\nv = fastmath.log2Uint32( 8 >>> 0 )\nv = fastmath.log2Uint32( 9 >>> 0 )\n",
	"fastmath.max": "v = fastmath.max( 3.14, 4.2 )\nv = fastmath.max( 3.14, NaN )\nv = fastmath.max( NaN, 3.14 )\nv = fastmath.max( -0.0, +0.0 )\nv = fastmath.max( +0.0, -0.0 )\n",
	"fastmath.min": "v = fastmath.min( 3.14, 4.2 )\nv = fastmath.min( 3.14, NaN )\nv = fastmath.min( NaN, 3.14 )\nv = fastmath.min( -0.0, +0.0 )\nv = fastmath.min( +0.0, -0.0 )\n",
	"fastmath.powint": "v = fastmath.powint( 2.0, 3 )\nv = fastmath.powint( 3.14, 0 )\nv = fastmath.powint( 2.0, -2 )\nv = fastmath.powint( 0.0, 0 )\nv = fastmath.powint( -3.14, 1 )\nv = fastmath.powint( NaN, 0 )\n",
	"fastmath.sqrtUint32": "v = fastmath.sqrtUint32( 9 >>> 0 )\nv = fastmath.sqrtUint32( 2 >>> 0 )\nv = fastmath.sqrtUint32( 3 >>> 0 )\nv = fastmath.sqrtUint32( 0 >>> 0 )\n",
	"FEMALE_FIRST_NAMES_EN": "list = FEMALE_FIRST_NAMES_EN()\n",
	"find": "data = [ 30, 20, 50, 60, 10 ];\nfunction condition( val ) { return val > 20; };\nvals = find( data, condition )\n\n// Limit number of results:\ndata = [ 30, 20, 50, 60, 10 ];\nopts = { 'k': 2, 'returns': 'values' };\nvals = find( data, opts, condition )\n\n// Return both indices and values as index-value pairs:\ndata = [ 30, 20, 50, 60, 10 ];\nopts = { 'k': -2, 'returns': '*' };\nvals = find( data, opts, condition )\n",
	"flattenArray": "arr = [ 1, [ 2, [ 3, [ 4, [ 5 ], 6 ], 7 ], 8 ], 9 ];\nout = flattenArray( arr )\n\n// Set the maximum depth:\narr = [ 1, [ 2, [ 3, [ 4, [ 5 ], 6 ], 7 ], 8 ], 9 ];\nout = flattenArray( arr, { 'depth': 2 } )\nbool = ( arr[ 1 ][ 1 ][ 1 ] === out[ 3 ] )\n\n// Deep copy:\narr = [ 1, [ 2, [ 3, [ 4, [ 5 ], 6 ], 7 ], 8 ], 9 ];\nout = flattenArray( arr, { 'depth': 2, 'copy': true } )\nbool = ( arr[ 1 ][ 1 ][ 1 ] === out[ 3 ] )\n",
	"flattenObject": "obj = { 'a': { 'b': { 'c': 'd' } } };\nout = flattenObject( obj )\n\n// Set the `depth` option to flatten to a specified depth:\nobj = { 'a': { 'b': { 'c': 'd' } } };\nout = flattenObject( obj, { 'depth': 1 } )\nbool = ( obj.a.b === out[ 'a.b' ] )\n\n// Set the `delimiter` option:\nobj = { 'a': { 'b': { 'c': 'd' } } };\nout = flattenObject( obj, { 'delimiter': '-|-' } )\n\n// Flatten arrays:\nobj = { 'a': { 'b': [ 1, 2, 3 ] } };\nout = flattenObject( obj, { 'flattenArrays': true } )\n",
	"FLOAT16_CBRT_EPS": "FLOAT16_CBRT_EPS\n",
	"FLOAT16_EPS": "FLOAT16_EPS\n",
	"FLOAT16_EXPONENT_BIAS": "FLOAT16_EXPONENT_BIAS\n",
	"FLOAT16_MAX": "FLOAT16_MAX\n",
	"FLOAT16_MAX_SAFE_INTEGER": "FLOAT16_MAX_SAFE_INTEGER\n",
	"FLOAT16_MIN_SAFE_INTEGER": "FLOAT16_MIN_SAFE_INTEGER\n",
	"FLOAT16_NINF": "FLOAT16_NINF\n",
	"FLOAT16_NUM_BYTES": "FLOAT16_NUM_BYTES\n",
	"FLOAT16_PINF": "FLOAT16_PINF\n",
	"FLOAT16_PRECISION": "FLOAT16_PRECISION\n",
	"FLOAT16_SMALLEST_NORMAL": "FLOAT16_SMALLEST_NORMAL\n",
	"FLOAT16_SMALLEST_SUBNORMAL": "FLOAT16_SMALLEST_SUBNORMAL\n",
	"FLOAT16_SQRT_EPS": "FLOAT16_SQRT_EPS\n",
	"Float32Array": "arr = new Float32Array()\n",
	"FLOAT32_CBRT_EPS": "FLOAT32_CBRT_EPS\n",
	"FLOAT32_EPS": "FLOAT32_EPS\n",
	"FLOAT32_EXPONENT_BIAS": "FLOAT32_EXPONENT_BIAS\n",
	"FLOAT32_MAX": "FLOAT32_MAX\n",
	"FLOAT32_MAX_SAFE_INTEGER": "FLOAT32_MAX_SAFE_INTEGER\n",
	"FLOAT32_MIN_SAFE_INTEGER": "FLOAT32_MIN_SAFE_INTEGER\n",
	"FLOAT32_NINF": "FLOAT32_NINF\n",
	"FLOAT32_NUM_BYTES": "FLOAT32_NUM_BYTES\n",
	"FLOAT32_PINF": "FLOAT32_PINF\n",
	"FLOAT32_PRECISION": "FLOAT32_PRECISION\n",
	"FLOAT32_SMALLEST_NORMAL": "FLOAT32_SMALLEST_NORMAL\n",
	"FLOAT32_SMALLEST_SUBNORMAL": "FLOAT32_SMALLEST_SUBNORMAL\n",
	"FLOAT32_SQRT_EPS": "FLOAT32_SQRT_EPS\n",
	"Float64Array": "arr = new Float64Array()\n",
	"FLOAT64_EXPONENT_BIAS": "FLOAT64_EXPONENT_BIAS\n",
	"FLOAT64_HIGH_WORD_EXPONENT_MASK": "FLOAT64_HIGH_WORD_EXPONENT_MASK\nbase.toBinaryStringUint32( FLOAT64_HIGH_WORD_EXPONENT_MASK )\n",
	"FLOAT64_HIGH_WORD_SIGNIFICAND_MASK": "FLOAT64_HIGH_WORD_SIGNIFICAND_MASK\nbase.toBinaryStringUint32( FLOAT64_HIGH_WORD_SIGNIFICAND_MASK )\n",
	"FLOAT64_MAX": "FLOAT64_MAX\n",
	"FLOAT64_MAX_BASE10_EXPONENT": "FLOAT64_MAX_BASE10_EXPONENT\n",
	"FLOAT64_MAX_BASE10_EXPONENT_SUBNORMAL": "FLOAT64_MAX_BASE10_EXPONENT_SUBNORMAL\n",
	"FLOAT64_MAX_BASE2_EXPONENT": "FLOAT64_MAX_BASE2_EXPONENT\n",
	"FLOAT64_MAX_BASE2_EXPONENT_SUBNORMAL": "FLOAT64_MAX_BASE2_EXPONENT_SUBNORMAL\n",
	"FLOAT64_MAX_LN": "FLOAT64_MAX_LN\n",
	"FLOAT64_MAX_SAFE_FIBONACCI": "FLOAT64_MAX_SAFE_FIBONACCI\n",
	"FLOAT64_MAX_SAFE_INTEGER": "FLOAT64_MAX_SAFE_INTEGER\n",
	"FLOAT64_MAX_SAFE_LUCAS": "FLOAT64_MAX_SAFE_LUCAS\n",
	"FLOAT64_MAX_SAFE_NTH_FIBONACCI": "FLOAT64_MAX_SAFE_NTH_FIBONACCI\n",
	"FLOAT64_MAX_SAFE_NTH_LUCAS": "FLOAT64_MAX_SAFE_NTH_LUCAS\n",
	"FLOAT64_MIN_BASE10_EXPONENT": "FLOAT64_MIN_BASE10_EXPONENT\n",
	"FLOAT64_MIN_BASE10_EXPONENT_SUBNORMAL": "FLOAT64_MIN_BASE10_EXPONENT_SUBNORMAL\n",
	"FLOAT64_MIN_BASE2_EXPONENT": "FLOAT64_MIN_BASE2_EXPONENT\n",
	"FLOAT64_MIN_BASE2_EXPONENT_SUBNORMAL": "FLOAT64_MIN_BASE2_EXPONENT_SUBNORMAL\n",
	"FLOAT64_MIN_LN": "FLOAT64_MIN_LN\n",
	"FLOAT64_MIN_SAFE_INTEGER": "FLOAT64_MIN_SAFE_INTEGER\n",
	"FLOAT64_NUM_BYTES": "FLOAT64_NUM_BYTES\n",
	"FLOAT64_PRECISION": "FLOAT64_PRECISION\n",
	"FLOAT64_SMALLEST_NORMAL": "FLOAT64_SMALLEST_NORMAL\n",
	"FLOAT64_SMALLEST_SUBNORMAL": "FLOAT64_SMALLEST_SUBNORMAL\n",
	"forEach": "function logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4 ];\nforEach( arr, logger )\n",
	"forEachAsync": "\n// Basic usage:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\narr = [ 3000, 2500, 1000 ];\nforEachAsync( arr, onDuration, done )\n\n// Limit number of concurrent invocations:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nforEachAsync( arr, opts, onDuration, done )\n\n// Process sequentially:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\nforEachAsync( arr, opts, onDuration, done )\n",
	"forEachRight": "function logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4 ];\nforEachRight( arr, logger )\n",
	"forEachRightAsync": "\n// Basic usage:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\narr = [ 1000, 2500, 3000 ];\nforEachRightAsync( arr, onDuration, done )\n\n// Limit number of concurrent invocations:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\nforEachRightAsync( arr, opts, onDuration, done )\n\n// Process sequentially:\nfunction onDuration( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next();\n  }\n};\nfunction done( error ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( 'Done.' );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\nforEachRightAsync( arr, opts, onDuration, done )\n",
	"forIn": "function logger( v, k ) { console.log( '%s: %d', k, v ); };\nfunction Foo() { return this; };\nFoo.prototype.beep = 'boop';\nobj = new Foo();\nforIn( obj, logger )\n",
	"forOwn": "function logger( v, k ) { console.log( '%s: %d', k, v ); };\nobj = { 'a': 1, 'b': 2, 'c': 3, 'd': 4 };\nforOwn( obj, logger )\n",
	"FOURTH_PI": "FOURTH_PI\n",
	"FOURTH_ROOT_EPS": "FOURTH_ROOT_EPS\n",
	"FRB_SF_WAGE_RIGIDITY": "data = FRB_SF_WAGE_RIGIDITY()\n",
	"fromCodePoint": "out = fromCodePoint( 9731 )\nout = fromCodePoint( [ 9731 ] )\nout = fromCodePoint( 97, 98, 99 )\nout = fromCodePoint( [ 97, 98, 99 ] )\n",
	"functionName": "v = functionName( String )\nv = functionName( function foo(){} )\nv = functionName( function(){} )\n",
	"functionSequence": "function a( x ) { return 2 * x; };\nfunction b( x ) { return x + 3; };\nfunction c( x ) { return x / 5; };\nf = functionSequence( a, b, c );\nz = f( 6 )\n",
	"functionSequenceAsync": "function a( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, 2*x );\n   }\n};\nfunction b( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, x+3 );\n   }\n};\nfunction c( x, next ) {\n   setTimeout( onTimeout, 0 );\n   function onTimeout() {\n     next( null, x/5 );\n   }\n};\nf = functionSequenceAsync( a, b, c );\nfunction done( error, result ) {\n   if ( error ) {\n     throw error;\n   }\n   console.log( result );\n};\nf( 6, done )\n",
	"GAMMA_LANCZOS_G": "GAMMA_LANCZOS_G\n",
	"getPrototypeOf": "proto = getPrototypeOf( {} )\n",
	"getuid": "uid = getuid();\n",
	"GLAISHER": "GLAISHER\n",
	"group": "collection = [ 'beep', 'boop', 'foo', 'bar' ];\ngroups = [ 'b', 'b', 'f', 'b' ];\nout = group( collection, groups )\ngroups = [ 1, 1, 2, 1 ];\nout = group( collection, groups )\n\n// Output group results as indices:\ngroups = [ 'b', 'b', 'f', 'b' ];\nopts = { 'returns': 'indices' };\nout = group( collection, opts, groups )\n\n// Output group results as index-element pairs:\nopts = { 'returns': '*' };\nout = group( collection, opts, groups )\n",
	"groupBy": "function indicator( v ) {\n  if ( v[ 0 ] === 'b' ) {\n      return 'b';\n  }\n  return 'other';\n};\ncollection = [ 'beep', 'boop', 'foo', 'bar' ];\nout = groupBy( collection, indicator )\n\n// Output group results as indices:\nopts = { 'returns': 'indices' };\nout = groupBy( collection, opts, indicator )\n\n// Output group results as index-value pairs:\nopts = { 'returns': '*' };\nout = groupBy( collection, opts, indicator )\n",
	"groupByAsync": "\n// Basic usage:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\narr = [ 3000, 2500, 1000 ];\ngroupByAsync( arr, indicator, done )\n\n// Output group results as indices:\nopts = { 'returns': 'indices' };\ngroupByAsync( arr, opts, indicator, done )\n\n// Output group results as index-value pairs:\nopts = { 'returns': '*' };\ngroupByAsync( arr, opts, indicator done )\n\n// Limit number of concurrent invocations:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\ngroupByAsync( arr, opts, indicator, done )\n\n// Process sequentially:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\ngroupByAsync( arr, opts, indicator, done )\n",
	"groupIn": "function indicator( v ) {\n  if ( v[ 0 ] === 'b' ) {\n      return 'b';\n  }\n  return 'other';\n};\nfunction Foo() { this.a = 'beep'; this.b = 'boop'; return this; };\nFoo.prototype = Object.create( null );\nFoo.prototype.c = 'foo';\nFoo.prototype.d = 'bar';\nobj = new Foo();\nout = groupIn( obj, indicator )\n\n// Output group results as keys:\nopts = { 'returns': 'keys' };\nout = groupIn( obj, opts, indicator )\n\n// Output group results as key-value pairs:\nopts = { 'returns': '*' };\nout = groupIn( obj, opts, indicator )\n",
	"groupOwn": "function indicator( v ) {\n  if ( v[ 0 ] === 'b' ) {\n      return 'b';\n  }\n  return 'other';\n};\nobj = { 'a': 'beep', 'b': 'boop', 'c': 'foo', 'd': 'bar' };\nout = groupOwn( obj, indicator )\n\n// Output group results as keys:\nopts = { 'returns': 'keys' };\nout = groupOwn( obj, opts, indicator )\n\n// Output group results as key-value pairs:\nopts = { 'returns': '*' };\nout = groupOwn( obj, opts, indicator )\n",
	"HALF_LN2": "HALF_LN2\n",
	"HALF_PI": "HALF_PI\n",
	"hasArrayBufferSupport": "bool = hasArrayBufferSupport()\n",
	"hasAsyncAwaitSupport": "bool = hasAsyncAwaitSupport()\n",
	"hasClassSupport": "bool = hasClassSupport()\n",
	"hasFloat32ArraySupport": "bool = hasFloat32ArraySupport()\n",
	"hasFloat64ArraySupport": "bool = hasFloat64ArraySupport()\n",
	"hasFunctionNameSupport": "bool = hasFunctionNameSupport()\n",
	"hasGeneratorSupport": "bool = hasGeneratorSupport()\n",
	"hasInt16ArraySupport": "bool = hasInt16ArraySupport()\n",
	"hasInt32ArraySupport": "bool = hasInt32ArraySupport()\n",
	"hasInt8ArraySupport": "bool = hasInt8ArraySupport()\n",
	"hasMapSupport": "bool = hasMapSupport()\n",
	"hasNodeBufferSupport": "bool = hasNodeBufferSupport()\n",
	"hasOwnProp": "beep = { 'boop': true };\nbool = hasOwnProp( beep, 'boop' )\nbool = hasOwnProp( beep, 'bop' )\n",
	"hasProp": "beep = { 'boop': true };\nbool = hasProp( beep, 'boop' )\nbool = hasProp( beep, 'toString' )\nbool = hasProp( beep, 'bop' )\n",
	"hasPrototype": "function Foo() { return this; };\nfunction Bar() { return this; };\ninherit( Bar, Foo );\nbar = new Bar();\nbool = hasPrototype( bar, Foo.prototype )\n",
	"hasProxySupport": "bool = hasProxySupport()\n",
	"hasSetSupport": "bool = hasSetSupport()\n",
	"hasSharedArrayBufferSupport": "bool = hasSharedArrayBufferSupport()\n",
	"hasSymbolSupport": "bool = hasSymbolSupport()\n",
	"hasToStringTagSupport": "bool = hasToStringTagSupport()\n",
	"hasUint16ArraySupport": "bool = hasUint16ArraySupport()\n",
	"hasUint32ArraySupport": "bool = hasUint32ArraySupport()\n",
	"hasUint8ArraySupport": "bool = hasUint8ArraySupport()\n",
	"hasUint8ClampedArraySupport": "bool = hasUint8ClampedArraySupport()\n",
	"hasWeakMapSupport": "bool = hasWeakMapSupport()\n",
	"hasWeakSetSupport": "bool = hasWeakSetSupport()\n",
	"hasWebAssemblySupport": "bool = hasWebAssemblySupport()\n",
	"homedir": "home = homedir()\n",
	"HOURS_IN_DAY": "days = 3.14;\nhrs = days * HOURS_IN_DAY\n",
	"HOURS_IN_WEEK": "wkrs = 3.14;\nhrs = wks * HOURS_IN_WEEK\n",
	"hoursInMonth": "num = hoursInMonth()\nnum = hoursInMonth( 2 )\nnum = hoursInMonth( 2, 2016 )\nnum = hoursInMonth( 2, 2017 )\n\n// Other ways to supply month:\nnum = hoursInMonth( 'feb', 2016 )\nnum = hoursInMonth( 'february', 2016 )\n",
	"hoursInYear": "num = hoursInYear()\nnum = hoursInYear( 2016 )\nnum = hoursInYear( 2017 )\n",
	"httpServer": "\n// Basic usage:\ncreateServer = httpServer()\n\n// Provide a request callback:\nfunction onRequest( request, response ) {\nconsole.log( request.url );\nresponse.end( 'OK' );\n};\ncreateServer = httpServer( onRequest )\n\n// Specify a specific port:\nopts = { 'port': 7331 };\ncreateServer = httpServer( opts )\n",
	"identity": "v = identity( 3.14 )\n",
	"ifelse": "z = ifelse( true, 1.0, -1.0 )\nz = ifelse( false, 1.0, -1.0 )\n",
	"ifelseAsync": "function predicate( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( null, true );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nifelseAsync( predicate, 'beep', 'boop', done )\n",
	"ifthen": "function x() { return 1.0; };\nfunction y() { return -1.0; };\nz = ifthen( true, x, y )\nz = ifthen( false, x, y )\n",
	"ifthenAsync": "function predicate( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( null, false );\n  }\n};\nfunction x( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( null, 'beep' );\n  }\n};\nfunction y( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( null, 'boop' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nifthenAsync( predicate, x, y, done )\n",
	"imag": "z = new Complex128( 5.0, 3.0 );\nim = imag( z )\n",
	"IMG_ACANTHUS_MOLLIS": "img = IMG_ACANTHUS_MOLLIS()\n",
	"IMG_AIRPLANE_FROM_ABOVE": "img = IMG_AIRPLANE_FROM_ABOVE()\n",
	"IMG_ALLIUM_OREOPHILUM": "img = IMG_ALLIUM_OREOPHILUM()\n",
	"IMG_BLACK_CANYON": "img = IMG_BLACK_CANYON()\n",
	"IMG_DUST_BOWL_HOME": "img = IMG_DUST_BOWL_HOME()\n",
	"IMG_FRENCH_ALPINE_LANDSCAPE": "img = IMG_FRENCH_ALPINE_LANDSCAPE()\n",
	"IMG_LOCOMOTION_HOUSE_CAT": "img = IMG_LOCOMOTION_HOUSE_CAT()\n",
	"IMG_LOCOMOTION_NUDE_MALE": "img = IMG_LOCOMOTION_NUDE_MALE()\n",
	"IMG_MARCH_PASTORAL": "img = IMG_MARCH_PASTORAL()\n",
	"IMG_NAGASAKI_BOATS": "img = IMG_NAGASAKI_BOATS()\n",
	"incrspace": "arr = incrspace( 0, 11, 2 )\n",
	"indexOf": "\n// Basic usage:\narr = [ 4, 3, 2, 1 ];\nidx = indexOf( arr, 3 );\narr = [ 4, 3, 2, 1 ];\nidx = indexOf( arr, 5 );\n\n// Using a `fromIndex`:\narr = [ 1, 2, 3, 4, 5, 2, 6 ];\nidx = indexOf( arr, 2, 3 )\n\n// `fromIndex` which exceeds `array` length:\narr = [ 1, 2, 3, 4, 2, 5 ];\nidx = indexOf( arr, 2, 10 )\n\n// Negative `fromIndex`:\narr = [ 1, 2, 3, 4, 5, 2, 6, 2 ];\nidx = indexOf( arr, 2, -4 )\nidx = indexOf( arr, 2, -1 )\n\n// Negative `fromIndex` exceeding input `array` length:\narr = [ 1, 2, 3, 4, 5, 2, 6 ];\nidx = indexOf( arr, 2, -10 )\n\n// Array-like objects:\nstr = 'bebop';\nidx = indexOf( str, 'o' )\n",
	"inherit": "\n// Create a parent constructor:\nfunction Foo() { return this; };\nFoo.prototype.beep = function beep() { return 'boop'; };\n\n// Create a child constructor:\nfunction Bar() { Foo.call( this ); return this; };\n\n// Setup inheritance:\ninherit( Bar, Foo );\nbar = new Bar();\nv = bar.beep()\n",
	"inmap": "function foo( v, i ) { return v * i; };\narr = [ 1.0, 2.0, 3.0 ];\nout = inmap( arr, foo )\nbool = ( out === arr )\n",
	"inmapAsync": "\n// Basic usage:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\narr = [ 3000, 2500, 1000 ];\ninmapAsync( arr, fcn, done )\n\n// Limit number of concurrent invocations:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\ninmapAsync( arr, opts, fcn, done )\n\n// Process sequentially:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\ninmapAsync( arr, opts, fcn, done )\n",
	"inmapRight": "function foo( v, i ) { console.log( '%s: %d', i, v ); return v * i; };\narr = [ 1.0, 2.0, 3.0 ];\nout = inmapRight( arr, foo )\nbool = ( out === arr )\n",
	"inmapRightAsync": "\n// Basic usage:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\narr = [ 1000, 2500, 3000 ];\ninmapRightAsync( arr, fcn, done )\n\n// Limit number of concurrent invocations:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\ninmapRightAsync( arr, opts, fcn, done )\n\n// Process sequentially:\nfunction fcn( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, value*index );\n  }\n};\nfunction done( error, collection ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( collection === arr );\n  console.log( collection );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\ninmapRightAsync( arr, opts, fcn, done )\n",
	"instanceOf": "bool = instanceOf( [], Array )\nbool = instanceOf( {}, Object )\nbool = instanceOf( null, Object )\n",
	"Int16Array": "arr = new Int16Array()\n",
	"INT16_MAX": "INT16_MAX\n",
	"INT16_MIN": "INT16_MIN\n",
	"INT16_NUM_BYTES": "INT16_NUM_BYTES\n",
	"Int32Array": "arr = new Int32Array()\n",
	"INT32_MAX": "INT32_MAX\n",
	"INT32_MIN": "INT32_MIN\n",
	"INT32_NUM_BYTES": "INT32_NUM_BYTES\n",
	"Int8Array": "arr = new Int8Array()\n",
	"INT8_MAX": "INT8_MAX\n",
	"INT8_MIN": "INT8_MIN\n",
	"INT8_NUM_BYTES": "INT8_NUM_BYTES\n",
	"isAbsolutePath": "\n// Windows environment:\nbool = isAbsolutePath( 'C:\\\\foo\\\\bar\\\\baz' )\n\n// POSIX environment:\nbool = isAbsolutePath( '/foo/bar/baz' )\n",
	"isAlphagram": "out = isAlphagram( 'beep' )\nout = isAlphagram( 'zba' )\nout = isAlphagram( '' )\n",
	"isAnagram": "str1 = 'I am a weakish speller';\nstr2 = 'William Shakespeare';\nbool = isAnagram( str1, str2 )\nbool = isAnagram( 'bat', 'tabba' )\n",
	"isArguments": "function foo() { return arguments; };\nbool = isArguments( foo() )\nbool = isArguments( [] )\n",
	"isArray": "bool = isArray( [] )\nbool = isArray( {} )\n",
	"isArrayArray": "bool = isArrayArray( [ [], [] ] )\nbool = isArrayArray( [ {}, {} ] )\nbool = isArrayArray( [] )\n",
	"isArrayBuffer": "bool = isArrayBuffer( new ArrayBuffer( 10 ) )\nbool = isArrayBuffer( [] )\n",
	"isArrayLength": "bool = isArrayLength( 5 )\nbool = isArrayLength( 2.0e200 )\nbool = isArrayLength( -3.14 )\nbool = isArrayLength( null )\n",
	"isArrayLike": "bool = isArrayLike( [] )\nbool = isArrayLike( { 'length': 10 } )\nbool = isArrayLike( 'beep' )\nbool = isArrayLike( null )\n",
	"isArrayLikeObject": "bool = isArrayLikeObject( [] )\nbool = isArrayLikeObject( { 'length': 10 } )\nbool = isArrayLikeObject( 'beep' )\n",
	"isASCII": "str = 'beep boop';\nbool = isASCII( str )\nbool = isASCII( fromCodePoint( 130 ) )\n",
	"isBetween": "bool = isBetween( 3.14, 3.0, 4.0 )\nbool = isBetween( 3.0, 3.0, 4.0 )\nbool = isBetween( 4.0, 3.0, 4.0 )\nbool = isBetween( 3.0, 3.14, 4.0 )\nbool = isBetween( 3.14, 3.14, 4.0, 'open', 'closed' )\nbool = isBetween( 3.14, 3.0, 3.14, 'closed', 'open' )\n",
	"isBetweenArray": "arr = [ 3.0, 3.14, 4.0 ];\nbool = isBetweenArray( arr, 3.0, 4.0 )\nbool = isBetweenArray( arr, 3.14, 4.0 )\nbool = isBetweenArray( arr, 3.0, 3.14 )\nbool = isBetweenArray( arr, 3.0, 4.0, 'open', 'closed' )\nbool = isBetweenArray( arr, 3.0, 4.0, 'closed', 'open' )\n",
	"isBinaryString": "bool = isBinaryString( '1000101' )\nbool = isBinaryString( 'beep' )\nbool = isBinaryString( '' )\n",
	"isBoolean": "bool = isBoolean( false )\nbool = isBoolean( new Boolean( false ) )\n",
	"isBooleanArray": "bool = isBooleanArray( [ true, false, true ] )\nbool = isBooleanArray( [ true, 'abc', false ] )\n",
	"isBuffer": "bool = isBuffer( new Buffer( 'beep' ) )\nbool = isBuffer( new Buffer( [ 1, 2, 3, 4 ] ) )\nbool = isBuffer( {} )\nbool = isBuffer( [] )\n",
	"isCapitalized": "bool = isCapitalized( 'Hello' )\nbool = isCapitalized( 'world' )\n",
	"isCollection": "bool = isCollection( [] )\nbool = isCollection( { 'length': 0 } )\nbool = isCollection( {} )\n",
	"isComplex": "bool = isComplex( Complex64( 2.0, 2.0 ) )\nbool = isComplex( Complex128( 3.0, 1.0 ) )\nbool = isComplex( 3.14 )\nbool = isComplex( {} )\n",
	"isComplex64": "bool = isComplex64( Complex64( 2.0, 2.0 ) )\nbool = isComplex64( Complex128( 3.0, 1.0 ) )\nbool = isComplex64( 3.14 )\nbool = isComplex64( {} )\n",
	"isComplex128": "bool = isComplex128( Complex128( 3.0, 1.0 ) )\nbool = isComplex128( Complex64( 2.0, 2.0 ) )\nbool = isComplex128( 3.14 )\nbool = isComplex128( {} )\n",
	"isDateObject": "bool = isDateObject( new Date() )\nbool = isDateObject( '2017-01-01' )\n",
	"isDigitString": "bool = isDigitString( '0123456789' )\nbool = isDigitString( 'abcdef' )\nbool = isDigitString( '0xff' )\nbool = isDigitString( '' )\n",
	"isEmailAddress": "bool = isEmailAddress( 'beep@boop.com' )\nbool = isEmailAddress( 'beep' )\nbool = isEmailAddress( null )\n",
	"isEmptyArray": "bool = isEmptyArray( [] )\nbool = isEmptyArray( [ 1, 2, 3 ] )\nbool = isEmptyArray( {} )\n",
	"isEmptyObject": "bool = isEmptyObject( {} )\nbool = isEmptyObject( { 'beep': 'boop' } )\nbool = isEmptyObject( [] )\n",
	"isEmptyString": "bool = isEmptyString( '' )\nbool = isEmptyString( new String( '' ) )\nbool = isEmptyString( 'beep' )\nbool = isEmptyString( [] )\n",
	"isEnumerableProperty": "beep = { 'boop': true };\nbool = isEnumerableProperty( beep, 'boop' )\nbool = isEnumerableProperty( beep, 'hasOwnProperty' )\n",
	"isError": "bool = isError( new Error( 'beep' ) )\nbool = isError( {} )\n",
	"isEvalError": "bool = isEvalError( new EvalError( 'beep' ) )\nbool = isEvalError( {} )\n",
	"isEven": "bool = isEven( 4.0 )\nbool = isEven( new Number( 4.0 ) )\nbool = isEven( 3.0 )\nbool = isEven( -3.14 )\nbool = isEven( null )\n",
	"isFalsy": "bool = isFalsy( false )\nbool = isFalsy( '' )\nbool = isFalsy( 0 )\nbool = isFalsy( null )\nbool = isFalsy( void 0 )\nbool = isFalsy( NaN )\nbool = isFalsy( {} )\nbool = isFalsy( [] )\n",
	"isFalsyArray": "bool = isFalsyArray( [ null, '' ] )\nbool = isFalsyArray( [ {}, [] ] )\nbool = isFalsyArray( [] )\n",
	"isFinite": "bool = isFinite( 5.0 )\nbool = isFinite( new Number( 5.0 ) )\nbool = isFinite( 1.0/0.0 )\nbool = isFinite( null )\n",
	"isFiniteArray": "bool = isFiniteArray( [ -3.0, new Number(0.0), 2.0 ] )\nbool = isFiniteArray( [ -3.0, 1.0/0.0 ] )\n",
	"isFloat32Array": "bool = isFloat32Array( new Float32Array( 10 ) )\nbool = isFloat32Array( [] )\n",
	"isFloat64Array": "bool = isFloat64Array( new Float64Array( 10 ) )\nbool = isFloat64Array( [] )\n",
	"isFunction": "function beep() {};\nbool = isFunction( beep )\nbool = isFunction( {} )\n",
	"isFunctionArray": "function beep() {};\nfunction boop() {};\nbool = isFunctionArray( [ beep, boop ] )\nbool = isFunctionArray( [ {}, beep ] )\nbool = isFunctionArray( [] )\n",
	"isHexString": "bool = isHexString( '0123456789abcdefABCDEF' )\nbool = isHexString( '0xffffff' )\nbool = isHexString( 'x' )\nbool = isHexString( '' )\n",
	"isInfinite": "bool = isInfinite( 1.0/0.0 )\nbool = isInfinite( new Number( -1.0/0.0 ) )\nbool = isInfinite( 5.0 )\nbool = isInfinite( '1.0/0.0' )\n",
	"isInt16Array": "bool = isInt16Array( new Int16Array( 10 ) )\nbool = isInt16Array( [] )\n",
	"isInt32Array": "bool = isInt32Array( new Int32Array( 10 ) )\nbool = isInt32Array( [] )\n",
	"isInt8Array": "bool = isInt8Array( new Int8Array( 10 ) )\nbool = isInt8Array( [] )\n",
	"isInteger": "bool = isInteger( 5.0 )\nbool = isInteger( new Number( 5.0 ) )\nbool = isInteger( -3.14 )\nbool = isInteger( null )\n",
	"isIntegerArray": "bool = isIntegerArray( [ -3.0, new Number(0.0), 2.0 ] )\nbool = isIntegerArray( [ -3.0, '3.0' ] )\n",
	"isJSON": "bool = isJSON( '{\"a\":5}' )\nbool = isJSON( '{a\":5}' )\n",
	"isLeapYear": "bool = isLeapYear( new Date() )\nbool = isLeapYear( 1996 )\nbool = isLeapYear( 2001 )\n",
	"isLowercase": "bool = isLowercase( 'hello' )\nbool = isLowercase( 'World' )\n",
	"isnan": "bool = isnan( NaN )\nbool = isnan( new Number( NaN ) )\nbool = isnan( 3.14 )\nbool = isnan( null )\n",
	"isNaNArray": "bool = isNaNArray( [ NaN, NaN, NaN ] )\nbool = isNaNArray( [ NaN, 2 ] )\n",
	"isNativeFunction": "bool = isNativeFunction( Date )\nfunction beep() {};\nbool = isNativeFunction( beep )\nbool = isNativeFunction( {} )\n",
	"isNegativeInteger": "bool = isNegativeInteger( -5.0 )\nbool = isNegativeInteger( new Number( -5.0 ) )\nbool = isNegativeInteger( 5.0 )\nbool = isNegativeInteger( -3.14 )\nbool = isNegativeInteger( null )\n",
	"isNegativeIntegerArray": "bool = isNegativeIntegerArray( [ -3.0, new Number(-3.0) ] )\nbool = isNegativeIntegerArray( [ -3.0, '-3.0' ] )\n",
	"isNegativeNumber": "bool = isNegativeNumber( -5.0 )\nbool = isNegativeNumber( new Number( -5.0 ) )\nbool = isNegativeNumber( -3.14 )\nbool = isNegativeNumber( 5.0 )\nbool = isNegativeNumber( null )\n",
	"isNegativeNumberArray": "bool = isNegativeNumberArray( [ -3.0, new Number(-3.0) ] )\nbool = isNegativeNumberArray( [ -3.0, '-3.0' ] )\n",
	"isNegativeZero": "bool = isNegativeZero( -0.0 )\nbool = isNegativeZero( new Number( -0.0 ) )\nbool = isNegativeZero( -3.14 )\nbool = isNegativeZero( 0.0 )\nbool = isNegativeZero( null )\n",
	"isNodeDuplexStreamLike": "Stream = require( 'stream' ).Duplex;\ns = new Stream();\nbool = isNodeDuplexStreamLike( s )\nbool = isNodeDuplexStreamLike( {} )\n",
	"isNodeReadableStreamLike": "Stream = require( 'stream' ).Readable;\ns = new Stream();\nbool = isNodeReadableStreamLike( s )\nbool = isNodeReadableStreamLike( {} )\n",
	"isNodeREPL": "bool = isNodeREPL()\n",
	"isNodeStreamLike": "Stream = require( 'stream' ).Stream;\ns = new Stream();\nbool = isNodeStreamLike( s )\nbool = isNodeStreamLike( {} )\n",
	"isNodeTransformStreamLike": "Stream = require( 'stream' ).Transform;\ns = new Stream();\nbool = isNodeTransformStreamLike( s )\nbool = isNodeTransformStreamLike( {} )\n",
	"isNodeWritableStreamLike": "Stream = require( 'stream' ).Writable;\ns = new Stream();\nbool = isNodeWritableStreamLike( s )\nbool = isNodeWritableStreamLike( {} )\n",
	"isNonNegativeInteger": "bool = isNonNegativeInteger( 5.0 )\nbool = isNonNegativeInteger( new Number( 5.0 ) )\nbool = isNonNegativeInteger( 3.14 )\nbool = isNonNegativeInteger( -5.0 )\nbool = isNonNegativeInteger( null )\n",
	"isNonNegativeIntegerArray": "bool = isNonNegativeIntegerArray( [ 3.0, new Number(3.0) ] )\nbool = isNonNegativeIntegerArray( [ 3.0, '3.0' ] )\n",
	"isNonNegativeNumber": "bool = isNonNegativeNumber( 5.0 )\nbool = isNonNegativeNumber( new Number( 5.0 ) )\nbool = isNonNegativeNumber( 3.14 )\nbool = isNonNegativeNumber( -5.0 )\nbool = isNonNegativeNumber( null )\n",
	"isNonNegativeNumberArray": "bool = isNonNegativeNumberArray( [ 3.0, new Number(3.0) ] )\nbool = isNonNegativeNumberArray( [ 3.0, '3.0' ] )\n",
	"isNonPositiveInteger": "bool = isNonPositiveInteger( -5.0 )\nbool = isNonPositiveInteger( new Number( -5.0 ) )\nbool = isNonPositiveInteger( 5.0 )\nbool = isNonPositiveInteger( -3.14 )\nbool = isNonPositiveInteger( null )\n",
	"isNonPositiveIntegerArray": "bool = isNonPositiveIntegerArray( [ -3.0, new Number(-3.0) ] )\nbool = isNonPositiveIntegerArray( [ -3.0, '-3.0' ] )\n",
	"isNonPositiveNumber": "bool = isNonPositiveNumber( -5.0 )\nbool = isNonPositiveNumber( new Number( -5.0 ) )\nbool = isNonPositiveNumber( -3.14 )\nbool = isNonPositiveNumber( 5.0 )\nbool = isNonPositiveNumber( null )\n",
	"isNonPositiveNumberArray": "bool = isNonPositiveNumberArray( [ -3.0, new Number(-3.0) ] )\nbool = isNonPositiveNumberArray( [ -3.0, '-3.0' ] )\n",
	"isNull": "bool = isNull( null )\nbool = isNull( true )\n",
	"isNullArray": "bool = isNullArray( [ null, null, null ] )\nbool = isNullArray( [ NaN, 2, null ] )\n",
	"isNumber": "bool = isNumber( 3.14 )\nbool = isNumber( new Number( 3.14 ) )\nbool = isNumber( NaN )\nbool = isNumber( null )\n",
	"isNumberArray": "bool = isNumberArray( [ 1, 2, 3 ] )\nbool = isNumberArray( [ '1', 2, 3 ] )\n",
	"isNumericArray": "bool = isNumericArray( new Int8Array( 10 ) )\nbool = isNumericArray( [ 1, 2, 3 ] )\nbool = isNumericArray( [ '1', '2', '3' ] )\n",
	"isObject": "bool = isObject( {} )\nbool = isObject( true )\n",
	"isObjectArray": "bool = isObjectArray( [ {}, new Number(3.0) ] )\nbool = isObjectArray( [ {}, { 'beep': 'boop' } ] )\nbool = isObjectArray( [ {}, '3.0' ] )\n",
	"isObjectLike": "bool = isObjectLike( {} )\nbool = isObjectLike( [] )\nbool = isObjectLike( null )\n",
	"isOdd": "bool = isOdd( 5.0 )\nbool = isOdd( new Number( 5.0 ) )\nbool = isOdd( 4.0 )\nbool = isOdd( new Number( 4.0 ) )\nbool = isOdd( -3.14 )\nbool = isOdd( null )\n",
	"isoWeeksInYear": "num = isoWeeksInYear()\nnum = isoWeeksInYear( 2015 )\nnum = isoWeeksInYear( 2017 )\n",
	"isPlainObject": "bool = isPlainObject( {} )\nbool = isPlainObject( null )\n",
	"isPlainObjectArray": "bool = isPlainObjectArray( [ {}, { 'beep': 'boop' } ] )\nbool = isPlainObjectArray( [ {}, new Number(3.0) ] )\nbool = isPlainObjectArray( [ {}, '3.0' ] )\n",
	"isPositiveInteger": "bool = isPositiveInteger( 5.0 )\nbool = isPositiveInteger( new Number( 5.0 ) )\nbool = isPositiveInteger( 3.14 )\nbool = isPositiveInteger( -5.0 )\nbool = isPositiveInteger( null )\n",
	"isPositiveIntegerArray": "bool = isPositiveIntegerArray( [ 3.0, new Number(3.0) ] )\nbool = isPositiveIntegerArray( [ 3.0, '3.0' ] )\n",
	"isPositiveNumber": "bool = isPositiveNumber( 5.0 )\nbool = isPositiveNumber( new Number( 5.0 ) )\nbool = isPositiveNumber( 3.14 )\nbool = isPositiveNumber( -5.0 )\nbool = isPositiveNumber( null )\n",
	"isPositiveNumberArray": "bool = isPositiveNumberArray( [ 3.0, new Number(3.0) ] )\nbool = isPositiveNumberArray( [ 3.0, '3.0' ] )\n",
	"isPositiveZero": "bool = isPositiveZero( 0.0 )\nbool = isPositiveZero( new Number( 0.0 ) )\nbool = isPositiveZero( -3.14 )\nbool = isPositiveZero( -0.0 )\nbool = isPositiveZero( null )\n",
	"isPrimitive": "bool = isPrimitive( true )\nbool = isPrimitive( {} )\n",
	"isPrimitiveArray": "bool = isPrimitiveArray( [ '3', 2, null ] )\nbool = isPrimitiveArray( [ {}, 2, 1 ] )\nbool = isPrimitiveArray( [ new String('abc'), '3.0' ] )\n",
	"isProbability": "bool = isProbability( 0.5 )\nbool = isProbability( new Number( 0.5 ) )\nbool = isProbability( 3.14 )\nbool = isProbability( -5.0 )\nbool = isProbability( null )\n",
	"isProbabilityArray": "bool = isProbabilityArray( [ 0.5, new Number(0.8) ] )\nbool = isProbabilityArray( [ 0.8, 1.2 ] )\nbool = isProbabilityArray( [ 0.8, '0.2' ] )\n",
	"isRangeError": "bool = isRangeError( new RangeError( 'beep' ) )\nbool = isRangeError( {} )\n",
	"isReferenceError": "bool = isReferenceError( new ReferenceError( 'beep' ) )\nbool = isReferenceError( {} )\n",
	"isRegExp": "bool = isRegExp( /\\.+/ )\nbool = isRegExp( {} )\n",
	"isRegExpString": "bool = isRegExpString( '/beep/' )\nbool = isRegExpString( 'beep' )\nbool = isRegExpString( '' )\nbool = isRegExpString( null )\n",
	"isRelativePath": "\n// Windows environments:\nbool = isRelativePath( 'foo\\\\bar\\\\baz' )\n\n// POSIX environments:\nbool = isRelativePath( './foo/bar/baz' )\n",
	"isSafeInteger": "bool = isSafeInteger( 5.0 )\nbool = isSafeInteger( new Number( 5.0 ) )\nbool = isSafeInteger( 2.0e200 )\nbool = isSafeInteger( -3.14 )\nbool = isSafeInteger( null )\n",
	"isSafeIntegerArray": "arr = [ -3.0, new Number(0.0), 2.0 ];\nbool = isSafeIntegerArray( arr )\narr = [ -3.0, '3.0' ];\nbool = isSafeIntegerArray( arr )\n",
	"isSameValue": "bool = isSameValue( true, true )\nbool = isSameValue( {}, {} )\nbool = isSameValue( -0.0, -0.0 )\nbool = isSameValue( -0.0, 0.0 )\nbool = isSameValue( NaN, NaN )\n",
	"isSharedArrayBuffer": "\n// Assuming an environment supports SharedArrayBuffer...\nbool = isSharedArrayBuffer( new SharedArrayBuffer( 10 ) )\nbool = isSharedArrayBuffer( [] )\n",
	"isStrictEqual": "bool = isStrictEqual( true, true )\nbool = isStrictEqual( {}, {} )\nbool = isStrictEqual( -0.0, -0.0 )\nbool = isStrictEqual( -0.0, 0.0 )\nbool = isStrictEqual( NaN, NaN )\n",
	"isString": "bool = isString( 'beep' )\nbool = isString( new String( 'beep' ) )\nbool = isString( 5 )\n",
	"isStringArray": "bool = isStringArray( [ 'abc', 'def' ] )\nbool = isStringArray( [ 'abc', 123 ] )\n",
	"isSymbol": "bool = isSymbol( Symbol( 'beep' ) )\nbool = isSymbol( Object( Symbol( 'beep' ) ) )\nbool = isSymbol( {} )\nbool = isSymbol( null )\nbool = isSymbol( true )\n",
	"isSymbolArray": "bool = isSymbolArray( [ Symbol( 'beep' ), Symbol( 'boop' ) ] )\nbool = isSymbolArray( Symbol( 'beep' ) )\nbool = isSymbolArray( [] )\nbool = isSymbolArray( {} )\nbool = isSymbolArray( null )\nbool = isSymbolArray( true )\n",
	"isSyntaxError": "bool = isSyntaxError( new SyntaxError( 'beep' ) )\nbool = isSyntaxError( {} )\n",
	"isTruthy": "bool = isTruthy( {} )\nbool = isTruthy( [] )\nbool = isTruthy( false )\nbool = isTruthy( '' )\nbool = isTruthy( 0 )\nbool = isTruthy( null )\nbool = isTruthy( void 0 )\nbool = isTruthy( NaN )\n",
	"isTruthyArray": "bool = isTruthyArray( [ {}, [] ] )\nbool = isTruthyArray( [ null, '' ] )\nbool = isTruthyArray( [] )\n",
	"isTypeError": "bool = isTypeError( new TypeError( 'beep' ) )\nbool = isTypeError( {} )\n",
	"isTypedArray": "bool = isTypedArray( new Int8Array( 10 ) );\n",
	"isTypedArrayLength": "bool = isTypedArrayLength( 5 )\nbool = isTypedArrayLength( 2.0e200 )\nbool = isTypedArrayLength( -3.14 )\nbool = isTypedArrayLength( null )\n",
	"isTypedArrayLike": "bool = isTypedArrayLike( new Int16Array() )\nbool = isTypedArrayLike({\n'length': 10,\n'byteOffset': 0,\n'byteLength': 10,\n'BYTES_PER_ELEMENT': 4\n})\n",
	"isUint16Array": "bool = isUint16Array( new Uint16Array( 10 ) )\nbool = isUint16Array( [] )\n",
	"isUint32Array": "bool = isUint32Array( new Uint32Array( 10 ) )\nbool = isUint32Array( [] )\n",
	"isUint8Array": "bool = isUint8Array( new Uint8Array( 10 ) )\nbool = isUint8Array( [] )\n",
	"isUint8ClampedArray": "bool = isUint8ClampedArray( new Uint8ClampedArray( 10 ) )\nbool = isUint8ClampedArray( [] )\n",
	"isUNCPath": "bool = isUNCPath( '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz' )\nbool = isUNCPath( '/foo/bar/baz' )\n",
	"isUndefined": "bool = isUndefined( void 0 )\nbool = isUndefined( null )\n",
	"isUndefinedOrNull": "bool = isUndefinedOrNull( void 0 )\nbool = isUndefinedOrNull( null )\nbool = isUndefinedOrNull( false )\n",
	"isUnityProbabilityArray": "bool = isUnityProbabilityArray( [ 0.25, 0.5, 0.25 ] )\nbool = isUnityProbabilityArray( Uint8Array( [ 0, 1 ] )\nbool = isUnityProbabilityArray( [ 0.4, 0.4, 0.4 ] )\nbool = isUnityProbabilityArray( [ 3.14, 0.0 ] )\n",
	"isUppercase": "bool = isUppercase( 'HELLO' )\nbool = isUppercase( 'World' )\n",
	"isURI": "bool = isURI( 'http://google.com' )\nbool = isURI( 'http://localhost/' )\nbool = isURI( 'http://example.w3.org/path%20with%20spaces.html' )\nbool = isURI( 'ftp://ftp.is.co.za/rfc/rfc1808.txt' )\n\n// No scheme:\nbool = isURI( '' )\nbool = isURI( 'foo@bar' )\nbool = isURI( '://foo/' )\n\n// Illegal characters:\nbool = isURI( 'http://<foo>' )\n\n// Invalid path:\nbool = isURI( 'http:////foo.html' )\n\n// Incomplete hex escapes:\nbool = isURI( 'http://example.w3.org/%a' )\n",
	"isURIError": "bool = isURIError( new URIError( 'beep' ) )\nbool = isURIError( {} )\n",
	"isWhitespace": "bool = isWhitespace( '       ' )\nbool = isWhitespace( 'abcdef' )\nbool = isWhitespace( '' )\n",
	"IS_BROWSER": "IS_BROWSER\n",
	"IS_DARWIN": "IS_DARWIN\n",
	"IS_ELECTRON": "IS_ELECTRON\n",
	"IS_ELECTRON_MAIN": "IS_ELECTRON_MAIN\n",
	"IS_ELECTRON_RENDERER": "IS_ELECTRON_RENDERER\n",
	"IS_LITTLE_ENDIAN": "IS_LITTLE_ENDIAN\n",
	"IS_NODE": "IS_NODE\n",
	"IS_WEB_WORKER": "IS_WEB_WORKER\n",
	"IS_WINDOWS": "IS_WINDOWS\n",
	"keysIn": "function Foo() { this.beep = 'boop'; return this; };\nFoo.prototype.foo = 'bar';\nobj = new Foo();\nkeys = keysIn( obj )\n",
	"keyBy": "function toKey( v ) { return v.a; };\narr = [ { 'a': 1 }, { 'a': 2 } ];\nkeyBy( arr, toKey )\n",
	"keyByRight": "function toKey( v ) { return v.a; };\narr = [ { 'a': 1 }, { 'a': 2 } ];\nkeyByRight( arr, toKey )\n",
	"kstest": "\n// Verify that data is drawn from a normal distribution:\nrnorm = base.random.normal.factory({ 'seed': 4839 });\nx = new Array( 100 );\nfor ( var i = 0; i < 100; i++ ) { x[ i ] = rnorm( 3.0, 1.0 ); }\n\n// Test against N(0,1)\nout = kstest( x, 'normal', 0.0, 1.0 );\n\n// Test against N(3,1)\nout = kstest( x, 'normal', 3.0, 1.0 )\n\n// Verify that data is drawn from a uniform distribution:\nrunif = base.random.uniform.factory( 0.0, 1.0, { 'seed': 8798 })\nx = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) { x[ i ] = runif(); }\nout = kstest( x, 'uniform', 0.0, 1.0 )\n\n// Print output:\nout.print()\n\n// Set custom significance level:\nout = kstest( x, 'uniform', 0.0, 1.0, { 'alpha': 0.1 })\n\n// Carry out one-sided hypothesis tests:\nrunif = base.random.uniform.factory( 0.0, 1.0, { 'seed': 8798 });\nx = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) { x[ i ] = runif(); }\nout = kstest( x, 'uniform', 0.0, 1.0, { 'alternative': 'less' });\nout = kstest( x, 'uniform', 0.0, 1.0, { 'alternative': 'greater' });\n\n// Set `sorted` option to true when data is in increasing order:\n",
	"linspace": "arr = linspace( 0, 100, 6 )\n",
	"LIU_NEGATIVE_OPINION_WORDS_EN": "list = LIU_NEGATIVE_OPINION_WORDS_EN()\n",
	"LIU_POSITIVE_OPINION_WORDS_EN": "list = LIU_POSITIVE_OPINION_WORDS_EN()\n",
	"LN_HALF": "LN_HALF\n",
	"LN_PI": "LN_PI\n",
	"LN_SQRT_TWO_PI": "LN_SQRT_TWO_PI\n",
	"LN_TWO_PI": "LN_TWO_PI\n",
	"LN10": "LN10\n",
	"LN2": "LN2\n",
	"logspace": "arr = logspace( 0, 2, 6 )\n",
	"LOG10E": "LOG10E\n",
	"LOG2E": "LOG2E\n",
	"lowercase": "out = lowercase( 'bEEp' )\n",
	"lowercaseKeys": "obj = { 'A': 1, 'B': 2 };\nout = lowercaseKeys( obj )\n",
	"lpad": "out = lpad( 'a', 5 )\nout = lpad( 'beep', 10, 'b' )\nout = lpad( 'boop', 12, 'beep' )\n",
	"ltrim": "out = ltrim( ' \\r\\n\\t  Beep \\t\\t\\n  ' )\n",
	"MALE_FIRST_NAMES_EN": "list = MALE_FIRST_NAMES_EN()\n",
	"mapFun": "function fcn( i ) { return i; };\narr = mapFun( fcn, 5 )\n",
	"mapFunAsync": "\n// Basic usage:\nfunction fcn( i, next ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      next( null, i );\n  }\n};\nfunction done( error, arr ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( arr );\n};\nmapFunAsync( fcn, 10, done )\n\n// Limit number of concurrent invocations:\nfunction fcn( i, next ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      next( null, i );\n  }\n};\nfunction done( error, arr ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( arr );\n};\nopts = { 'limit': 2 };\nmapFunAsync( fcn, 10, opts, done )\n\n// Sequential invocation:\nfunction fcn( i, next ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      next( null, i );\n  }\n};\nfunction done( error, arr ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( arr );\n};\nopts = { 'series': true };\nmapFunAsync( fcn, 10, opts, done )\n",
	"mapKeys": "function transform( key, value ) { return key + value; };\nobj = { 'a': 1, 'b': 2 };\nout = mapKeys( obj, transform )\n",
	"mapKeysAsync": "\n// Basic usage:\nfunction transform( key, value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nobj = { 'a': 1, 'b': 2 };\nmapKeysAsync( obj, transform, done )\n\n// Limit number of concurrent invocations:\nfunction transform( key, value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nopts = { 'limit': 2 };\nobj = { 'a': 1, 'b': 2, 'c': 3 };\nmapKeysAsync( obj, opts, transform, done )\n\n// Process sequentially:\nfunction transform( key, value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nopts = { 'series': true };\nobj = { 'a': 1, 'b': 2, 'c': 3 };\nmapKeysAsync( obj, opts, transform, done )\n",
	"mapValues": "function transform( value, key ) { return key + value; };\nobj = { 'a': 1, 'b': 2 };\nout = mapValues( obj, transform )\n",
	"mapValuesAsync": "\n// Basic usage:\nfunction transform( value, key, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nobj = { 'a': 1, 'b': 2 };\nmapValuesAsync( obj, transform, done )\n\n// Limit number of concurrent invocations:\nfunction transform( value, key, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nopts = { 'limit': 2 };\nobj = { 'a': 1, 'b': 2, 'c': 3 };\nmapValuesAsync( obj, opts, transform, done )\n\n// Process sequentially:\nfunction transform( value, key, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      next( null, key+':'+value );\n  }\n};\nfunction done( error, out ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( out );\n};\nopts = { 'series': true };\nobj = { 'a': 1, 'b': 2, 'c': 3 };\nmapValuesAsync( obj, opts, transform, done )\n",
	"MAX_ARRAY_LENGTH": "MAX_ARRAY_LENGTH\n",
	"MAX_TYPED_ARRAY_LENGTH": "MAX_TYPED_ARRAY_LENGTH\n",
	"memoize": "function factorial( n ) {\n  var prod;\n  var i;\n  prod = 1;\n  for ( i = n; i > 1; i-- ) {\n      prod *= i;\n  }\n  return prod;\n};\nmemoized = memoize( factorial );\nv = memoized( 5 )\nv = memoized( 5 )\n",
	"merge": "target = { 'a': 'beep' };\nsource = { 'a': 'boop', 'b': 'bap' };\nout = merge( target, source )\nbool = ( out === target )\n",
	"MILLISECONDS_IN_DAY": "days = 3.14;\nms = days * MILLISECONDS_IN_DAY\n",
	"MILLISECONDS_IN_HOUR": "hrs = 3.14;\nms = hrs * MILLISECONDS_IN_HOUR\n",
	"MILLISECONDS_IN_MINUTE": "mins = 3.14;\nms = mins * MILLISECONDS_IN_MINUTE\n",
	"MILLISECONDS_IN_SECOND": "secs = 3.14;\nms = secs * MILLISECONDS_IN_SECOND\n",
	"MILLISECONDS_IN_WEEK": "weeks = 3.14;\nms = weeks * MILLISECONDS_IN_WEEK\n",
	"MINARD_NAPOLEONS_MARCH": "data = MINARD_NAPOLEONS_MARCH();\narmy = data.army\ncities = data.cities\nlabels = data.labels\nriver = data.river\nt = data.temperature\n",
	"MINUTES_IN_DAY": "days = 3.14;\nmins = days * MINUTES_IN_DAY\n",
	"MINUTES_IN_HOUR": "hrs = 3.14;\nmins = hrs * MINUTES_IN_HOUR\n",
	"MINUTES_IN_WEEK": "wks = 3.14;\nmins = wks * MINUTES_IN_WEEK\n",
	"minutesInMonth": "num = minutesInMonth()\nnum = minutesInMonth( 2 )\nnum = minutesInMonth( 2, 2016 )\nnum = minutesInMonth( 2, 2017 )\n\n// Other ways to supply month:\nnum = minutesInMonth( 'feb', 2016 )\nnum = minutesInMonth( 'february', 2016 )\n",
	"minutesInYear": "num = minutesInYear()\nnum = minutesInYear( 2016 )\nnum = minutesInYear( 2017 )\n",
	"MOBY_DICK": "data = MOBY_DICK()\n",
	"MONTHS_IN_YEAR": "yrs = 3.14;\nmons = yrs * MONTHS_IN_YEAR\n",
	"MONTH_NAMES_EN": "list = MONTH_NAMES_EN()\n",
	"moveProperty": "obj1 = { 'a': 'b' };\nobj2 = {};\nbool = moveProperty( obj1, 'a', obj2 )\nbool = moveProperty( obj1, 'c', obj2 )\n",
	"nativeClass": "str = nativeClass( 'a' )\nstr = nativeClass( 5 )\nfunction Beep(){};\nstr = nativeClass( new Beep() )\n",
	"NIGHTINGALES_ROSE": "data = NIGHTINGALES_ROSE()\n",
	"NINF": "NINF\n",
	"NODE_VERSION": "NODE_VERSION\n",
	"none": "arr = [ 0, 0, 0, 0, 0 ];\nbool = none( arr )\n",
	"noneBy": "function negative( v ) { return ( v < 0 ); };\narr = [ 1, 2, 3, 4 ];\nbool = noneBy( arr, negative )\n",
	"noneByAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 3000, 2500, 1000 ];\nnoneByAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nnoneByAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\nnoneByAsync( arr, opts, predicate, done )\n",
	"noneByRight": "function positive( v ) { return ( v > 0 ); };\narr = [ -1, -2, -3, -4 ];\nbool = noneByRight( arr, positive )\n",
	"noneByRightAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 1000, 2500, 3000 ];\nnoneByRightAsync( arr, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\nnoneByRightAsync( arr, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\nnoneByRightAsync( arr, opts, predicate, done )\n",
	"noop": "noop();\n",
	"now": "ts = now()\n",
	"Number": "v = new Number( 5 )\n",
	"NUM_CPUS": "NUM_CPUS\n",
	"objectEntries": "obj = { 'beep': 'boop', 'foo': 'bar' };\nentries = objectEntries( obj )\n",
	"objectEntriesIn": "function Foo() { this.beep = 'boop'; return this; };\nFoo.prototype.foo = 'bar';\nobj = new Foo();\nentries = objectEntriesIn( obj )\n",
	"objectFromEntries": "entries = [ [ 'beep', 'boop' ], [ 'foo', 'bar' ] ];\nobj = objectFromEntries( entries )\n",
	"objectInverse": "\n// Basic usage:\nobj = { 'a': 'beep', 'b': 'boop' };\nout = objectInverse( obj )\n\n// Duplicate values:\nobj = { 'a': 'beep', 'b': 'beep' };\nout = objectInverse( obj )\n\n// Override duplicate values:\nobj = {};\nobj.a = 'beep';\nobj.b = 'boop';\nobj.c = 'beep';\nout = objectInverse( obj, { 'duplicates': false } )\n",
	"objectInverseBy": "\n// Basic usage:\nfunction transform( key, value ) { return key + value; };\nobj = { 'a': 'beep', 'b': 'boop' };\nout = objectInverseBy( obj, transform )\n\n// Duplicate values:\nfunction transform( key, value ) { return value; };\nobj = { 'a': 'beep', 'b': 'beep' };\nout = objectInverseBy( obj, transform )\n\n// Override duplicate values:\nobj = {};\nobj.a = 'beep';\nobj.b = 'boop';\nobj.c = 'beep';\nout = objectInverseBy( obj, { 'duplicates': false }, transform )\n",
	"objectValues": "obj = { 'beep': 'boop', 'foo': 'bar' };\nvals = objectValues( obj )\n",
	"objectValuesIn": "function Foo() { this.beep = 'boop'; return this; };\nFoo.prototype.foo = 'bar';\nobj = new Foo();\nvalues = objectValuesIn( obj )\n",
	"omit": "obj1 = { 'a': 1, 'b': 2 };\nobj2 = omit( obj1, 'b' )\n",
	"omitBy": "function predicate( key, value ) { return ( value > 1 ); };\nobj1 = { 'a': 1, 'b': 2 };\nobj2 = omitBy( obj1, predicate )\n",
	"openURL": "out = openURL( 'https://google.com' );\n",
	"pad": "\n// Standard usage:\nout = pad( 'a', 5 )\n\n// Left pad:\nout = pad( 'a', 10, { 'lpad': 'b' })\n\n// Right pad:\nout = pad( 'a', 12, { 'rpad': 'b' })\n\n// Center an input string:\nopts = { 'lpad': 'a', 'rpad': 'c' };\nout = pad( 'b', 11, opts )\n\n// Left center:\nopts.centerRight = false;\nout = pad( 'b', 10, opts )\n\n// Right center:\nopts.centerRight = true;\nout = pad( 'b', 10, opts )\n\n// Output string always length `len`:\nopts = { 'lpad': 'boop', 'rpad': 'woot' };\nout = pad( 'beep', 10, opts )\n\n// Pad right, trim right:\nout = pad( 'beep', 2 )\n\n// Pad left, trim left:\nopts = { 'lpad': 'b' };\nout = pad( 'beep', 2, opts )\n\n// Pad both, trim both:\nopts = { 'lpad': '@', 'rpad': '!' };\nout = pad( 'beep', 2, opts )\n\n// Pad both, trim both starting from left:\nout = pad( 'abcdef', 3, opts )\n\n// Pad both, trim both starting from right:\nopts.centerRight = true;\nout = pad( 'abcdef', 3, opts )\n",
	"papply": "function add( x, y ) { return x + y; };\nadd2 = papply( add, 2 );\nsum = add2( 3 )\n",
	"papplyRight": "function say( text, name ) { return text + ', ' + name + '.'; };\ntoGrace = papplyRight( say, 'Grace Hopper' );\nstr = toGrace( 'Hello' )\nstr = toGrace( 'Thank you' )\n",
	"parallel": "function done( error ) { if ( error ) { throw error; } };\nfiles = [ './a.js', './b.js' ];\nparallel( files, done );\n\n// Specify the number of workers:\nopts = { 'workers': 8 };\nparallel( files, opts, done );\n",
	"parseJSON": "obj = parseJSON( '{\"beep\":\"boop\"}' )\n\n// Provide a reviver:\nfunction reviver( key, value ) {\n  if ( key === '' ) { return value; }\n  if ( key === 'beep' ) { return value; }\n};\nstr = '{\"beep\":\"boop\",\"a\":\"b\"}';\nout = parseJSON( str, reviver )\n",
	"PATH_DELIMITER": "PATH_DELIMITER\n\n// POSIX environment:\npath = '/usr/bin:/bin:/usr/sbin';\nparts = path.split( PATH_DELIMITER )\n\n// Windows environment:\npath = 'C:\\\\Windows\\\\system32;C:\\\\Windows';\nparts = path.split( PATH_DELIMITER )\n",
	"PATH_DELIMITER_POSIX": "PATH_DELIMITER_POSIX\nPATH = '/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin';\npaths = PATH.split( PATH_DELIMITER_POSIX )\n",
	"PATH_DELIMITER_WIN32": "PATH_DELIMITER_WIN32\nPATH = 'C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Program Files\\\\node\\\\';\npaths = PATH.split( PATH_DELIMITER_WIN32 )\n",
	"PATH_SEP": "PATH_SEP\n\n// Windows environment:\nparts = 'foo\\\\bar\\\\baz'.split( PATH_SEP )\n\n// POSIX environment:\nparts = 'foo/bar/baz'.split( PATH_SEP )\n",
	"PATH_SEP_POSIX": "PATH_SEP_POSIX\nparts = 'foo/bar/baz'.split( PATH_SEP_POSIX )\n",
	"PATH_SEP_WIN32": "PATH_SEP_WIN32\nparts = 'foo\\\\bar\\\\baz'.split( PATH_SEP_WIN32 )\n",
	"pcorrtest": "rho = 0.5;\nx = new Array( 300 );\ny = new Array( 300 );\nfor ( var i = 0; i < 300; i++ ) {\n   x[ i ] = base.random.normal( 0.0, 1.0 );\n   y[ i ] = ( rho * x[ i ] ) + base.random.normal( 0.0, base.sqrt( 1.0 - (rho*rho) ) );\n}\nout = pcorrtest( x, y )\n\n// Print output:\ntable = out.print()\n",
	"percentEncode": "out = percentEncode( '☃' )\n",
	"PHI": "PHI\n",
	"PI": "PI\n",
	"PI_SQUARED": "PI_SQUARED\n",
	"pick": "obj1 = { 'a': 1, 'b': 2 };\nobj2 = pick( obj1, 'b' )\n",
	"pickBy": "function predicate( key, value ) {\n  return ( value > 1 );\n};\nobj1 = { 'a': 1, 'b': 2 };\nobj2 = pickBy( obj1, predicate )\n",
	"PINF": "PINF\n",
	"PLATFORM": "PLATFORM\n",
	"plot": "plot = plot()\n\n// Provide plot data at instantiation:\nx = [[0.10, 0.20, 0.30]];\ny = [[0.52, 0.79, 0.64]];\nplot = plot( x, y )\n",
	"Plot": "plot = Plot()\n\n// Provide plot data at instantiation:\nx = [[0.10, 0.20, 0.30]];\ny = [[0.52, 0.79, 0.64]];\nplot = Plot( x, y )\n",
	"pluck": "arr = [\n  { 'a': 1, 'b': 2 },\n  { 'a': 0.5, 'b': 3 }\n];\nout = pluck( arr, 'a' )\narr = [\n  { 'a': 1, 'b': 2 },\n  { 'a': 0.5, 'b': 3 }\n];\nout = pluck( arr, 'a', { 'copy': false } )\nbool = ( arr[ 0 ] === out[ 0 ] )\n",
	"pop": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\nout = pop( arr )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\nout = pop( arr )\n\n// Array-like object:\narr = { 'length': 2, '0': 1.0, '1': 2.0 };\nout = pop( arr )\n",
	"prepend": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\narr = prepend( arr, [ 6.0, 7.0 ] )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\narr = prepend( arr, [ 3.0, 4.0 ] )\n\n// Array-like object:\narr = { 'length': 1, '0': 1.0 };\narr = prepend( arr, [ 2.0, 3.0 ] )\n",
	"push": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\narr = push( arr, 6.0, 7.0 )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\narr = push( arr, 3.0, 4.0 )\n\n// Array-like object:\narr = { 'length': 0 };\narr = push( arr, 1.0, 2.0 )\n",
	"quarterOfYear": "q = quarterOfYear( new Date() )\nq = quarterOfYear( 4 )\nq = quarterOfYear( 'June' )\n\n// Other ways to supply month:\nq = quarterOfYear( 'April' )\nq = quarterOfYear( 'apr' )\n",
	"readDir": "function onRead( error, data ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( data );\n  }\n};\nreadDir( './beep/boop', onRead );\n",
	"readFile": "function onRead( error, data ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( data );\n  }\n};\nreadFile( './beep/boop.js', onRead );\n",
	"readFileList": "function onRead( error, data ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( data );\n  }\n};\nfilepaths = [ './beep/boop.txt', './foo/bar.txt' ];\nreadFileList( filepaths, onRead );\n",
	"readJSON": "function onRead( error, data ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( data );\n  }\n};\nreadJSON( './beep/boop.json', onRead );\n",
	"readWASM": "function onRead( error, data ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( data );\n  }\n};\nreadWASM( './beep/boop.wasm', onRead );\n",
	"real": "z = new Complex128( 5.0, 3.0 );\nre = real( z )\n",
	"realmax": "m = realmax( 'float16' )\nm = realmax( 'float32' )\n",
	"realmin": "m = realmin( 'float16' )\nm = realmin( 'float32' )\n",
	"reduce": "function sum( acc, v ) { return acc + v; };\narr = [ 1.0, 2.0, 3.0 ];\nout = reduce( arr, 0, sum )\n",
	"reduceAsync": "\n// Basic usage:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\narr = [ 3000, 2500, 1000 ];\nacc = { 'sum': 0 };\nreduceAsync( arr, acc, fcn, done )\n\n// Limit number of concurrent invocations:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nacc = { 'sum': 0 };\nreduceAsync( arr, acc, opts, fcn, done )\n\n// Process concurrently:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\nopts = { 'series': false };\narr = [ 3000, 2500, 1000 ];\nacc = { 'sum': 0 };\nreduceAsync( arr, acc, opts, fcn, done )\n",
	"reduceRight": "function sum( acc, v ) { console.log( '%s: %d', i, v ); return acc + v; };\narr = [ 1.0, 2.0, 3.0 ];\nout = reduceRight( arr, 0, sum )\n",
	"reduceRightAsync": "\n// Basic usage:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\narr = [ 1000, 2500, 3000 ];\nacc = { 'sum': 0 };\nreduceRightAsync( arr, acc, fcn, done )\n\n// Limit number of concurrent invocations:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\nacc = { 'sum': 0 };\nreduceRightAsync( arr, acc, opts, fcn, done )\n\n// Process concurrently:\nfunction fcn( acc, value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      acc.sum += value;\n      next( null, acc );\n  }\n};\nfunction done( error, acc ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( acc.sum );\n};\nopts = { 'series': false };\narr = [ 1000, 2500, 3000 ];\nacc = { 'sum': 0 };\nreduceRightAsync( arr, acc, opts, fcn, done )\n",
	"reFromString": "re = reFromString( '/beep/' )\nre = reFromString( '/beep' )\n",
	"reim": "z = new Complex128( 5.0, 3.0 );\nout = reim( z )\n",
	"removeFirst": "out = removeFirst( 'beep' )\nout = removeFirst( 'Boop' )\n",
	"removeLast": "out = removeLast( 'beep' )\nout = removeLast( 'Boop' )\n",
	"removePunctuation": "str = 'Sun Tzu said: \"A leader leads by example not by force.\"';\nout = {{alias }}( str )\nstr = 'This function removes these characters: `{}[]:,!/<>().;~|?\\'\"';\nout = removePunctuation( str )\n",
	"removeUTF8BOM": "out = removeUTF8BOM( '\\ufeffbeep' )\n",
	"removeWords": "out = removeWords( 'beep boop Foo bar', [ 'boop', 'foo' ] )\n\n// Case-insensitive:\nout = removeWords( 'beep boop Foo bar', [ 'boop', 'foo' ], true )\n",
	"reorderArguments": "function foo( a, b, c ) { return [ a, b, c ]; };\nbar = reorderArguments( foo, [ 2, 0, 1 ] );\nout = bar( 1, 2, 3 )\n",
	"repeat": "out = repeat( 'a', 5 )\nout = repeat( '', 100 )\nout = repeat( 'beep', 0 )\n",
	"replace": "\n// Standard usage:\nout = replace( 'beep', 'e', 'o' )\n\n// Replacer function:\nfunction replacer( match, p1 ) { return '/'+p1+'/'; };\nstr = 'Oranges and lemons';\nout = replace( str, /([^\\s]+)/gi, replacer )\n\n// Replace only first match:\nout = replace( 'beep', /e/, 'o' )\n",
	"rescape": "str = rescape( '[A-Z]*' )\n",
	"resolveParentPath": "function onPath( error, path ) {\n  if ( error ) {\n      console.error( error.message );\n  } else {\n      console.log( path );\n  }\n};\nresolveParentPath( 'package.json', onPath );\n",
	"reverseArguments": "function foo( a, b, c ) { return [ a, b, c ]; };\nbar = reverseArguments( foo );\nout = bar( 1, 2, 3 )\n",
	"reverseString": "out = reverseString( 'foo' )\nout = reverseString( 'abcdef' )\n",
	"reviveBuffer": "str = '{\"type\":\"Buffer\",\"data\":[5,3]}';\nbuf = parseJSON( str, reviveBuffer )\n",
	"reviveComplex": "str = '{\"type\":\"Complex128\",\"re\":5,\"im\":3}';\nz = parseJSON( str, reviveComplex )\n",
	"reviveComplex128": "str = '{\"type\":\"Complex128\",\"re\":5,\"im\":3}';\nz = parseJSON( str, reviveComplex128 )\n",
	"reviveComplex64": "str = '{\"type\":\"Complex64\",\"re\":5,\"im\":3}';\nz = parseJSON( str, reviveComplex64 )\n",
	"reviveError": "str = '{\"type\":\"TypeError\",\"message\":\"beep\"}';\nerr = JSON.parse( str, reviveError )\n",
	"reviveTypedArray": "str = '{\"type\":\"Float64Array\",\"data\":[5,3]}';\narr = parseJSON( str, reviveTypedArray )\n",
	"RE_BASENAME": "base = RE_BASENAME.exec( '/foo/bar/index.js' )[ 1 ]\n",
	"RE_BASENAME_POSIX": "base = RE_BASENAME_POSIX.exec( '/foo/bar/index.js' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( './foo/bar/.gitignore' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( 'foo/file.pdf' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( '/foo/bar/file' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( 'index.js' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( '.' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( './' )[ 1 ]\nbase = RE_BASENAME_POSIX.exec( '' )[ 1 ]\n",
	"RE_BASENAME_WINDOWS": "base = RE_BASENAME_WINDOWS.exec( '\\\\foo\\\\bar\\\\index.js' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( 'C:\\\\foo\\\\bar\\\\.gitignore' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( 'foo\\\\file.pdf' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( 'foo\\\\bar\\\\file' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( 'index.js' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( '.' )[ 1 ]\nbase = RE_BASENAME_WINDOWS.exec( '' )[ 1 ]\n",
	"RE_COLOR_HEXADECIMAL": "bool = RE_COLOR_HEXADECIMAL.test( 'ffffff' )\nbool = RE_COLOR_HEXADECIMAL.test( '000' )\nbool = RE_COLOR_HEXADECIMAL.test( 'beep' )\n",
	"RE_DECIMAL_NUMBER": "bool = RE_DECIMAL_NUMBER.test( '1.234' )\nbool = RE_DECIMAL_NUMBER.test( '-1.234' )\nbool = RE_DECIMAL_NUMBER.test( '0.0' )\nbool = RE_DECIMAL_NUMBER.test( '.0' )\nbool = RE_DECIMAL_NUMBER.test( '0' )\nbool = RE_DECIMAL_NUMBER.test( 'beep' )\n\n// Create a RegExp to capture all decimal numbers:\nre = new RegExp( RE_DECIMAL_NUMBER.source, 'g' );\nstr = '1.234 5.6, 7.8';\nout = str.match( re );\n",
	"RE_DIRNAME": "dir = RE_DIRNAME.exec( '/foo/bar/index.js' )[ 1 ]\n",
	"RE_DIRNAME_POSIX": "dir = RE_DIRNAME_POSIX.exec( '/foo/bar/index.js' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( './foo/bar/.gitignore' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( 'foo/file.pdf' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( '/foo/bar/file' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( 'index.js' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( '.' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( './' )[ 1 ]\ndir = RE_DIRNAME_POSIX.exec( '' )[ 1 ]\n",
	"RE_DIRNAME_WINDOWS": "dir = RE_DIRNAME_WINDOWS.exec( 'foo\\\\bar\\\\index.js' )[ 1 ]\ndir = RE_DIRNAME_WINDOWS.exec( 'C:\\\\foo\\\\bar\\\\.gitignore' )[ 1 ]\ndir = RE_DIRNAME_WINDOWS.exec( 'foo\\\\file.pdf' )[ 1 ]\ndir = RE_DIRNAME_WINDOWS.exec( '\\\\foo\\\\bar\\\\file' )[ 1 ]\ndir = RE_DIRNAME_WINDOWS.exec( 'index.js' )[ 1 ]\ndir = RE_DIRNAME_WINDOWS.exec( '' )[ 1 ]\n",
	"RE_EOL": "bool = RE_EOL.test( '\\n' )\nbool = RE_EOL.test( '\\r\\n' )\nbool = RE_EOL.test( '\\\\r\\\\n' )\n",
	"RE_EXTENDED_LENGTH_PATH": "path = '\\\\\\\\?\\\\C:\\\\foo\\\\bar';\nbool = RE_EXTENDED_LENGTH_PATH.test( path )\npath = '\\\\\\\\?\\\\UNC\\\\server\\\\share';\nbool = RE_EXTENDED_LENGTH_PATH.test( path )\npath = 'C:\\\\foo\\\\bar';\nbool = RE_EXTENDED_LENGTH_PATH.test( path )\npath = '/c/foo/bar';\nbool = RE_EXTENDED_LENGTH_PATH.test( path )\npath = '/foo/bar';\nbool = RE_EXTENDED_LENGTH_PATH.test( path )\n",
	"RE_EXTNAME": "dir = RE_EXTNAME.exec( '/foo/bar/index.js' )[ 1 ]\n",
	"RE_EXTNAME_POSIX": "ext = RE_EXTNAME_POSIX.exec( '/foo/bar/index.js' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( './foo/bar/.gitignore' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( 'foo/file.pdf' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( '/foo/bar/file' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( 'index.js' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( '.' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( './' )[ 1 ]\next = RE_EXTNAME_POSIX.exec( '' )[ 1 ]\n",
	"RE_EXTNAME_WINDOWS": "ext = RE_EXTNAME_WINDOWS.exec( 'C:\\\\foo\\\\bar\\\\index.js' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( 'C:\\\\foo\\\\bar\\\\.gitignore' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( 'foo\\\\file.pdf' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( '\\\\foo\\\\bar\\\\file' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( beep\\\\boop.' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( 'index.js' )[ 1 ]\next = RE_EXTNAME_WINDOWS.exec( '' )[ 1 ]\n",
	"RE_FILENAME": "f = '/foo/bar/index.js';\nparts = RE_FILENAME.exec( f ).slice()\n",
	"RE_FILENAME_POSIX": "parts = RE_FILENAME_POSIX.exec( '/foo/bar/index.js' ).slice()\nparts = RE_FILENAME_POSIX.exec( './foo/bar/.gitignore' ).slice()\nparts = RE_FILENAME_POSIX.exec( 'foo/file.pdf' ).slice()\nparts = RE_FILENAME_POSIX.exec( '/foo/bar/file' ).slice()\nparts = RE_FILENAME_POSIX.exec( 'index.js' ).slice()\nparts = RE_FILENAME_POSIX.exec( '.' ).slice()\nparts = RE_FILENAME_POSIX.exec( './' ).slice()\nparts = RE_FILENAME_POSIX.exec( '' ).slice()\n",
	"RE_FILENAME_WINDOWS": "parts = RE_FILENAME_WINDOWS.exec( 'C:\\\\foo\\\\bar\\\\index.js' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( '\\\\foo\\\\bar\\\\.gitignore' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( 'foo\\\\file.pdf' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( '\\\\foo\\\\bar\\\\file' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( 'index.js' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( '.' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( './' ).slice()\nparts = RE_FILENAME_WINDOWS.exec( '' ).slice()\n",
	"RE_FUNCTION_NAME": "function beep() { return 'boop'; };\nname = RE_FUNCTION_NAME.exec( beep.toString() )[ 1 ]\nname = RE_FUNCTION_NAME.exec( function () {} )[ 1 ]\n",
	"RE_NATIVE_FUNCTION": "bool = RE_NATIVE_FUNCTION.test( Date.toString() )\nbool = RE_NATIVE_FUNCTION.test( (function noop() {}).toString() )\n",
	"RE_REGEXP": "bool = RE_REGEXP.test( '/^beep$/' )\nbool = RE_REGEXP.test( '/boop' )\n\n// Escape regular expression strings:\nbool = RE_REGEXP.test( '/^\\/([^\\/]+)\\/(.*)$/' )\nbool = RE_REGEXP.test( '/^\\\\/([^\\\\/]+)\\\\/(.*)$/' )\n",
	"RE_UNC_PATH": "path = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz:a:b';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz::b';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz:a';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\\\\\share';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\\\\\\\\\server\\\\share';\nbool = RE_UNC_PATH.test( path )\npath = 'beep boop \\\\\\\\server\\\\share';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\';\nbool = RE_UNC_PATH.test( path )\npath = '';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz:';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz:a:';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz::';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\baz:a:b:c';\nbool = RE_UNC_PATH.test( path )\npath = '\\\\\\\\server\\\\share\\\\foo\\\\bar\\\\';\nbool = RE_UNC_PATH.test( path )\npath = '//server/share';\nbool = RE_UNC_PATH.test( path )\npath = '/foo/bar';\nbool = RE_UNC_PATH.test( path )\npath = 'foo/bar';\nbool = RE_UNC_PATH.test( path )\npath = './foo/bar';\nbool = RE_UNC_PATH.test( path )\npath = '/foo/../bar';\nbool = RE_UNC_PATH.test( path )\n",
	"RE_UTF16_SURROGATE_PAIR": "bool = RE_UTF16_SURROGATE_PAIR.test( 'abc\\uD800\\uDC00def' )\nbool = RE_UTF16_SURROGATE_PAIR.test( 'abcdef' )\n",
	"RE_UTF16_UNPAIRED_SURROGATE": "bool = RE_UTF16_UNPAIRED_SURROGATE.test( 'abc' )\nbool = RE_UTF16_UNPAIRED_SURROGATE.test( '\\uD800' )\n",
	"RE_WHITESPACE": "bool = RE_WHITESPACE.test( '\\n' )\nbool = RE_WHITESPACE.test( ' ' )\nbool = RE_WHITESPACE.test( 'a' )\n",
	"rpad": "out = rpad( 'a', 5 )\nout = rpad( 'beep', 10, 'p' )\nout = rpad( 'beep', 12, 'boop' )\n",
	"rtrim": "out = rtrim( ' \\t\\t\\n  Beep \\r\\n\\t  ' )\n",
	"safeintmax": "m = safeintmax( 'float16' )\nm = safeintmax( 'float32' )\n",
	"safeintmin": "m = safeintmin( 'float16' )\nm = safeintmin( 'float32' )\n",
	"sample": "out = sample( 'abc' )\nout = sample( [ 3, 6, 9 ] )\nbool = ( out.length === 3 )\nout = sample( [ 3, null, NaN, 'abc', function(){} ] )\n\n// Set sample size:\nout = sample( [ 3, 6, 9 ], { 'size': 10 })\nout = sample( [ 0, 1 ], { 'size': 20 })\n\n// Draw without replacement:\nout = sample( [ 1, 2, 3, 4, 5, 6 ], { 'replace': false, 'size': 3 })\nout = sample( [ 0, 1 ], { 'replace': false })\n\n// Assigning non-uniform element probabilities:\nx = [ 1, 2, 3, 4, 5, 6 ];\nprobs = [ 0.1, 0.1, 0.1, 0.1, 0.1, 0.5 ];\nout = sample( x, { 'probs': probs })\nout = sample( x, { 'probs': probs, 'size': 3, 'replace': false })\n",
	"SAVOY_STOPWORDS_FIN": "list = SAVOY_STOPWORDS_FIN()\n",
	"SAVOY_STOPWORDS_FR": "list = SAVOY_STOPWORDS_FR()\n",
	"SAVOY_STOPWORDS_GER": "list = SAVOY_STOPWORDS_GER()\n",
	"SAVOY_STOPWORDS_IT": "list = SAVOY_STOPWORDS_IT()\n",
	"SAVOY_STOPWORDS_POR": "list = SAVOY_STOPWORDS_POR()\n",
	"SAVOY_STOPWORDS_SP": "list = SAVOY_STOPWORDS_SP()\n",
	"SAVOY_STOPWORDS_SWE": "list = SAVOY_STOPWORDS_SWE()\n",
	"SECONDS_IN_DAY": "days = 3.14;\nsecs = days * SECONDS_IN_DAY\n",
	"SECONDS_IN_HOUR": "hrs = 3.14;\nsecs = hrs * SECONDS_IN_HOUR\n",
	"SECONDS_IN_MINUTE": "mins = 3.14;\nsecs = mins * SECONDS_IN_MINUTE\n",
	"SECONDS_IN_WEEK": "wks = 3.14;\nsecs = wks * SECONDS_IN_WEEK\n",
	"secondsInMonth": "num = secondsInMonth()\nnum = secondsInMonth( 2 )\nnum = secondsInMonth( 2, 2016 )\nnum = secondsInMonth( 2, 2017 )\n\n// Other ways to supply month:\nnum = secondsInMonth( 'feb', 2016 )\nnum = secondsInMonth( 'february', 2016 )\n",
	"secondsInYear": "num = secondsInYear()\nnum = secondsInYear( 2016 )\nnum = secondsInYear( 2017 )\n",
	"setReadOnly": "obj = {};\nsetReadOnly( obj, 'foo', 'bar' );\nobj.foo = 'boop';\nobj\n",
	"SharedArrayBuffer": "\n// Assuming an environment supports SharedArrayBuffers...\nbuf = new SharedArrayBuffer( 5 )\n",
	"shift": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\nout = shift( arr )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\nout = shift( arr )\n\n// Array-like object:\narr = { 'length': 2, '0': 1.0, '1': 2.0 };\nout = shift( arr )\n",
	"sizeOf": "s = sizeOf( 'int8' )\ns = sizeOf( 'uint32' )\n",
	"some": "arr = [ 0, 0, 1, 2, 3 ];\nbool = some( arr, 3 )\n",
	"someBy": "function negative( v ) { return ( v < 0 ); };\narr = [ 1, 2, -3, 4, -1 ];\nbool = someBy( arr, 2, negative )\n",
	"someByAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 3000, 2500, 1000 ];\nsomeByAsync( arr, 2, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000 ];\nsomeByAsync( arr, 2, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000 ];\nsomeByAsync( arr, 2, opts, predicate, done )\n",
	"someByRight": "function negative( v ) { return ( v < 0 ); };\narr = [ -1, 1, -2, 3, 4 ];\nbool = someByRight( arr, 2, negative )\n",
	"someByRightAsync": "\n// Basic usage:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\narr = [ 1000, 2500, 3000 ];\nsomeByRightAsync( arr, 2, predicate, done )\n\n// Limit number of concurrent invocations:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'limit': 2 };\narr = [ 1000, 2500, 3000 ];\nsomeByRightAsync( arr, 2, opts, predicate, done )\n\n// Process sequentially:\nfunction predicate( value, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, false );\n  }\n};\nfunction done( error, bool ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( bool );\n};\nopts = { 'series': true };\narr = [ 1000, 2500, 3000 ];\nsomeByRightAsync( arr, 2, opts, predicate, done )\n",
	"SOTU": "out = SOTU()\n\n// Retrieve addresses by one or more Presidents...\nopts = { 'name': 'Barack Obama' };\nout = SOTU( opts )\n\n// Retrieve addresses by one or more political parties...\nopts = { 'party': [ 'Democratic', 'Federalist' ] };\nout = SOTU( opts )\n\n// Retrieve addresses from one or more years...\nopts = { 'year': [ 2008, 2009, 2011 ] };\nout = SOTU( opts )\n\n// Retrieve addresses from a range of consecutive years...\nopts = { 'range': [ 2008-2016 ] }\nout = SOTU( opts )\n",
	"SPACHE_REVISED": "list = SPACHE_REVISED()\n",
	"SPAM_ASSASSIN": "data = SPAM_ASSASSIN()\n",
	"SQRT_EPS": "SQRT_EPS\n",
	"SQRT_HALF": "SQRT_HALF\n",
	"SQRT_HALF_PI": "SQRT_HALF_PI\n",
	"SQRT_PHI": "SQRT_PHI\n",
	"SQRT_PI": "SQRT_PI\n",
	"SQRT_THREE": "SQRT_THREE\n",
	"SQRT_TWO": "SQRT_TWO\n",
	"SQRT_TWO_PI": "SQRT_TWO_PI\n",
	"startcase": "out = startcase( 'beep boop' )\n",
	"startsWith": "bool = startsWith( 'Beep', 'Be' )\nbool = startsWith( 'Beep', 'ep' )\nbool = startsWith( 'Beep', 'ee', 1 )\nbool = startsWith( 'Beep', 'ee', -3 )\nbool = startsWith( 'Beep', '' )\n",
	"STOPWORDS_EN": "list = STOPWORDS_EN()\n",
	"string2buffer": "b = string2buffer( 'beep boop' )\nb = string2buffer( '7468697320697320612074c3a97374', 'hex' );\nb.toString()\n",
	"tabulate": "collection = [ 'beep', 'boop', 'foo', 'beep' ];\nout = tabulate( collection )\n",
	"tabulateBy": "function indicator( value ) { return value[ 0 ]; };\ncollection = [ 'beep', 'boop', 'foo', 'beep' ];\nout = tabulateBy( collection, indicator )\n",
	"tabulateByAsync": "\n// Basic usage:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even': 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\narr = [ 3000, 2500, 1000, 750 ];\ntabulateByAsync( arr, indicator, done )\n\n// Limit number of concurrent invocations:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even' : 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'limit': 2 };\narr = [ 3000, 2500, 1000, 750 ];\ntabulateByAsync( arr, opts, indicator, done )\n\n// Process sequentially:\nfunction indicator( value, index, next ) {\n  setTimeout( onTimeout, value );\n  function onTimeout() {\n      console.log( value );\n      next( null, ( index%2 === 0 ) ? 'even' : 'odd' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nopts = { 'series': true };\narr = [ 3000, 2500, 1000, 750 ];\ntabulateByAsync( arr, opts, indicator, done )\n",
	"tic": "t = tic()\n",
	"timeit": "code = 'var x = Math.pow( Math.random(), 3 );';\ncode += 'if ( x !== x ) {';\ncode += 'throw new Error( \\'Something went wrong.\\' );';\ncode += '}';\nfunction done( error, results ) {\n  if ( error ) {\n      throw error;\n  }\n  console.dir( results );\n};\ntimeit( code, done );\n",
	"tmpdir": "dir = tmpdir()\n",
	"toc": "start = tic();\ndelta = toc( start )\n",
	"tokenize": "out = tokenize( 'Hello Mrs. Maple, could you call me back?' )\nout = tokenize( 'Hello World!', true )\n",
	"trim": "out = trim( ' \\t\\t\\n  Beep \\r\\n\\t  ' )\n",
	"trycatch": "function x() {\n  if ( base.random.randu() < 0.5 ) {\n      throw new Error( 'beep' );\n  }\n  return 1.0;\n};\nz = trycatch( x, -1.0 )\n",
	"trycatchAsync": "function x( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( new Error( 'beep' ) );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      // process error...\n  }\n  console.log( result );\n};\ntrycatchAsync( x, 'boop', done )\n",
	"tryFunction": "function fcn() { throw new Error( 'beep boop' ); };\nf = wrap( fcn );\nout = f();\nout.message\n",
	"tryRequire": "out = tryRequire( '_unknown_module_id_' )\n",
	"trythen": "function x() {\n  if ( base.random.randu() < 0.5 ) {\n      throw new Error( 'beep' );\n  }\n  return 1.0;\n};\nfunction y() {\n  return -1.0;\n};\nz = trythen( x, y )\n",
	"trythenAsync": "function x( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( new Error( 'beep' ) );\n  }\n};\nfunction y( clbk ) {\n  setTimeout( onTimeout, 0 );\n  function onTimeout() {\n      clbk( null, 'boop' );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\ntrythenAsync( x, y, done )\n",
	"ttest": "\n// One-sample t-test:\nrnorm = base.random.normal.factory( 0.0, 2.0, { 'seed': 5776 });\nx = new Array( 100 );\nfor ( var i = 0; i < x.length; i++ ) {\n  x[ i ] = rnorm();\n}\nout = ttest( x )\n\n// Paired t-test:\nrnorm = base.random.normal.factory( 1.0, 2.0, { 'seed': 786 });\nx = new Array( 100 );\ny = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) {\n  x[ i ] = rnorm();\n  y[ i ] = rnorm();\n}\nout = ttest( x, y )\n\n// Print formatted output:\ntable = out.print()\n\n// Choose custom significance level:\narr = [ 2, 4, 3, 1, 0 ];\nout = ttest( arr, { 'alpha': 0.01 });\ntable = out.print()\n\n// Test for a mean equal to five:\narr = [ 4, 4, 6, 6, 5 ];\nout = ttest( arr, { 'mu': 5 })\n\n// Perform one-sided tests:\narr = [ 4, 4, 6, 6, 5 ];\nout = ttest( arr, { 'alternative': 'less' });\ntable = out.print()\nout = ttest( arr, { 'alternative': 'greater' });\ntable = out.print()\n",
	"ttest2": "\n// Student's sleep data:\nx = [ 0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0.0, 2.0 ];\ny = [ 1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4 ];\nout = ttest2( x, y )\n\n// Print table output:\ntable = out.print();\n\n// Choose a different significance level than `0.05`:\nout = ttest2( x, y, { 'alpha': 0.1 });\ntable = out.print();\n\n// Perform one-sided tests:\nout = ttest2( x, y, { 'alternative': 'less' });\ntable = out.print()\nout = ttest2( x, y, { 'alternative': 'greater' });\ntable = out.print()\n\n// Run tests with equal variances assumption:\nx = [ 2, 3, 1, 4 ];\ny = [ 1, 2, 3, 1, 2, 5, 3, 4 ];\nout = ttest2( x, y, { 'variance': 'equal' });\ntable = out.print();\n\n// Test for a difference in means besides zero:\nrnorm = base.random.normal.factory({ 'seed': 372 });\nx = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) {\n  x[ i ] = rnorm( 2.0, 3.0 );\n}\ny = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) {\n  y[ i ] = rnorm( 1.0, 3.0 );\n}\nout = ttest2( x, y, { 'difference': 1.0, 'variance': 'equal' })\n",
	"TWO_PI": "TWO_PI\n",
	"typedarray2json": "arr = new Float64Array( 2 );\narr[ 0 ] = 5.0;\narr[ 1 ] = 3.0;\njson = typedarray2json( arr )\n",
	"typedarray": "arr = typedarray()\narr = typedarray( 'float32' )\n",
	"typedarrayCtors": "ctor = typedarrayCtors( 'float64' )\nctor = typedarrayCtors( 'float' )\n",
	"typedarrayDataTypes": "out = typedarrayDataTypes()\n",
	"typemax": "m = typemax( 'int8' )\nm = typemax( 'uint32' )\n",
	"typemin": "m = typemin( 'int8' )\nm = typemin( 'uint32' )\n",
	"typeOf": "\n// Built-ins:\nt = typeOf( 'a' )\nt = typeOf( 5 )\nt = typeOf( NaN )\nt = typeOf( true )\nt = typeOf( false )\nt = typeOf( null )\nt = typeOf( undefined )\nt = typeOf( [] )\nt = typeOf( {} )\nt = typeOf( function noop() {} )\nt = typeOf( new Symbol( 'beep' ) )\nt = typeOf( /.+/ )\nt = typeOf( new String( 'beep' ) )\nt = typeOf( new Number( 5 ) )\nt = typeOf( new Boolean( false ) )\nt = typeOf( new Array() )\nt = typeOf( new Object() )\nt = typeOf( new Int8Array( 10 ) )\nt = typeOf( new Uint8Array( 10 ) )\nt = typeOf( new Uint8ClampedArray( 10 ) )\nt = typeOf( new Int16Array( 10 ) )\nt = typeOf( new Uint16Array( 10 ) )\nt = typeOf( new Int32Array( 10 ) )\nt = typeOf( new Uint32Array( 10 ) )\nt = typeOf( new Float32Array( 10 ) )\nt = typeOf( new Float64Array( 10 ) )\nt = typeOf( new ArrayBuffer( 10 ) )\nt = typeOf( new Date() )\nt = typeOf( new RegExp( '.+ )') )\nt = typeOf( new Map() )\nt = typeOf( new Set() )\nt = typeOf( new WeakMap() )\nt = typeOf( new WeakSet() )\nt = typeOf( new Error( 'beep' ) )\nt = typeOf( new TypeError( 'beep' ) )\nt = typeOf( new SyntaxError( 'beep' ) )\nt = typeOf( new ReferenceError( 'beep' ) )\nt = typeOf( new URIError( 'beep' ) )\nt = typeOf( new RangeError( 'beep' ) )\nt = typeOf( new EvalError( 'beep' ) )\nt = typeOf( Math )\nt = typeOf( JSON )\n\n// Arguments object:\nfunction beep() { return arguments; };\nt = typeOf( beep() )\n\n// Node.js Buffer object:\nt = typeOf( new Buffer( 10 ) )\n\n// Custom constructor:\nfunction Person() { return this };\nt = typeOf( new Person() )\n\n// Anonymous constructor:\nFoo = function () { return this; };\nt = typeOf new Foo() )\n",
	"Uint16Array": "arr = new Uint16Array()\n",
	"UINT16_MAX": "UINT16_MAX\n",
	"UINT16_NUM_BYTES": "UINT16_NUM_BYTES\n",
	"Uint32Array": "arr = new Uint32Array()\n",
	"UINT32_MAX": "UINT32_MAX\n",
	"UINT32_NUM_BYTES": "UINT32_NUM_BYTES\n",
	"Uint8Array": "arr = new Uint8Array()\n",
	"Uint8ClampedArray": "arr = new Uint8ClampedArray()\n",
	"UINT8_MAX": "UINT8_MAX\n",
	"UINT8_NUM_BYTES": "UINT8_NUM_BYTES\n",
	"uncapitalize": "out = uncapitalize( 'Beep' )\nout = uncapitalize( 'bOOp' )\n",
	"uncapitalizeKeys": "obj = { 'AA': 1, 'BB': 2 };\nout = uncapitalizeKeys( obj )\n",
	"uncurry": "function addX( x ) {\n  return function addY( y ) {\n      return x + y;\n  };\n};\nfcn = uncurry( addX );\nsum = fcn( 2, 3 )\n\n// To enforce a fixed number of parameters, provide an `arity` argument:\nfunction add( x ) {\n  return function add( y ) {\n      return x + y;\n  };\n};\nfcn = uncurry( add, 2 );\nsum = fcn( 9 )\n\n// To specify an execution context, provide a `thisArg` argument:\nfunction addX( x ) {\n  this.x = x;\n  return addY;\n};\nfunction addY( y ) {\n  return this.x + y;\n};\nfcn = uncurry( addX, {} );\nsum = fcn( 2, 3 )\n",
	"uncurryRight": "function addX( x ) {\n  return function addY( y ) {\n      return x + y;\n  };\n};\nfcn = uncurryRight( addX );\nsum = fcn( 3, 2 )\n\n// To enforce a fixed number of parameters, provide an `arity` argument:\nfunction add( y ) {\n  return function add( x ) {\n      return x + y;\n  };\n};\nfcn = uncurryRight( add, 2 );\nsum = fcn( 9 )\n\n// To specify an execution context, provide a `thisArg` argument:\nfunction addY( y ) {\n  this.y = y;\n  return addX;\n};\nfunction addX( x ) {\n  return x + this.y;\n};\nfcn = uncurryRight( addY, {} );\nsum = fcn( 3, 2 )\n",
	"UNICODE_MAX": "UNICODE_MAX\n",
	"UNICODE_MAX_BMP": "UNICODE_MAX_BMP\n",
	"unlink": "function done( error ) {\n  if ( error ) {\n      console.error( error.message );\n  }\n};\nunlink( './beep/boop.txt', done );\n",
	"unshift": "\n// Arrays:\narr = [ 1.0, 2.0, 3.0, 4.0, 5.0 ];\narr = unshift( arr, 6.0, 7.0 )\n\n// Typed arrays:\narr = new Float64Array( [ 1.0, 2.0 ] );\narr = unshift( arr, 3.0, 4.0 )\n\n// Array-like object:\narr = { 'length': 1, '0': 1.0 };\narr = unshift( arr, 2.0, 3.0 )\n",
	"until": "function predicate( i ) { return ( i >= 5 ); };\nfunction beep( i ) { console.log( 'boop: %d', i ); };\nuntil( predicate, beep )\n",
	"untilAsync": "function predicate( i, clbk ) { clbk( null, i >= 5 ); };\nfunction fcn( i, next ) {\n  setTimeout( onTimeout, i );\n  function onTimeout() {\n      next( null, 'boop'+i );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nuntilAsync( predicate, fcn, done )\n",
	"untilEach": "function predicate( v ) { return v !== v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4, NaN, 5 ];\nuntilEach( arr, predicate, logger )\n",
	"untilEachRight": "function predicate( v ) { return v !== v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, NaN, 2, 3, 4, 5 ];\nuntilEachRight( arr, predicate, logger )\n",
	"unzip": "\n// Basic usage:\narr = [ [ 1, 'a', 3 ], [ 2, 'b', 4 ] ];\nout = unzip( arr )\n\n// Provide indices:\narr = [ [ 1, 'a', 3 ], [ 2, 'b', 4 ] ];\nout = unzip( arr, [ 0, 2 ] )\n",
	"uppercase": "out = uppercase( 'bEEp' )\n",
	"uppercaseKeys": "obj = { 'a': 1, 'b': 2 };\nout = uppercaseKeys( obj )\n",
	"US_STATES_ABBR": "list = US_STATES_ABBR()\n",
	"US_STATES_CAPITALS": "list = US_STATES_CAPITALS()\n",
	"US_STATES_CAPITALS_NAMES": "out = US_STATES_CAPITALS_NAMES()\n",
	"US_STATES_NAMES": "list = US_STATES_NAMES()\n",
	"US_STATES_NAMES_CAPITALS": "out = US_STATES_NAMES_CAPITALS()\n",
	"utf16ToUTF8Array": "str = '☃';\nout = utf16ToUTF8Array( str )\n",
	"waterfall": "function foo( next ) { next( null, 'beep' ); };\nfunction bar( str, next ) { console.log( str ); next(); };\nfunction done( error ) { if ( error ) { throw error; } };\nfcns = [ foo, bar ];\nwaterfall( fcns, done );\n",
	"whilst": "function predicate( i ) { return ( i < 5 ); };\nfunction beep( i ) { console.log( 'boop: %d', i ); };\nwhilst( predicate, beep )\n",
	"whileAsync": "function predicate( i, clbk ) { clbk( null, i < 5 ); };\nfunction fcn( i, next ) {\n  setTimeout( onTimeout, i );\n  function onTimeout() {\n      next( null, 'boop'+i );\n  }\n};\nfunction done( error, result ) {\n  if ( error ) {\n      throw error;\n  }\n  console.log( result );\n};\nwhileAsync( predicate, fcn, done )\n",
	"whileEach": "function predicate( v ) { return v === v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, 2, 3, 4, NaN, 5 ];\nwhileEach( arr, predicate, logger )\n",
	"whileEachRight": "function predicate( v ) { return v === v; };\nfunction logger( v, i ) { console.log( '%s: %d', i, v ); };\narr = [ 1, NaN, 2, 3, 4, 5 ];\nwhileEachRight( arr, predicate, logger )\n",
	"writeFile": "function onWrite( error ) {\n  if ( error ) {\n      console.error( error.message );\n  }\n};\nwriteFile( './beep/boop.txt', 'beep boop', onWrite );\n",
	"zip": "\n// Basic usage:\nout = zip( [ 1, 2 ], [ 'a', 'b' ] )\n\n// Turn off truncation:\nopts = { 'trunc': false };\nout = zip( [ 1, 2, 3 ], [ 'a', 'b' ], opts )\n",
	"ztest": "\n// One-sample z-test:\nrnorm = base.random.normal.factory( 0.0, 2.0, { 'seed': 212 });\nx = new Array( 100 );\nfor ( var i = 0; i < x.length; i++ ) {\n  x[ i ] = rnorm();\n}\nout = ztest( x, 2.0 )\n\n// Choose custom significance level and print output:\narr = [ 2, 4, 3, 1, 0 ];\nout = ztest( arr, 2.0, { 'alpha': 0.01 });\ntable = out.print()\n\n// Test for a mean equal to five:\narr = [ 4, 4, 6, 6, 5 ];\nout = ztest( arr, 1.0, { 'mu': 5 })\n\n// Perform one-sided tests:\narr = [ 4, 4, 6, 6, 5 ];\nout = ztest( arr, 1.0, { 'alternative': 'less' });\nout = ztest( arr, 1.0, { 'alternative': 'greater' });\n",
	"ztest2": "\n// Drawn from Normal(0,2):\nx = [ -0.21, 0.14, 1.65, 2.11, -1.86, -0.29, 1.48, 0.81, 0.86, 1.04 ];\n\n// Drawn from Normal(1,2):\ny = [ -1.53, -2.93, 2.34, -1.15, 2.7, -0.12, 4.22, 1.66, 3.43, 4.66 ];\nout = ztest2( x, y, 2.0, 2.0 )\n\n// Print table output:\ntable = out.print();\n\n// Choose a different significance level than `0.05`:\nout = ztest2( x, y, 2.0, 2.0, { 'alpha': 0.4 });\ntable = out.print();\n\n// Perform one-sided tests:\nout = ztest2( x, y, 2.0, 2.0, { 'alternative': 'less' });\ntable = out.print()\nout = ztest2( x, y, 2.0, 2.0, { 'alternative': 'greater' });\ntable = out.print()\n\n// Test for a difference in means besides zero:\nrnorm = base.random.normal.factory({ 'seed': 372 });\nx = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) {\n  x[ i ] = rnorm( 2.0, 1.0 );\n}\ny = new Array( 100 );\nfor ( i = 0; i < x.length; i++ ) {\n  y[ i ] = rnorm( 0.0, 2.0 );\n}\nout = ztest2( x, y, 1.0, 2.0, { 'difference': 2.0 })\n"
};
